var g_models = {"CohereForAI/aya-expanse-32b": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-10-24", "id": "CohereForAI/aya-expanse-32b", "name": "Aya Expanse 32B", "params": 32, "radar": {"en_basic": {"id": "en_basic", "series": [0.42, 0.7568, 0.6676, 0.6795, 0.9118, 0.7435, 0.8575, 0.344, 0.7575, 0.0049], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9651, 0.5539, 0.5857, 0.8119, 0.2951, 0.716, 0.2872, 0.2448, 0.6549, 0.0012], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.548, 0.72, 0.846, 0.657, 0.602, 0.824, 0.712, 0.794], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 36, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6143}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 17, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.713}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 37, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5116}}, "results": {"en_basic": {"BBH": 0.7575, "En Avg": 0.6143, "GSM8K": 0.8575, "HellaSwag": 0.6676, "HumanEval": 0.0049, "MATH": 0.344, "MMLU": 0.7435, "OpenBookQA": 0.42, "SQuAD2": 0.6795, "TriviaQA": 0.7568, "XWINO": 0.9118}, "ja_basic": {"JComQA": 0.9651, "JEMHopQA": 0.5539, "JHumanEval": 0.0012, "JMMLU": 0.6549, "JSQuAD": 0.8119, "Ja Avg": 0.5116, "MGSM": 0.716, "NIILC": 0.5857, "WMT20-en-ja": 0.2872, "WMT20-ja-en": 0.2448, "XL-Sum": 0.2951}, "ja_mtb": {"JMT Avg": 0.713, "coding": 0.548, "extraction": 0.72, "humanities": 0.846, "math": 0.657, "reasoning": 0.602, "roleplay": 0.824, "stem": 0.712, "writing": 0.794}, "other": {"GPQA": 0.1518}}, "sortkey": "aya expanse", "uri": "CohereForAI_aya-expanse-32b", "url": "https://huggingface.co/CohereForAI/aya-expanse-32b"}, "CohereForAI/aya-expanse-8b": {"base_model": "(private)", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-10-24", "id": "CohereForAI/aya-expanse-8b", "name": "Aya Expanse 8B", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.384, 0.5908, 0.6054, 0.6639, 0.8916, 0.6285, 0.7559, 0.284, 0.5898, 0.0], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9223, 0.4665, 0.3847, 0.8671, 0.2112, 0.608, 0.2609, 0.2058, 0.5213, 0.0012], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.494, 0.718, 0.855, 0.398, 0.433, 0.737, 0.677, 0.787], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 60, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5394}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 27, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.637}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 63, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4449}}, "results": {"en_basic": {"BBH": 0.5898, "En Avg": 0.5394, "GSM8K": 0.7559, "HellaSwag": 0.6054, "HumanEval": 0.0, "MATH": 0.284, "MMLU": 0.6285, "OpenBookQA": 0.384, "SQuAD2": 0.6639, "TriviaQA": 0.5908, "XWINO": 0.8916}, "ja_basic": {"JComQA": 0.9223, "JEMHopQA": 0.4665, "JHumanEval": 0.0012, "JMMLU": 0.5213, "JSQuAD": 0.8671, "Ja Avg": 0.4449, "MGSM": 0.608, "NIILC": 0.3847, "WMT20-en-ja": 0.2609, "WMT20-ja-en": 0.2058, "XL-Sum": 0.2112}, "ja_mtb": {"JMT Avg": 0.637, "coding": 0.494, "extraction": 0.718, "humanities": 0.855, "math": 0.398, "reasoning": 0.433, "roleplay": 0.737, "stem": 0.677, "writing": 0.787}, "other": {"GPQA": 0.2589}}, "sortkey": "aya expanse", "uri": "CohereForAI_aya-expanse-8b", "url": "https://huggingface.co/CohereForAI/aya-expanse-8b"}, "Qwen/Qwen2-72B-Instruct": {"base_model": "Qwen2-72B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-06-07", "id": "Qwen/Qwen2-72B-Instruct", "name": "Qwen2-72B-Instruct", "params": 72, "radar": {"en_basic": {"id": "en_basic", "series": [0.444, 0.7588, 0.6849, 0.6849, 0.911, 0.8395, 0.8484, 0.634, 0.1931, 0.6884], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9634, 0.6284, 0.5566, 0.9198, 0.1658, 0.78, 0.26, 0.2317, 0.7707, 0.7012], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.632, 0.8, 0.842, 0.688, 0.616, 0.824, 0.797, 0.846], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 23, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6687}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 12, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.756}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 9, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5978}}, "results": {"en_basic": {"BBH": 0.1931, "En Avg": 0.6687, "GSM8K": 0.8484, "HellaSwag": 0.6849, "HumanEval": 0.6884, "MATH": 0.634, "MMLU": 0.8395, "OpenBookQA": 0.444, "SQuAD2": 0.6849, "TriviaQA": 0.7588, "XWINO": 0.911}, "ja_basic": {"JComQA": 0.9634, "JEMHopQA": 0.6284, "JHumanEval": 0.7012, "JMMLU": 0.7707, "JSQuAD": 0.9198, "Ja Avg": 0.5978, "MGSM": 0.78, "NIILC": 0.5566, "WMT20-en-ja": 0.26, "WMT20-ja-en": 0.2317, "XL-Sum": 0.1658}, "ja_mtb": {"JMT Avg": 0.756, "coding": 0.632, "extraction": 0.8, "humanities": 0.842, "math": 0.688, "reasoning": 0.616, "roleplay": 0.824, "stem": 0.797, "writing": 0.846}, "other": {"GPQA": 0.4018}}, "sortkey": "qwen2", "uri": "Qwen_Qwen2-72B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2-72B-Instruct"}, "Qwen/Qwen2-7B-Instruct": {"base_model": "Qwen2-7B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-06-07", "id": "Qwen/Qwen2-7B-Instruct", "name": "Qwen2-7B-Instruct", "params": 7.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.396, 0.5466, 0.6146, 0.5927, 0.886, 0.7071, 0.6262, 0.504, 0.3044, 0.6427], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8883, 0.3902, 0.3788, 0.8967, 0.1265, 0.576, 0.2061, 0.1902, 0.571, 0.5549], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.512, 0.771, 0.719, 0.687, 0.514, 0.683, 0.563, 0.717], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 46, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.582}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 25, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.646}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 52, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4779}}, "results": {"en_basic": {"BBH": 0.3044, "En Avg": 0.582, "GSM8K": 0.6262, "HellaSwag": 0.6146, "HumanEval": 0.6427, "MATH": 0.504, "MMLU": 0.7071, "OpenBookQA": 0.396, "SQuAD2": 0.5927, "TriviaQA": 0.5466, "XWINO": 0.886}, "ja_basic": {"JComQA": 0.8883, "JEMHopQA": 0.3902, "JHumanEval": 0.5549, "JMMLU": 0.571, "JSQuAD": 0.8967, "Ja Avg": 0.4779, "MGSM": 0.576, "NIILC": 0.3788, "WMT20-en-ja": 0.2061, "WMT20-ja-en": 0.1902, "XL-Sum": 0.1265}, "ja_mtb": {"JMT Avg": 0.646, "coding": 0.512, "extraction": 0.771, "humanities": 0.719, "math": 0.687, "reasoning": 0.514, "roleplay": 0.683, "stem": 0.563, "writing": 0.717}, "other": {"GPQA": 0.1049}}, "sortkey": "qwen2", "uri": "Qwen_Qwen2-7B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2-7B-Instruct"}, "Qwen/Qwen2.5-0.5B-Instruct": {"base_model": "Qwen2.5-0.5B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-0.5B-Instruct", "name": "Qwen2.5-0.5B-Instruct", "params": 0.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.272, 0.1838, 0.3977, 0.5011, 0.7669, 0.4709, 0.1895, 0.236, 0.1055, 0.2396], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.3816, 0.4007, 0.1572, 0.6866, 0.1116, 0.08, 0.0947, 0.0666, 0.3183, 0.1348], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.335, 0.284, 0.285, 0.317, 0.248, 0.294, 0.279, 0.313], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 103, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.3363}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 59, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.294}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 105, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.2432}}, "results": {"en_basic": {"BBH": 0.1055, "En Avg": 0.3363, "GSM8K": 0.1895, "HellaSwag": 0.3977, "HumanEval": 0.2396, "MATH": 0.236, "MMLU": 0.4709, "OpenBookQA": 0.272, "SQuAD2": 0.5011, "TriviaQA": 0.1838, "XWINO": 0.7669}, "ja_basic": {"JComQA": 0.3816, "JEMHopQA": 0.4007, "JHumanEval": 0.1348, "JMMLU": 0.3183, "JSQuAD": 0.6866, "Ja Avg": 0.2432, "MGSM": 0.08, "NIILC": 0.1572, "WMT20-en-ja": 0.0947, "WMT20-ja-en": 0.0666, "XL-Sum": 0.1116}, "ja_mtb": {"JMT Avg": 0.294, "coding": 0.335, "extraction": 0.284, "humanities": 0.285, "math": 0.317, "reasoning": 0.248, "roleplay": 0.294, "stem": 0.279, "writing": 0.313}, "other": {"GPQA": 0.0446}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-0.5B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct"}, "Qwen/Qwen2.5-1.5B-Instruct": {"base_model": "Qwen2.5-1.5B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-1.5B-Instruct", "name": "Qwen2.5-1.5B-Instruct", "params": 1.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.334, 0.3781, 0.5029, 0.501, 0.8439, 0.6037, 0.257, 0.272, 0.2715, 0.2768], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8123, 0.2759, 0.2405, 0.8474, 0.1276, 0.292, 0.1473, 0.1192, 0.4473, 0.2421], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.408, 0.513, 0.456, 0.527, 0.352, 0.473, 0.406, 0.469], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 85, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4241}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 51, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.45}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 92, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3552}}, "results": {"en_basic": {"BBH": 0.2715, "En Avg": 0.4241, "GSM8K": 0.257, "HellaSwag": 0.5029, "HumanEval": 0.2768, "MATH": 0.272, "MMLU": 0.6037, "OpenBookQA": 0.334, "SQuAD2": 0.501, "TriviaQA": 0.3781, "XWINO": 0.8439}, "ja_basic": {"JComQA": 0.8123, "JEMHopQA": 0.2759, "JHumanEval": 0.2421, "JMMLU": 0.4473, "JSQuAD": 0.8474, "Ja Avg": 0.3552, "MGSM": 0.292, "NIILC": 0.2405, "WMT20-en-ja": 0.1473, "WMT20-ja-en": 0.1192, "XL-Sum": 0.1276}, "ja_mtb": {"JMT Avg": 0.45, "coding": 0.408, "extraction": 0.513, "humanities": 0.456, "math": 0.527, "reasoning": 0.352, "roleplay": 0.473, "stem": 0.406, "writing": 0.469}, "other": {"GPQA": 0.1406}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-1.5B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct"}, "Qwen/Qwen2.5-14B-Instruct": {"base_model": "Qwen2.5-14B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-09-25", "id": "Qwen/Qwen2.5-14B-Instruct", "name": "Qwen2.5-14B-Instruct", "params": 14, "radar": {"en_basic": {"id": "en_basic", "series": [0.438, 0.5919, 0.6558, 0.6797, 0.8903, 0.8005, 0.7612, 0.666, 0.0287, 0.6323], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9526, 0.588, 0.519, 0.9023, 0.14, 0.68, 0.1925, 0.1603, 0.708, 0.6909], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.673, 0.829, 0.798, 0.828, 0.571, 0.815, 0.743, 0.841], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 35, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6144}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 11, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.762}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 28, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5534}}, "results": {"en_basic": {"BBH": 0.0287, "En Avg": 0.6144, "GSM8K": 0.7612, "HellaSwag": 0.6558, "HumanEval": 0.6323, "MATH": 0.666, "MMLU": 0.8005, "OpenBookQA": 0.438, "SQuAD2": 0.6797, "TriviaQA": 0.5919, "XWINO": 0.8903}, "ja_basic": {"JComQA": 0.9526, "JEMHopQA": 0.588, "JHumanEval": 0.6909, "JMMLU": 0.708, "JSQuAD": 0.9023, "Ja Avg": 0.5534, "MGSM": 0.68, "NIILC": 0.519, "WMT20-en-ja": 0.1925, "WMT20-ja-en": 0.1603, "XL-Sum": 0.14}, "ja_mtb": {"JMT Avg": 0.762, "coding": 0.673, "extraction": 0.829, "humanities": 0.798, "math": 0.828, "reasoning": 0.571, "roleplay": 0.815, "stem": 0.743, "writing": 0.841}, "other": {"GPQA": 0.3795}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-14B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct"}, "Qwen/Qwen2.5-32B-Instruct": {"base_model": "Qwen2.5-32B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-09-25", "id": "Qwen/Qwen2.5-32B-Instruct", "name": "Qwen2.5-32B-Instruct", "params": 32, "radar": {"en_basic": {"id": "en_basic", "series": [0.424, 0.5341, 0.6709, 0.5362, 0.8933, 0.8336, 0.5807, 0.802, 0.0172, 0.589], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9589, 0.5672, 0.4966, 0.9033, 0.1688, 0.78, 0.2279, 0.1953, 0.7574, 0.6506], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.724, 0.885, 0.816, 0.918, 0.726, 0.834, 0.763, 0.808], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 45, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5881}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 6, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.809}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 24, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5706}}, "results": {"en_basic": {"BBH": 0.0172, "En Avg": 0.5881, "GSM8K": 0.5807, "HellaSwag": 0.6709, "HumanEval": 0.589, "MATH": 0.802, "MMLU": 0.8336, "OpenBookQA": 0.424, "SQuAD2": 0.5362, "TriviaQA": 0.5341, "XWINO": 0.8933}, "ja_basic": {"JComQA": 0.9589, "JEMHopQA": 0.5672, "JHumanEval": 0.6506, "JMMLU": 0.7574, "JSQuAD": 0.9033, "Ja Avg": 0.5706, "MGSM": 0.78, "NIILC": 0.4966, "WMT20-en-ja": 0.2279, "WMT20-ja-en": 0.1953, "XL-Sum": 0.1688}, "ja_mtb": {"JMT Avg": 0.809, "coding": 0.724, "extraction": 0.885, "humanities": 0.816, "math": 0.918, "reasoning": 0.726, "roleplay": 0.834, "stem": 0.763, "writing": 0.808}, "other": {"GPQA": 0.4018}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-32B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct"}, "Qwen/Qwen2.5-3B-Instruct": {"base_model": "Qwen2.5-3B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-3B-Instruct", "name": "Qwen2.5-3B-Instruct", "params": 3.1, "radar": {"en_basic": {"id": "en_basic", "series": [0.364, 0.4462, 0.562, 0.5041, 0.8692, 0.6642, 0.0955, 0.612, 0.1284, 0.4713], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8758, 0.3043, 0.2934, 0.8664, 0.1442, 0.228, 0.1984, 0.1679, 0.5363, 0.4738], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.567, 0.647, 0.597, 0.665, 0.457, 0.649, 0.526, 0.637], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 77, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4717}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 33, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.593}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 74, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4088}}, "results": {"en_basic": {"BBH": 0.1284, "En Avg": 0.4717, "GSM8K": 0.0955, "HellaSwag": 0.562, "HumanEval": 0.4713, "MATH": 0.612, "MMLU": 0.6642, "OpenBookQA": 0.364, "SQuAD2": 0.5041, "TriviaQA": 0.4462, "XWINO": 0.8692}, "ja_basic": {"JComQA": 0.8758, "JEMHopQA": 0.3043, "JHumanEval": 0.4738, "JMMLU": 0.5363, "JSQuAD": 0.8664, "Ja Avg": 0.4088, "MGSM": 0.228, "NIILC": 0.2934, "WMT20-en-ja": 0.1984, "WMT20-ja-en": 0.1679, "XL-Sum": 0.1442}, "ja_mtb": {"JMT Avg": 0.593, "coding": 0.567, "extraction": 0.647, "humanities": 0.597, "math": 0.665, "reasoning": 0.457, "roleplay": 0.649, "stem": 0.526, "writing": 0.637}, "other": {"GPQA": 0.3036}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-3B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct"}, "Qwen/Qwen2.5-72B-Instruct": {"base_model": "Qwen2.5-72B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-72B-Instruct", "name": "Qwen2.5-72B-Instruct", "params": 72, "radar": {"en_basic": {"id": "en_basic", "series": [0.454, 0.676, 0.7061, 0.6767, 0.8895, 0.8475, 0.9045, 0.77, 0.3749, 0.614], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9696, 0.5693, 0.5823, 0.7382, 0.17, 0.84, 0.2266, 0.2184, 0.7893, 0.6341], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.795, 0.86, 0.865, 0.857, 0.784, 0.863, 0.804, 0.854], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 16, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6913}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 4, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.835}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 21, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5738}}, "results": {"en_basic": {"BBH": 0.3749, "En Avg": 0.6913, "GSM8K": 0.9045, "HellaSwag": 0.7061, "HumanEval": 0.614, "MATH": 0.77, "MMLU": 0.8475, "OpenBookQA": 0.454, "SQuAD2": 0.6767, "TriviaQA": 0.676, "XWINO": 0.8895}, "ja_basic": {"JComQA": 0.9696, "JEMHopQA": 0.5693, "JHumanEval": 0.6341, "JMMLU": 0.7893, "JSQuAD": 0.7382, "Ja Avg": 0.5738, "MGSM": 0.84, "NIILC": 0.5823, "WMT20-en-ja": 0.2266, "WMT20-ja-en": 0.2184, "XL-Sum": 0.17}, "ja_mtb": {"JMT Avg": 0.835, "coding": 0.795, "extraction": 0.86, "humanities": 0.865, "math": 0.857, "reasoning": 0.784, "roleplay": 0.863, "stem": 0.804, "writing": 0.854}, "other": {"GPQA": 0.4643}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-72B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-72B-Instruct"}, "Qwen/Qwen2.5-7B-Instruct": {"base_model": "Qwen2.5-7B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-7B-Instruct", "name": "Qwen2.5-7B-Instruct", "params": 7.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.428, 0.5187, 0.6241, 0.5694, 0.877, 0.7416, 0.7392, 0.688, 0.2166, 0.636], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9151, 0.4293, 0.391, 0.891, 0.1675, 0.632, 0.2105, 0.1916, 0.623, 0.5323], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.599, 0.741, 0.719, 0.637, 0.541, 0.744, 0.624, 0.713], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 39, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6039}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 24, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.665}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 44, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4983}}, "results": {"en_basic": {"BBH": 0.2166, "En Avg": 0.6039, "GSM8K": 0.7392, "HellaSwag": 0.6241, "HumanEval": 0.636, "MATH": 0.688, "MMLU": 0.7416, "OpenBookQA": 0.428, "SQuAD2": 0.5694, "TriviaQA": 0.5187, "XWINO": 0.877}, "ja_basic": {"JComQA": 0.9151, "JEMHopQA": 0.4293, "JHumanEval": 0.5323, "JMMLU": 0.623, "JSQuAD": 0.891, "Ja Avg": 0.4983, "MGSM": 0.632, "NIILC": 0.391, "WMT20-en-ja": 0.2105, "WMT20-ja-en": 0.1916, "XL-Sum": 0.1675}, "ja_mtb": {"JMT Avg": 0.665, "coding": 0.599, "extraction": 0.741, "humanities": 0.719, "math": 0.637, "reasoning": 0.541, "roleplay": 0.744, "stem": 0.624, "writing": 0.713}, "other": {"GPQA": 0.3103}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-7B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct"}, "SakanaAI/TinySwallow-1.5B-Instruct": {"base_model": "TinySwallow-1.5B", "category": ["index-chat", "category-under-5b-chat"], "date": "2025-01-30", "id": "SakanaAI/TinySwallow-1.5B-Instruct", "name": "TinySwallow-1.5B-Instruct", "params": 1.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.31, 0.309, 0.4867, 0.5007, 0.843, 0.5598, 0.398, 0.162, 0.2505, 0.2939], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8025, 0.3448, 0.4471, 0.8561, 0.1593, 0.308, 0.2035, 0.143, 0.4606, 0.2506], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.434, 0.572, 0.772, 0.453, 0.392, 0.645, 0.61, 0.643], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 89, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4114}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 40, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.565}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 76, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3975}}, "results": {"en_basic": {"BBH": 0.2505, "En Avg": 0.4114, "GSM8K": 0.398, "HellaSwag": 0.4867, "HumanEval": 0.2939, "MATH": 0.162, "MMLU": 0.5598, "OpenBookQA": 0.31, "SQuAD2": 0.5007, "TriviaQA": 0.309, "XWINO": 0.843}, "ja_basic": {"JComQA": 0.8025, "JEMHopQA": 0.3448, "JHumanEval": 0.2506, "JMMLU": 0.4606, "JSQuAD": 0.8561, "Ja Avg": 0.3975, "MGSM": 0.308, "NIILC": 0.4471, "WMT20-en-ja": 0.2035, "WMT20-ja-en": 0.143, "XL-Sum": 0.1593}, "ja_mtb": {"JMT Avg": 0.565, "coding": 0.434, "extraction": 0.572, "humanities": 0.772, "math": 0.453, "reasoning": 0.392, "roleplay": 0.645, "stem": 0.61, "writing": 0.643}, "other": {"GPQA": 0.0134}}, "sortkey": "tinyswallow", "uri": "SakanaAI_TinySwallow-1.5B-Instruct", "url": "https://huggingface.co/SakanaAI/TinySwallow-1.5B-Instruct"}, "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407": {"base_model": "Llama 3.1 70B Instruct", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-07-23", "id": "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "name": "Llama-3.1-70B-Japanese-Instruct-2407", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.422, 0.8104, 0.6472, 0.6631, 0.917, 0.8074, 0.8893, 0.528, 0.8228, 0.7463], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9562, 0.6466, 0.6602, 0.9187, 0.1564, 0.748, 0.2901, 0.241, 0.7227, 0.6274], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.683, 0.827, 0.824, 0.749, 0.643, 0.818, 0.715, 0.751], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 5, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7253}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 13, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.751}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 11, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5967}}, "results": {"en_basic": {"BBH": 0.8228, "En Avg": 0.7253, "GSM8K": 0.8893, "HellaSwag": 0.6472, "HumanEval": 0.7463, "MATH": 0.528, "MMLU": 0.8074, "OpenBookQA": 0.422, "SQuAD2": 0.6631, "TriviaQA": 0.8104, "XWINO": 0.917}, "ja_basic": {"JComQA": 0.9562, "JEMHopQA": 0.6466, "JHumanEval": 0.6274, "JMMLU": 0.7227, "JSQuAD": 0.9187, "Ja Avg": 0.5967, "MGSM": 0.748, "NIILC": 0.6602, "WMT20-en-ja": 0.2901, "WMT20-ja-en": 0.241, "XL-Sum": 0.1564}, "ja_mtb": {"JMT Avg": 0.751, "coding": 0.683, "extraction": 0.827, "humanities": 0.824, "math": 0.749, "reasoning": 0.643, "roleplay": 0.818, "stem": 0.715, "writing": 0.751}, "other": {"GPQA": 0.4442}}, "sortkey": "llama 3.1 japanese 2407", "uri": "cyberagent_Llama-3.1-70B-Japanese-Instruct-2407", "url": "https://huggingface.co/cyberagent/Llama-3.1-70B-Japanese-Instruct-2407"}, "cyberagent/calm3-22b-chat": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-07-09", "id": "cyberagent/calm3-22b-chat", "name": "CyberAgentLM3-22B-chat", "params": 22, "radar": {"en_basic": {"id": "en_basic", "series": [0.372, 0.6192, 0.5975, 0.6027, 0.9049, 0.6025, 0.6975, 0.274, 0.5988, 0.0], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9339, 0.5096, 0.6479, 0.9109, 0.1044, 0.576, 0.2749, 0.215, 0.5411, 0.0006], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.519, 0.744, 0.859, 0.605, 0.548, 0.784, 0.7, 0.772], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 65, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5269}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 20, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.691}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 54, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4714}}, "results": {"en_basic": {"BBH": 0.5988, "En Avg": 0.5269, "GSM8K": 0.6975, "HellaSwag": 0.5975, "HumanEval": 0.0, "MATH": 0.274, "MMLU": 0.6025, "OpenBookQA": 0.372, "SQuAD2": 0.6027, "TriviaQA": 0.6192, "XWINO": 0.9049}, "ja_basic": {"JComQA": 0.9339, "JEMHopQA": 0.5096, "JHumanEval": 0.0006, "JMMLU": 0.5411, "JSQuAD": 0.9109, "Ja Avg": 0.4714, "MGSM": 0.576, "NIILC": 0.6479, "WMT20-en-ja": 0.2749, "WMT20-ja-en": 0.215, "XL-Sum": 0.1044}, "ja_mtb": {"JMT Avg": 0.691, "coding": 0.519, "extraction": 0.744, "humanities": 0.859, "math": 0.605, "reasoning": 0.548, "roleplay": 0.784, "stem": 0.7, "writing": 0.772}, "other": {"GPQA": 0.2567}}, "sortkey": "cyberagentlm3", "uri": "cyberagent_calm3-22b-chat", "url": "https://huggingface.co/cyberagent/calm3-22b-chat"}, "elyza/Llama-3-ELYZA-JP-8B": {"base_model": "(private)", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-06-26", "id": "elyza/Llama-3-ELYZA-JP-8B", "name": "Llama-3-ELYZA-JP-8B", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.318, 0.5508, 0.5229, 0.5997, 0.8817, 0.5871, 0.558, 0.164, 0.321, 0.4494], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8972, 0.4978, 0.4958, 0.9057, 0.1685, 0.436, 0.2504, 0.1851, 0.4866, 0.3884], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.389, 0.706, 0.647, 0.426, 0.613, 0.684, 0.533, 0.697], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 70, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4953}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 36, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.587}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 55, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4712}}, "results": {"en_basic": {"BBH": 0.321, "En Avg": 0.4953, "GSM8K": 0.558, "HellaSwag": 0.5229, "HumanEval": 0.4494, "MATH": 0.164, "MMLU": 0.5871, "OpenBookQA": 0.318, "SQuAD2": 0.5997, "TriviaQA": 0.5508, "XWINO": 0.8817}, "ja_basic": {"JComQA": 0.8972, "JEMHopQA": 0.4978, "JHumanEval": 0.3884, "JMMLU": 0.4866, "JSQuAD": 0.9057, "Ja Avg": 0.4712, "MGSM": 0.436, "NIILC": 0.4958, "WMT20-en-ja": 0.2504, "WMT20-ja-en": 0.1851, "XL-Sum": 0.1685}, "ja_mtb": {"JMT Avg": 0.587, "coding": 0.389, "extraction": 0.706, "humanities": 0.647, "math": 0.426, "reasoning": 0.613, "roleplay": 0.684, "stem": 0.533, "writing": 0.697}, "other": {"GPQA": 0.221}}, "sortkey": "llama 3 elyza jp", "uri": "elyza_Llama-3-ELYZA-JP-8B", "url": "https://huggingface.co/elyza/Llama-3-ELYZA-JP-8B"}, "google/gemma-2-27b-it": {"base_model": "Gemma 2 27B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-06-27", "id": "google/gemma-2-27b-it", "name": "Gemma 2 27B IT", "params": 27, "radar": {"en_basic": {"id": "en_basic", "series": [0.458, 0.7658, 0.6551, 0.6691, 0.9088, 0.7622, 0.8514, 0.466, 0.79, 0.7067], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9562, 0.5413, 0.5755, 0.8832, 0.1657, 0.704, 0.2903, 0.2488, 0.6701, 0.6378], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.727, 0.809, 0.874, 0.719, 0.639, 0.81, 0.74, 0.826], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 14, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7033}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 10, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.768}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 26, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5673}}, "results": {"en_basic": {"BBH": 0.79, "En Avg": 0.7033, "GSM8K": 0.8514, "HellaSwag": 0.6551, "HumanEval": 0.7067, "MATH": 0.466, "MMLU": 0.7622, "OpenBookQA": 0.458, "SQuAD2": 0.6691, "TriviaQA": 0.7658, "XWINO": 0.9088}, "ja_basic": {"JComQA": 0.9562, "JEMHopQA": 0.5413, "JHumanEval": 0.6378, "JMMLU": 0.6701, "JSQuAD": 0.8832, "Ja Avg": 0.5673, "MGSM": 0.704, "NIILC": 0.5755, "WMT20-en-ja": 0.2903, "WMT20-ja-en": 0.2488, "XL-Sum": 0.1657}, "ja_mtb": {"JMT Avg": 0.768, "coding": 0.727, "extraction": 0.809, "humanities": 0.874, "math": 0.719, "reasoning": 0.639, "roleplay": 0.81, "stem": 0.74, "writing": 0.826}, "other": {"GPQA": 0.0871}}, "sortkey": "gemma 2", "uri": "google_gemma-2-27b-it", "url": "https://huggingface.co/google/gemma-2-27b-it"}, "google/gemma-2-2b-it": {"base_model": "Gemma 2 2B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-06-27", "id": "google/gemma-2-2b-it", "name": "Gemma 2 2B IT", "params": 2.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.354, 0.5019, 0.5202, 0.5476, 0.8783, 0.5693, 0.4397, 0.23, 0.4637, 0.3823], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8624, 0.3478, 0.3147, 0.879, 0.1173, 0.252, 0.2068, 0.1835, 0.4366, 0.3213], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.454, 0.587, 0.693, 0.524, 0.445, 0.654, 0.567, 0.63], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 74, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4887}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 38, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.569}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 80, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3921}}, "results": {"en_basic": {"BBH": 0.4637, "En Avg": 0.4887, "GSM8K": 0.4397, "HellaSwag": 0.5202, "HumanEval": 0.3823, "MATH": 0.23, "MMLU": 0.5693, "OpenBookQA": 0.354, "SQuAD2": 0.5476, "TriviaQA": 0.5019, "XWINO": 0.8783}, "ja_basic": {"JComQA": 0.8624, "JEMHopQA": 0.3478, "JHumanEval": 0.3213, "JMMLU": 0.4366, "JSQuAD": 0.879, "Ja Avg": 0.3921, "MGSM": 0.252, "NIILC": 0.3147, "WMT20-en-ja": 0.2068, "WMT20-ja-en": 0.1835, "XL-Sum": 0.1173}, "ja_mtb": {"JMT Avg": 0.569, "coding": 0.454, "extraction": 0.587, "humanities": 0.693, "math": 0.524, "reasoning": 0.445, "roleplay": 0.654, "stem": 0.567, "writing": 0.63}, "other": {"GPQA": 0.0804}}, "sortkey": "gemma 2", "uri": "google_gemma-2-2b-it", "url": "https://huggingface.co/google/gemma-2-2b-it"}, "google/gemma-2-2b-jpn-it": {"base_model": "Gemma 2 2B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-06-27", "id": "google/gemma-2-2b-jpn-it", "name": "Gemma 2 JPN", "params": 2.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.37, 0.5026, 0.5319, 0.5391, 0.8787, 0.557, 0.351, 0.132, 0.4506, 0.3921], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8445, 0.3207, 0.2908, 0.8771, 0.1315, 0.192, 0.2042, 0.1795, 0.418, 0.311], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.467, 0.488, 0.741, 0.379, 0.406, 0.66, 0.589, 0.672], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 78, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4705}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 41, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.55}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 85, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3769}}, "results": {"en_basic": {"BBH": 0.4506, "En Avg": 0.4705, "GSM8K": 0.351, "HellaSwag": 0.5319, "HumanEval": 0.3921, "MATH": 0.132, "MMLU": 0.557, "OpenBookQA": 0.37, "SQuAD2": 0.5391, "TriviaQA": 0.5026, "XWINO": 0.8787}, "ja_basic": {"JComQA": 0.8445, "JEMHopQA": 0.3207, "JHumanEval": 0.311, "JMMLU": 0.418, "JSQuAD": 0.8771, "Ja Avg": 0.3769, "MGSM": 0.192, "NIILC": 0.2908, "WMT20-en-ja": 0.2042, "WMT20-ja-en": 0.1795, "XL-Sum": 0.1315}, "ja_mtb": {"JMT Avg": 0.55, "coding": 0.467, "extraction": 0.488, "humanities": 0.741, "math": 0.379, "reasoning": 0.406, "roleplay": 0.66, "stem": 0.589, "writing": 0.672}, "other": {"GPQA": 0.0335}}, "sortkey": "gemma 2 jpn", "uri": "google_gemma-2-2b-jpn-it", "url": "https://huggingface.co/google/gemma-2-2b-jpn-it"}, "google/gemma-2-9b-it": {"base_model": "Gemma 2 9B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-06-27", "id": "google/gemma-2-9b-it", "name": "Gemma 2 9B IT", "params": 9.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.432, 0.6584, 0.6048, 0.6592, 0.9041, 0.7234, 0.7786, 0.394, 0.7192, 0.6134], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9312, 0.5324, 0.5265, 0.8762, 0.1488, 0.636, 0.2734, 0.239, 0.6227, 0.5591], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.652, 0.765, 0.857, 0.614, 0.673, 0.811, 0.713, 0.8], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 27, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6487}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 16, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.736}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 30, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5345}}, "results": {"en_basic": {"BBH": 0.7192, "En Avg": 0.6487, "GSM8K": 0.7786, "HellaSwag": 0.6048, "HumanEval": 0.6134, "MATH": 0.394, "MMLU": 0.7234, "OpenBookQA": 0.432, "SQuAD2": 0.6592, "TriviaQA": 0.6584, "XWINO": 0.9041}, "ja_basic": {"JComQA": 0.9312, "JEMHopQA": 0.5324, "JHumanEval": 0.5591, "JMMLU": 0.6227, "JSQuAD": 0.8762, "Ja Avg": 0.5345, "MGSM": 0.636, "NIILC": 0.5265, "WMT20-en-ja": 0.2734, "WMT20-ja-en": 0.239, "XL-Sum": 0.1488}, "ja_mtb": {"JMT Avg": 0.736, "coding": 0.652, "extraction": 0.765, "humanities": 0.857, "math": 0.614, "reasoning": 0.673, "roleplay": 0.811, "stem": 0.713, "writing": 0.8}, "other": {"GPQA": 0.0647}}, "sortkey": "gemma 2", "uri": "google_gemma-2-9b-it", "url": "https://huggingface.co/google/gemma-2-9b-it"}, "gpt-3.5-turbo-0125": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-01-25", "id": "gpt-3.5-turbo-0125", "name": "GPT-3.5 (gpt-3.5-turbo-0125)", "params": 0, "radar": {"en_basic": {"id": "en_basic", "series": [-0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9223, 0.4563, 0.447, 0.8933, 0.2147, 0.572, 0.2867, 0.2431, 0.4993, 0.6159], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.693, 0.789, 0.773, 0.665, 0.462, 0.728, 0.644, 0.775], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 108, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.274}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 20, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.691}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 34, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5151}}, "results": {"en_basic": {"BBH": -0.01, "En Avg": -0.01, "GSM8K": -0.01, "HellaSwag": -0.01, "HumanEval": -0.01, "MATH": -0.01, "MMLU": -0.01, "OpenBookQA": -0.01, "SQuAD2": -0.01, "TriviaQA": -0.01, "XWINO": -0.01}, "ja_basic": {"JComQA": 0.9223, "JEMHopQA": 0.4563, "JHumanEval": 0.6159, "JMMLU": 0.4993, "JSQuAD": 0.8933, "Ja Avg": 0.5151, "MGSM": 0.572, "NIILC": 0.447, "WMT20-en-ja": 0.2867, "WMT20-ja-en": 0.2431, "XL-Sum": 0.2147}, "ja_mtb": {"JMT Avg": 0.691, "coding": 0.693, "extraction": 0.789, "humanities": 0.773, "math": 0.665, "reasoning": 0.462, "roleplay": 0.728, "stem": 0.644, "writing": 0.775}, "other": {"GPQA": 0.2902}}, "sortkey": "gpt 3.5 (gpt 3.5 turbo 0125)", "uri": "gpt-3.5-turbo-0125", "url": "https://platform.openai.com/docs/models"}, "gpt-4-turbo-2024-04-09": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-04-09", "id": "gpt-4-turbo-2024-04-09", "name": "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "params": 0, "radar": {"en_basic": {"id": "en_basic", "series": [-0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9714, 0.6897, 0.6151, 0.8783, 0.2008, 0.848, 0.2948, 0.2395, 0.7535, 0.7732], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.842, 0.891, 0.863, 0.865, 0.673, 0.861, 0.844, 0.854], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 108, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.274}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 3, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.837}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 4, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.6264}}, "results": {"en_basic": {"BBH": -0.01, "En Avg": -0.01, "GSM8K": -0.01, "HellaSwag": -0.01, "HumanEval": -0.01, "MATH": -0.01, "MMLU": -0.01, "OpenBookQA": -0.01, "SQuAD2": -0.01, "TriviaQA": -0.01, "XWINO": -0.01}, "ja_basic": {"JComQA": 0.9714, "JEMHopQA": 0.6897, "JHumanEval": 0.7732, "JMMLU": 0.7535, "JSQuAD": 0.8783, "Ja Avg": 0.6264, "MGSM": 0.848, "NIILC": 0.6151, "WMT20-en-ja": 0.2948, "WMT20-ja-en": 0.2395, "XL-Sum": 0.2008}, "ja_mtb": {"JMT Avg": 0.837, "coding": 0.842, "extraction": 0.891, "humanities": 0.863, "math": 0.865, "reasoning": 0.673, "roleplay": 0.861, "stem": 0.844, "writing": 0.854}, "other": {"GPQA": 0.3036}}, "sortkey": "gpt 4 turbo (gpt 4 turbo 2024 04 09)", "uri": "gpt-4-turbo-2024-04-09", "url": "https://platform.openai.com/docs/models"}, "gpt-4o-2024-05-13": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-05-13", "id": "gpt-4o-2024-05-13", "name": "GPT-4o (gpt-4o-2024-05-13)", "params": 0, "radar": {"en_basic": {"id": "en_basic", "series": [-0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9794, 0.7365, 0.7218, 0.8919, 0.14, 0.86, 0.3142, 0.2366, 0.7941, 0.8134], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.859, 0.93, 0.882, 0.917, 0.631, 0.858, 0.858, 0.851], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 108, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.274}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 1, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.848}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 1, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.6488}}, "results": {"en_basic": {"BBH": -0.01, "En Avg": -0.01, "GSM8K": -0.01, "HellaSwag": -0.01, "HumanEval": -0.01, "MATH": -0.01, "MMLU": -0.01, "OpenBookQA": -0.01, "SQuAD2": -0.01, "TriviaQA": -0.01, "XWINO": -0.01}, "ja_basic": {"JComQA": 0.9794, "JEMHopQA": 0.7365, "JHumanEval": 0.8134, "JMMLU": 0.7941, "JSQuAD": 0.8919, "Ja Avg": 0.6488, "MGSM": 0.86, "NIILC": 0.7218, "WMT20-en-ja": 0.3142, "WMT20-ja-en": 0.2366, "XL-Sum": 0.14}, "ja_mtb": {"JMT Avg": 0.848, "coding": 0.859, "extraction": 0.93, "humanities": 0.882, "math": 0.917, "reasoning": 0.631, "roleplay": 0.858, "stem": 0.858, "writing": 0.851}, "other": {"GPQA": 0.3058}}, "sortkey": "gpt 4o (gpt 4o 2024 05 13)", "uri": "gpt-4o-2024-05-13", "url": "https://platform.openai.com/docs/models"}, "gpt-4o-2024-08-06": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-08-06", "id": "gpt-4o-2024-08-06", "name": "GPT-4o (gpt-4o-2024-08-06)", "params": 0, "radar": {"en_basic": {"id": "en_basic", "series": [-0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9821, 0.7309, 0.7091, 0.8891, 0.17, 0.864, 0.3135, 0.2541, 0.797, 0.7518], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.855, 0.926, 0.88, 0.872, 0.706, 0.862, 0.838, 0.849], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 108, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.274}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 1, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.848}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 2, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.6462}}, "results": {"en_basic": {"BBH": -0.01, "En Avg": -0.01, "GSM8K": -0.01, "HellaSwag": -0.01, "HumanEval": -0.01, "MATH": -0.01, "MMLU": -0.01, "OpenBookQA": -0.01, "SQuAD2": -0.01, "TriviaQA": -0.01, "XWINO": -0.01}, "ja_basic": {"JComQA": 0.9821, "JEMHopQA": 0.7309, "JHumanEval": 0.7518, "JMMLU": 0.797, "JSQuAD": 0.8891, "Ja Avg": 0.6462, "MGSM": 0.864, "NIILC": 0.7091, "WMT20-en-ja": 0.3135, "WMT20-ja-en": 0.2541, "XL-Sum": 0.17}, "ja_mtb": {"JMT Avg": 0.848, "coding": 0.855, "extraction": 0.926, "humanities": 0.88, "math": 0.872, "reasoning": 0.706, "roleplay": 0.862, "stem": 0.838, "writing": 0.849}, "other": {"GPQA": 0.317}}, "sortkey": "gpt 4o (gpt 4o 2024 08 06)", "uri": "gpt-4o-2024-08-06", "url": "https://platform.openai.com/docs/models"}, "gpt-4o-mini-2024-07-18": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-08-06", "id": "gpt-4o-mini-2024-07-18", "name": "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "params": 0, "radar": {"en_basic": {"id": "en_basic", "series": [-0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01, -0.01], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9607, 0.4642, 0.5913, 0.902, 0.1601, 0.832, 0.2991, 0.2411, 0.6792, 0.675], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.825, 0.865, 0.857, 0.843, 0.665, 0.846, 0.855, 0.84], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 108, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.274}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 5, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.824}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 18, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5805}}, "results": {"en_basic": {"BBH": -0.01, "En Avg": -0.01, "GSM8K": -0.01, "HellaSwag": -0.01, "HumanEval": -0.01, "MATH": -0.01, "MMLU": -0.01, "OpenBookQA": -0.01, "SQuAD2": -0.01, "TriviaQA": -0.01, "XWINO": -0.01}, "ja_basic": {"JComQA": 0.9607, "JEMHopQA": 0.4642, "JHumanEval": 0.675, "JMMLU": 0.6792, "JSQuAD": 0.902, "Ja Avg": 0.5805, "MGSM": 0.832, "NIILC": 0.5913, "WMT20-en-ja": 0.2991, "WMT20-ja-en": 0.2411, "XL-Sum": 0.1601}, "ja_mtb": {"JMT Avg": 0.824, "coding": 0.825, "extraction": 0.865, "humanities": 0.857, "math": 0.843, "reasoning": 0.665, "roleplay": 0.846, "stem": 0.855, "writing": 0.84}, "other": {"GPQA": 0.2746}}, "sortkey": "gpt 4o mini (gpt 4o mini 2024 07 18)", "uri": "gpt-4o-mini-2024-07-18", "url": "https://platform.openai.com/docs/models"}, "llm-jp/llm-jp-3-1.8b-instruct": {"base_model": "llm-jp-3-1.8b", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "llm-jp/llm-jp-3-1.8b-instruct", "name": "llm-jp-3-1.8b-instruct", "params": 1.8, "radar": {"en_basic": {"id": "en_basic", "series": [0.286, 0.2961, 0.4854, 0.5018, 0.8469, 0.2772, 0.0432, 0.016, 0.2901, 0.0866], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.3244, 0.4131, 0.4663, 0.8373, 0.1049, 0.08, 0.2059, 0.1424, 0.2917, 0.061], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.274, 0.321, 0.68, 0.281, 0.301, 0.628, 0.504, 0.617], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 105, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.3129}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 50, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.451}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 101, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.2927}}, "results": {"en_basic": {"BBH": 0.2901, "En Avg": 0.3129, "GSM8K": 0.0432, "HellaSwag": 0.4854, "HumanEval": 0.0866, "MATH": 0.016, "MMLU": 0.2772, "OpenBookQA": 0.286, "SQuAD2": 0.5018, "TriviaQA": 0.2961, "XWINO": 0.8469}, "ja_basic": {"JComQA": 0.3244, "JEMHopQA": 0.4131, "JHumanEval": 0.061, "JMMLU": 0.2917, "JSQuAD": 0.8373, "Ja Avg": 0.2927, "MGSM": 0.08, "NIILC": 0.4663, "WMT20-en-ja": 0.2059, "WMT20-ja-en": 0.1424, "XL-Sum": 0.1049}, "ja_mtb": {"JMT Avg": 0.451, "coding": 0.274, "extraction": 0.321, "humanities": 0.68, "math": 0.281, "reasoning": 0.301, "roleplay": 0.628, "stem": 0.504, "writing": 0.617}, "other": {"GPQA": 0.1228}}, "sortkey": "llm jp 3", "uri": "llm-jp_llm-jp-3-1.8b-instruct", "url": "https://huggingface.co/llm-jp/llm-jp-3-1.8b-instruct"}, "llm-jp/llm-jp-3-13b-instruct": {"base_model": "llm-jp-3-13b", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-09-25", "id": "llm-jp/llm-jp-3-13b-instruct", "name": "llm-jp-3-13b-instruct", "params": 13, "radar": {"en_basic": {"id": "en_basic", "series": [0.342, 0.534, 0.5944, 0.5165, 0.892, 0.5056, 0.2434, 0.046, 0.4382, 0.2055], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8937, 0.339, 0.6382, 0.9014, 0.1507, 0.324, 0.2523, 0.2034, 0.4677, 0.1878], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.373, 0.556, 0.816, 0.371, 0.526, 0.73, 0.614, 0.715], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 84, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4318}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 35, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.588}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 69, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4358}}, "results": {"en_basic": {"BBH": 0.4382, "En Avg": 0.4318, "GSM8K": 0.2434, "HellaSwag": 0.5944, "HumanEval": 0.2055, "MATH": 0.046, "MMLU": 0.5056, "OpenBookQA": 0.342, "SQuAD2": 0.5165, "TriviaQA": 0.534, "XWINO": 0.892}, "ja_basic": {"JComQA": 0.8937, "JEMHopQA": 0.339, "JHumanEval": 0.1878, "JMMLU": 0.4677, "JSQuAD": 0.9014, "Ja Avg": 0.4358, "MGSM": 0.324, "NIILC": 0.6382, "WMT20-en-ja": 0.2523, "WMT20-ja-en": 0.2034, "XL-Sum": 0.1507}, "ja_mtb": {"JMT Avg": 0.588, "coding": 0.373, "extraction": 0.556, "humanities": 0.816, "math": 0.371, "reasoning": 0.526, "roleplay": 0.73, "stem": 0.614, "writing": 0.715}, "other": {"GPQA": 0.2009}}, "sortkey": "llm jp 3", "uri": "llm-jp_llm-jp-3-13b-instruct", "url": "https://huggingface.co/llm-jp/llm-jp-3-13b-instruct"}, "llm-jp/llm-jp-3-3.7b-instruct": {"base_model": "llm-jp-3-3.7b", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "llm-jp/llm-jp-3-3.7b-instruct", "name": "llm-jp-3-3.7b-instruct", "params": 3.7, "radar": {"en_basic": {"id": "en_basic", "series": [0.31, 0.3981, 0.5339, 0.5035, 0.8624, 0.349, 0.0713, 0.022, 0.3244, 0.0988], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.5326, 0.4637, 0.5285, 0.8469, 0.1393, 0.152, 0.224, 0.1702, 0.3587, 0.0848], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.311, 0.418, 0.73, 0.311, 0.339, 0.618, 0.551, 0.6], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 101, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.3473}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 49, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.485}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 95, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3501}}, "results": {"en_basic": {"BBH": 0.3244, "En Avg": 0.3473, "GSM8K": 0.0713, "HellaSwag": 0.5339, "HumanEval": 0.0988, "MATH": 0.022, "MMLU": 0.349, "OpenBookQA": 0.31, "SQuAD2": 0.5035, "TriviaQA": 0.3981, "XWINO": 0.8624}, "ja_basic": {"JComQA": 0.5326, "JEMHopQA": 0.4637, "JHumanEval": 0.0848, "JMMLU": 0.3587, "JSQuAD": 0.8469, "Ja Avg": 0.3501, "MGSM": 0.152, "NIILC": 0.5285, "WMT20-en-ja": 0.224, "WMT20-ja-en": 0.1702, "XL-Sum": 0.1393}, "ja_mtb": {"JMT Avg": 0.485, "coding": 0.311, "extraction": 0.418, "humanities": 0.73, "math": 0.311, "reasoning": 0.339, "roleplay": 0.618, "stem": 0.551, "writing": 0.6}, "other": {"GPQA": 0.1116}}, "sortkey": "llm jp 3", "uri": "llm-jp_llm-jp-3-3.7b-instruct", "url": "https://huggingface.co/llm-jp/llm-jp-3-3.7b-instruct"}, "meta-llama/Llama-3.2-1B-Instruct": {"base_model": "Llama 3.2 1B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "meta-llama/Llama-3.2-1B-Instruct", "name": "Llama 3.2 1B Instruct", "params": 1.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.274, 0.3749, 0.4396, 0.5014, 0.8366, 0.4543, 0.3177, 0.172, 0.362, 0.347], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.3968, 0.346, 0.1789, 0.5704, 0.0749, 0.164, 0.0698, 0.0906, 0.2875, 0.2067], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.254, 0.376, 0.218, 0.307, 0.267, 0.262, 0.246, 0.258], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 90, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4079}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 60, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.273}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 106, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.2386}}, "results": {"en_basic": {"BBH": 0.362, "En Avg": 0.4079, "GSM8K": 0.3177, "HellaSwag": 0.4396, "HumanEval": 0.347, "MATH": 0.172, "MMLU": 0.4543, "OpenBookQA": 0.274, "SQuAD2": 0.5014, "TriviaQA": 0.3749, "XWINO": 0.8366}, "ja_basic": {"JComQA": 0.3968, "JEMHopQA": 0.346, "JHumanEval": 0.2067, "JMMLU": 0.2875, "JSQuAD": 0.5704, "Ja Avg": 0.2386, "MGSM": 0.164, "NIILC": 0.1789, "WMT20-en-ja": 0.0698, "WMT20-ja-en": 0.0906, "XL-Sum": 0.0749}, "ja_mtb": {"JMT Avg": 0.273, "coding": 0.254, "extraction": 0.376, "humanities": 0.218, "math": 0.307, "reasoning": 0.267, "roleplay": 0.262, "stem": 0.246, "writing": 0.258}, "other": {"GPQA": 0.0513}}, "sortkey": "llama 3.2", "uri": "meta-llama_Llama-3.2-1B-Instruct", "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"}, "meta-llama/Llama-3.2-3B-Instruct": {"base_model": "Llama 3.2 3B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "meta-llama/Llama-3.2-3B-Instruct", "name": "Llama 3.2 3B Instruct", "params": 3.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.306, 0.5562, 0.5245, 0.5397, 0.8735, 0.597, 0.6293, 0.324, 0.5124, 0.511], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.7828, 0.3036, 0.2682, 0.8464, 0.1115, 0.372, 0.1733, 0.1551, 0.4038, 0.3866], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.426, 0.593, 0.431, 0.389, 0.292, 0.35, 0.38, 0.38], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 63, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5374}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 56, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.405}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 83, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3803}}, "results": {"en_basic": {"BBH": 0.5124, "En Avg": 0.5374, "GSM8K": 0.6293, "HellaSwag": 0.5245, "HumanEval": 0.511, "MATH": 0.324, "MMLU": 0.597, "OpenBookQA": 0.306, "SQuAD2": 0.5397, "TriviaQA": 0.5562, "XWINO": 0.8735}, "ja_basic": {"JComQA": 0.7828, "JEMHopQA": 0.3036, "JHumanEval": 0.3866, "JMMLU": 0.4038, "JSQuAD": 0.8464, "Ja Avg": 0.3803, "MGSM": 0.372, "NIILC": 0.2682, "WMT20-en-ja": 0.1733, "WMT20-ja-en": 0.1551, "XL-Sum": 0.1115}, "ja_mtb": {"JMT Avg": 0.405, "coding": 0.426, "extraction": 0.593, "humanities": 0.431, "math": 0.389, "reasoning": 0.292, "roleplay": 0.35, "stem": 0.38, "writing": 0.38}, "other": {"GPQA": 0.2589}}, "sortkey": "llama 3.2", "uri": "meta-llama_Llama-3.2-3B-Instruct", "url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"}, "meta-llama/Llama-3.3-70B-Instruct": {"base_model": "Llama 3.1 70B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-12-06", "id": "meta-llama/Llama-3.3-70B-Instruct", "name": "Llama 3.3 70B Instruct", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.426, 0.8172, 0.6674, 0.6837, 0.9174, 0.8241, 0.8901, 0.706, 0.8529, 0.8341], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.941, 0.6399, 0.5699, 0.8926, 0.1787, 0.784, 0.2779, 0.2429, 0.7345, 0.7439], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.707, 0.865, 0.757, 0.72, 0.635, 0.773, 0.706, 0.733], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 1, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7619}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 15, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.737}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 8, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.6005}}, "results": {"en_basic": {"BBH": 0.8529, "En Avg": 0.7619, "GSM8K": 0.8901, "HellaSwag": 0.6674, "HumanEval": 0.8341, "MATH": 0.706, "MMLU": 0.8241, "OpenBookQA": 0.426, "SQuAD2": 0.6837, "TriviaQA": 0.8172, "XWINO": 0.9174}, "ja_basic": {"JComQA": 0.941, "JEMHopQA": 0.6399, "JHumanEval": 0.7439, "JMMLU": 0.7345, "JSQuAD": 0.8926, "Ja Avg": 0.6005, "MGSM": 0.784, "NIILC": 0.5699, "WMT20-en-ja": 0.2779, "WMT20-ja-en": 0.2429, "XL-Sum": 0.1787}, "ja_mtb": {"JMT Avg": 0.737, "coding": 0.707, "extraction": 0.865, "humanities": 0.757, "math": 0.72, "reasoning": 0.635, "roleplay": 0.773, "stem": 0.706, "writing": 0.733}, "other": {"GPQA": 0.5915}}, "sortkey": "llama 3.3", "uri": "meta-llama_Llama-3.3-70B-Instruct", "url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"}, "meta-llama/Meta-Llama-3-70B-Instruct": {"base_model": "Llama 3 70B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-04-18", "id": "meta-llama/Meta-Llama-3-70B-Instruct", "name": "Llama 3 70B Instruct", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.438, 0.7997, 0.6549, 0.6962, 0.914, 0.8, 0.909, 0.474, 0.8331, 0.7738], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9401, 0.6145, 0.5567, 0.9131, 0.1907, 0.716, 0.2695, 0.2344, 0.6798, 0.6616], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.588, 0.884, 0.715, 0.637, 0.487, 0.594, 0.598, 0.619], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 4, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7293}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 26, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.64}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 20, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5776}}, "results": {"en_basic": {"BBH": 0.8331, "En Avg": 0.7293, "GSM8K": 0.909, "HellaSwag": 0.6549, "HumanEval": 0.7738, "MATH": 0.474, "MMLU": 0.8, "OpenBookQA": 0.438, "SQuAD2": 0.6962, "TriviaQA": 0.7997, "XWINO": 0.914}, "ja_basic": {"JComQA": 0.9401, "JEMHopQA": 0.6145, "JHumanEval": 0.6616, "JMMLU": 0.6798, "JSQuAD": 0.9131, "Ja Avg": 0.5776, "MGSM": 0.716, "NIILC": 0.5567, "WMT20-en-ja": 0.2695, "WMT20-ja-en": 0.2344, "XL-Sum": 0.1907}, "ja_mtb": {"JMT Avg": 0.64, "coding": 0.588, "extraction": 0.884, "humanities": 0.715, "math": 0.637, "reasoning": 0.487, "roleplay": 0.594, "stem": 0.598, "writing": 0.619}, "other": {"GPQA": 0.0357}}, "sortkey": "llama 3", "uri": "meta-llama_Meta-Llama-3-70B-Instruct", "url": "https://huggingface.co/meta-llama/Meta-Llama-3-70B-Instruct"}, "meta-llama/Meta-Llama-3-8B-Instruct": {"base_model": "Llama 3 8B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-04-18", "id": "meta-llama/Meta-Llama-3-8B-Instruct", "name": "Llama 3 8B Instruct", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.388, 0.6698, 0.5826, 0.6109, 0.892, 0.6569, 0.7453, 0.306, 0.6457, 0.5543], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8803, 0.4173, 0.3853, 0.8909, 0.1261, 0.424, 0.2141, 0.202, 0.4677, 0.2957], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.467, 0.706, 0.692, 0.31, 0.433, 0.542, 0.532, 0.546], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 38, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6051}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 43, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.529}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 71, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4303}}, "results": {"en_basic": {"BBH": 0.6457, "En Avg": 0.6051, "GSM8K": 0.7453, "HellaSwag": 0.5826, "HumanEval": 0.5543, "MATH": 0.306, "MMLU": 0.6569, "OpenBookQA": 0.388, "SQuAD2": 0.6109, "TriviaQA": 0.6698, "XWINO": 0.892}, "ja_basic": {"JComQA": 0.8803, "JEMHopQA": 0.4173, "JHumanEval": 0.2957, "JMMLU": 0.4677, "JSQuAD": 0.8909, "Ja Avg": 0.4303, "MGSM": 0.424, "NIILC": 0.3853, "WMT20-en-ja": 0.2141, "WMT20-ja-en": 0.202, "XL-Sum": 0.1261}, "ja_mtb": {"JMT Avg": 0.529, "coding": 0.467, "extraction": 0.706, "humanities": 0.692, "math": 0.31, "reasoning": 0.433, "roleplay": 0.542, "stem": 0.532, "writing": 0.546}, "other": {"GPQA": 0.2567}}, "sortkey": "llama 3", "uri": "meta-llama_Meta-Llama-3-8B-Instruct", "url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct"}, "meta-llama/Meta-Llama-3.1-70B-Instruct": {"base_model": "Llama 3.1 70B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-07-23", "id": "meta-llama/Meta-Llama-3.1-70B-Instruct", "name": "Llama 3.1 70B Instruct", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.426, 0.821, 0.6622, 0.6602, 0.917, 0.8222, 0.8764, 0.56, 0.8417, 0.7939], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.95, 0.6347, 0.5789, 0.9208, 0.1779, 0.732, 0.2792, 0.2475, 0.7331, 0.6957], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.691, 0.848, 0.73, 0.669, 0.618, 0.699, 0.699, 0.694], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 2, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7381}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 18, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.706}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 12, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.595}}, "results": {"en_basic": {"BBH": 0.8417, "En Avg": 0.7381, "GSM8K": 0.8764, "HellaSwag": 0.6622, "HumanEval": 0.7939, "MATH": 0.56, "MMLU": 0.8222, "OpenBookQA": 0.426, "SQuAD2": 0.6602, "TriviaQA": 0.821, "XWINO": 0.917}, "ja_basic": {"JComQA": 0.95, "JEMHopQA": 0.6347, "JHumanEval": 0.6957, "JMMLU": 0.7331, "JSQuAD": 0.9208, "Ja Avg": 0.595, "MGSM": 0.732, "NIILC": 0.5789, "WMT20-en-ja": 0.2792, "WMT20-ja-en": 0.2475, "XL-Sum": 0.1779}, "ja_mtb": {"JMT Avg": 0.706, "coding": 0.691, "extraction": 0.848, "humanities": 0.73, "math": 0.669, "reasoning": 0.618, "roleplay": 0.699, "stem": 0.699, "writing": 0.694}, "other": {"GPQA": 0.4353}}, "sortkey": "llama 3.1", "uri": "meta-llama_Meta-Llama-3.1-70B-Instruct", "url": "https://huggingface.co/meta-llama/Meta-Llama-3.1-70B-Instruct"}, "meta-llama/Meta-Llama-3.1-8B-Instruct": {"base_model": "Llama 3.1 8B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-07-23", "id": "meta-llama/Meta-Llama-3.1-8B-Instruct", "name": "Llama 3.1 8B Instruct", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.366, 0.6993, 0.5922, 0.6004, 0.9037, 0.6802, 0.743, 0.376, 0.6899, 0.6244], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8803, 0.4469, 0.4072, 0.8856, 0.1478, 0.516, 0.2177, 0.1995, 0.5086, 0.4884], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.42, 0.83, 0.55, 0.514, 0.349, 0.502, 0.479, 0.504], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 32, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6275}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 46, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.519}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 57, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4698}}, "results": {"en_basic": {"BBH": 0.6899, "En Avg": 0.6275, "GSM8K": 0.743, "HellaSwag": 0.5922, "HumanEval": 0.6244, "MATH": 0.376, "MMLU": 0.6802, "OpenBookQA": 0.366, "SQuAD2": 0.6004, "TriviaQA": 0.6993, "XWINO": 0.9037}, "ja_basic": {"JComQA": 0.8803, "JEMHopQA": 0.4469, "JHumanEval": 0.4884, "JMMLU": 0.5086, "JSQuAD": 0.8856, "Ja Avg": 0.4698, "MGSM": 0.516, "NIILC": 0.4072, "WMT20-en-ja": 0.2177, "WMT20-ja-en": 0.1995, "XL-Sum": 0.1478}, "ja_mtb": {"JMT Avg": 0.519, "coding": 0.42, "extraction": 0.83, "humanities": 0.55, "math": 0.514, "reasoning": 0.349, "roleplay": 0.502, "stem": 0.479, "writing": 0.504}, "other": {"GPQA": 0.2835}}, "sortkey": "llama 3.1", "uri": "meta-llama_Meta-Llama-3.1-8B-Instruct", "url": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct"}, "microsoft/Phi-3-mini-128k-instruct": {"base_model": "(private)", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-04-23", "id": "microsoft/Phi-3-mini-128k-instruct", "name": "Phi-3-Mini-128K-Instruct", "params": 3.8, "radar": {"en_basic": {"id": "en_basic", "series": [0.422, 0.5265, 0.6053, 0.5594, 0.8714, 0.6953, 0.7589, 0.368, 0.7114, 0.6268], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.7203, 0.3943, 0.2082, 0.8319, 0.1323, 0.408, 0.1502, 0.1363, 0.4089, 0.428], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.535, 0.68, 0.553, 0.514, 0.416, 0.505, 0.465, 0.525], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 34, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6145}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 45, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.524}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 82, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3819}}, "results": {"en_basic": {"BBH": 0.7114, "En Avg": 0.6145, "GSM8K": 0.7589, "HellaSwag": 0.6053, "HumanEval": 0.6268, "MATH": 0.368, "MMLU": 0.6953, "OpenBookQA": 0.422, "SQuAD2": 0.5594, "TriviaQA": 0.5265, "XWINO": 0.8714}, "ja_basic": {"JComQA": 0.7203, "JEMHopQA": 0.3943, "JHumanEval": 0.428, "JMMLU": 0.4089, "JSQuAD": 0.8319, "Ja Avg": 0.3819, "MGSM": 0.408, "NIILC": 0.2082, "WMT20-en-ja": 0.1502, "WMT20-ja-en": 0.1363, "XL-Sum": 0.1323}, "ja_mtb": {"JMT Avg": 0.524, "coding": 0.535, "extraction": 0.68, "humanities": 0.553, "math": 0.514, "reasoning": 0.416, "roleplay": 0.505, "stem": 0.465, "writing": 0.525}, "other": {"GPQA": 0.2746}}, "sortkey": "phi 3 mini 128k", "uri": "microsoft_Phi-3-mini-128k-instruct", "url": "https://huggingface.co/microsoft/Phi-3-mini-128k-instruct"}, "microsoft/phi-4": {"base_model": "(private)", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-12-13", "id": "microsoft/phi-4", "name": "Phi-4", "params": 14, "radar": {"en_basic": {"id": "en_basic", "series": [0.378, 0.6823, 0.6468, 0.6461, 0.9032, 0.802, 0.8992, 0.556, 0.6538, 0.6012], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9446, 0.6075, 0.5068, 0.9231, 0.2189, 0.796, 0.2831, 0.2308, 0.6885, 0.5982], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.692, 0.929, 0.795, 0.914, 0.544, 0.754, 0.688, 0.84], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 19, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6769}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 8, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.769}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 19, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5797}}, "results": {"en_basic": {"BBH": 0.6538, "En Avg": 0.6769, "GSM8K": 0.8992, "HellaSwag": 0.6468, "HumanEval": 0.6012, "MATH": 0.556, "MMLU": 0.802, "OpenBookQA": 0.378, "SQuAD2": 0.6461, "TriviaQA": 0.6823, "XWINO": 0.9032}, "ja_basic": {"JComQA": 0.9446, "JEMHopQA": 0.6075, "JHumanEval": 0.5982, "JMMLU": 0.6885, "JSQuAD": 0.9231, "Ja Avg": 0.5797, "MGSM": 0.796, "NIILC": 0.5068, "WMT20-en-ja": 0.2831, "WMT20-ja-en": 0.2308, "XL-Sum": 0.2189}, "ja_mtb": {"JMT Avg": 0.769, "coding": 0.692, "extraction": 0.929, "humanities": 0.795, "math": 0.914, "reasoning": 0.544, "roleplay": 0.754, "stem": 0.688, "writing": 0.84}, "other": {"GPQA": 0.0}}, "sortkey": "phi 4", "uri": "microsoft_phi-4", "url": "https://huggingface.co/microsoft/phi-4"}, "mistralai/Mistral-7B-Instruct-v0.3": {"base_model": "Mistral-7B-v0.3", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-05-22", "id": "mistralai/Mistral-7B-Instruct-v0.3", "name": "Mistral-7B-Instruct-v0.3", "params": 7.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.408, 0.6767, 0.6522, 0.5762, 0.9054, 0.6206, 0.4996, 0.16, 0.563, 0.3457], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.7542, 0.4467, 0.2677, 0.8695, 0.2053, 0.224, 0.1634, 0.177, 0.4033, 0.2665], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.488, 0.54, 0.435, 0.354, 0.392, 0.409, 0.405, 0.401], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 58, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5407}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 52, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.428}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 84, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3778}}, "results": {"en_basic": {"BBH": 0.563, "En Avg": 0.5407, "GSM8K": 0.4996, "HellaSwag": 0.6522, "HumanEval": 0.3457, "MATH": 0.16, "MMLU": 0.6206, "OpenBookQA": 0.408, "SQuAD2": 0.5762, "TriviaQA": 0.6767, "XWINO": 0.9054}, "ja_basic": {"JComQA": 0.7542, "JEMHopQA": 0.4467, "JHumanEval": 0.2665, "JMMLU": 0.4033, "JSQuAD": 0.8695, "Ja Avg": 0.3778, "MGSM": 0.224, "NIILC": 0.2677, "WMT20-en-ja": 0.1634, "WMT20-ja-en": 0.177, "XL-Sum": 0.2053}, "ja_mtb": {"JMT Avg": 0.428, "coding": 0.488, "extraction": 0.54, "humanities": 0.435, "math": 0.354, "reasoning": 0.392, "roleplay": 0.409, "stem": 0.405, "writing": 0.401}, "other": {"GPQA": 0.2768}}, "sortkey": "mistral v0.3", "uri": "mistralai_Mistral-7B-Instruct-v0.3", "url": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3"}, "mistralai/Mistral-Nemo-Instruct-2407": {"base_model": "Mistral-Nemo-Base-2407 (12B)", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-07-18", "id": "mistralai/Mistral-Nemo-Instruct-2407", "name": "Mistral-NeMo-Instruct-2407 (12B)", "params": 12, "radar": {"en_basic": {"id": "en_basic", "series": [0.406, 0.7259, 0.6451, 0.6061, 0.9114, 0.6831, 0.721, 0.274, 0.5372, 0.5713], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9267, 0.4967, 0.4841, 0.9046, 0.1764, 0.552, 0.2402, 0.2054, 0.5479, 0.4695], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.515, 0.698, 0.702, 0.512, 0.481, 0.669, 0.66, 0.691], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 37, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6081}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 30, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.616}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 41, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5004}}, "results": {"en_basic": {"BBH": 0.5372, "En Avg": 0.6081, "GSM8K": 0.721, "HellaSwag": 0.6451, "HumanEval": 0.5713, "MATH": 0.274, "MMLU": 0.6831, "OpenBookQA": 0.406, "SQuAD2": 0.6061, "TriviaQA": 0.7259, "XWINO": 0.9114}, "ja_basic": {"JComQA": 0.9267, "JEMHopQA": 0.4967, "JHumanEval": 0.4695, "JMMLU": 0.5479, "JSQuAD": 0.9046, "Ja Avg": 0.5004, "MGSM": 0.552, "NIILC": 0.4841, "WMT20-en-ja": 0.2402, "WMT20-ja-en": 0.2054, "XL-Sum": 0.1764}, "ja_mtb": {"JMT Avg": 0.616, "coding": 0.515, "extraction": 0.698, "humanities": 0.702, "math": 0.512, "reasoning": 0.481, "roleplay": 0.669, "stem": 0.66, "writing": 0.691}, "other": {"GPQA": 0.2076}}, "sortkey": "mistral nemo 2407 ()", "uri": "mistralai_Mistral-Nemo-Instruct-2407", "url": "https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407"}, "mistralai/Mixtral-8x22B-Instruct-v0.1": {"base_model": "Mixtral-8x22B-v0.1", "category": ["index-chat"], "date": "2024-04-17", "id": "mistralai/Mixtral-8x22B-Instruct-v0.1", "name": "Mixtral-8x22B-Instruct-v0.1", "params": 141, "radar": {"en_basic": {"id": "en_basic", "series": [0.45, 0.8274, 0.7078, 0.6763, 0.9196, 0.7739, 0.8324, 0.456, 0.8295, 0.7232], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9026, 0.4978, 0.4464, 0.9184, 0.2071, 0.696, 0.2333, 0.2316, 0.6018, 0.5884], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.591, 0.797, 0.606, 0.585, 0.557, 0.618, 0.565, 0.658], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 6, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7196}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 28, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.622}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 31, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5323}}, "results": {"en_basic": {"BBH": 0.8295, "En Avg": 0.7196, "GSM8K": 0.8324, "HellaSwag": 0.7078, "HumanEval": 0.7232, "MATH": 0.456, "MMLU": 0.7739, "OpenBookQA": 0.45, "SQuAD2": 0.6763, "TriviaQA": 0.8274, "XWINO": 0.9196}, "ja_basic": {"JComQA": 0.9026, "JEMHopQA": 0.4978, "JHumanEval": 0.5884, "JMMLU": 0.6018, "JSQuAD": 0.9184, "Ja Avg": 0.5323, "MGSM": 0.696, "NIILC": 0.4464, "WMT20-en-ja": 0.2333, "WMT20-ja-en": 0.2316, "XL-Sum": 0.2071}, "ja_mtb": {"JMT Avg": 0.622, "coding": 0.591, "extraction": 0.797, "humanities": 0.606, "math": 0.585, "reasoning": 0.557, "roleplay": 0.618, "stem": 0.565, "writing": 0.658}, "other": {"GPQA": 0.3348}}, "sortkey": "mixtral v0.1", "uri": "mistralai_Mixtral-8x22B-Instruct-v0.1", "url": "https://huggingface.co/mistralai/Mixtral-8x22B-Instruct-v0.1"}, "nvidia/Mistral-NeMo-Minitron-8B-Instruct": {"base_model": "Mistral-NeMo-Minitron 8B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-08-21", "id": "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "name": "Mistral-NeMo-Minitron 8B Instruct", "params": 8.4, "radar": {"en_basic": {"id": "en_basic", "series": [0.452, 0.7192, 0.6392, 0.6239, 0.9092, 0.7008, 0.7536, 0.274, 0.6632, 0.6006], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8919, 0.4979, 0.3801, 0.5781, 0, 0.556, 0.1992, 0.1927, 0.5103, 0.4963], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.547, 0.684, 0.649, 0.545, 0.454, 0.564, 0.549, 0.541], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 29, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6336}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 39, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.567}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 51, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4781}}, "results": {"en_basic": {"BBH": 0.6632, "En Avg": 0.6336, "GSM8K": 0.7536, "HellaSwag": 0.6392, "HumanEval": 0.6006, "MATH": 0.274, "MMLU": 0.7008, "OpenBookQA": 0.452, "SQuAD2": 0.6239, "TriviaQA": 0.7192, "XWINO": 0.9092}, "ja_basic": {"JComQA": 0.8919, "JEMHopQA": 0.4979, "JHumanEval": 0.4963, "JMMLU": 0.5103, "JSQuAD": 0.5781, "Ja Avg": 0.4781, "MGSM": 0.556, "NIILC": 0.3801, "WMT20-en-ja": 0.1992, "WMT20-ja-en": 0.1927, "XL-Sum": 0}, "ja_mtb": {"JMT Avg": 0.567, "coding": 0.547, "extraction": 0.684, "humanities": 0.649, "math": 0.545, "reasoning": 0.454, "roleplay": 0.564, "stem": 0.549, "writing": 0.541}, "other": {"GPQA": 0.2835}}, "sortkey": "mistral nemo minitron", "uri": "nvidia_Mistral-NeMo-Minitron-8B-Instruct", "url": "https://huggingface.co/nvidia/Mistral-NeMo-Minitron-8B-Instruct"}, "rinna/gemma-2-baku-2b-it": {"base_model": "Gemma 2 Baku 2B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-10-03", "id": "rinna/gemma-2-baku-2b-it", "name": "Gemma 2 Baku 2B IT", "params": 2.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.342, 0.416, 0.5107, 0.5219, 0.8705, 0.5259, 0.0265, 0.174, 0.0627, 0.1579], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.8552, 0.2278, 0.3899, 0.8773, 0.1148, 0.172, 0.2549, 0.1896, 0.4154, 0.1646], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.47, 0.625, 0.81, 0.414, 0.382, 0.713, 0.609, 0.697], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 100, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.3608}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 34, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.59}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 89, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3662}}, "results": {"en_basic": {"BBH": 0.0627, "En Avg": 0.3608, "GSM8K": 0.0265, "HellaSwag": 0.5107, "HumanEval": 0.1579, "MATH": 0.174, "MMLU": 0.5259, "OpenBookQA": 0.342, "SQuAD2": 0.5219, "TriviaQA": 0.416, "XWINO": 0.8705}, "ja_basic": {"JComQA": 0.8552, "JEMHopQA": 0.2278, "JHumanEval": 0.1646, "JMMLU": 0.4154, "JSQuAD": 0.8773, "Ja Avg": 0.3662, "MGSM": 0.172, "NIILC": 0.3899, "WMT20-en-ja": 0.2549, "WMT20-ja-en": 0.1896, "XL-Sum": 0.1148}, "ja_mtb": {"JMT Avg": 0.59, "coding": 0.47, "extraction": 0.625, "humanities": 0.81, "math": 0.414, "reasoning": 0.382, "roleplay": 0.713, "stem": 0.609, "writing": 0.697}, "other": {"GPQA": 0.0513}}, "sortkey": "gemma 2 baku", "uri": "rinna_gemma-2-baku-2b-it", "url": "https://huggingface.co/rinna/gemma-2-baku-2b-it"}, "rinna/llama-3-youko-70b-instruct": {"base_model": "Llama 3 Youko 70B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-07-25", "id": "rinna/llama-3-youko-70b-instruct", "name": "Llama 3 Youko 70B Instruct", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.454, 0.7969, 0.6861, 0.6591, 0.9153, 0.8054, 0.8923, 0.434, 0.7801, 0.6616], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9517, 0.6252, 0.5841, 0.9212, 0.198, 0.72, 0.2629, 0.2258, 0.7184, 0.6098], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.607, 0.894, 0.834, 0.609, 0.673, 0.79, 0.764, 0.829], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 13, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7085}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 14, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.75}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 17, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5817}}, "results": {"en_basic": {"BBH": 0.7801, "En Avg": 0.7085, "GSM8K": 0.8923, "HellaSwag": 0.6861, "HumanEval": 0.6616, "MATH": 0.434, "MMLU": 0.8054, "OpenBookQA": 0.454, "SQuAD2": 0.6591, "TriviaQA": 0.7969, "XWINO": 0.9153}, "ja_basic": {"JComQA": 0.9517, "JEMHopQA": 0.6252, "JHumanEval": 0.6098, "JMMLU": 0.7184, "JSQuAD": 0.9212, "Ja Avg": 0.5817, "MGSM": 0.72, "NIILC": 0.5841, "WMT20-en-ja": 0.2629, "WMT20-ja-en": 0.2258, "XL-Sum": 0.198}, "ja_mtb": {"JMT Avg": 0.75, "coding": 0.607, "extraction": 0.894, "humanities": 0.834, "math": 0.609, "reasoning": 0.673, "roleplay": 0.79, "stem": 0.764, "writing": 0.829}, "other": {"GPQA": 0.3036}}, "sortkey": "llama 3 youko", "uri": "rinna_llama-3-youko-70b-instruct", "url": "https://huggingface.co/rinna/llama-3-youko-70b-instruct"}, "rinna/llama-3-youko-8b-instruct": {"base_model": "Llama 3 Youko 8B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-05-07", "id": "rinna/llama-3-youko-8b-instruct", "name": "Llama 3 Youko 8B Instruct", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.406, 0.6125, 0.599, 0.5589, 0.8972, 0.5965, 0.5625, 0.152, 0.4015, 0.2866], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9205, 0.4813, 0.517, 0.8994, 0.2086, 0.472, 0.2562, 0.1907, 0.4685, 0.2616], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.464, 0.757, 0.769, 0.414, 0.487, 0.695, 0.583, 0.753], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 68, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5073}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 30, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.616}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 59, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4676}}, "results": {"en_basic": {"BBH": 0.4015, "En Avg": 0.5073, "GSM8K": 0.5625, "HellaSwag": 0.599, "HumanEval": 0.2866, "MATH": 0.152, "MMLU": 0.5965, "OpenBookQA": 0.406, "SQuAD2": 0.5589, "TriviaQA": 0.6125, "XWINO": 0.8972}, "ja_basic": {"JComQA": 0.9205, "JEMHopQA": 0.4813, "JHumanEval": 0.2616, "JMMLU": 0.4685, "JSQuAD": 0.8994, "Ja Avg": 0.4676, "MGSM": 0.472, "NIILC": 0.517, "WMT20-en-ja": 0.2562, "WMT20-ja-en": 0.1907, "XL-Sum": 0.2086}, "ja_mtb": {"JMT Avg": 0.616, "coding": 0.464, "extraction": 0.757, "humanities": 0.769, "math": 0.414, "reasoning": 0.487, "roleplay": 0.695, "stem": 0.583, "writing": 0.753}, "other": {"GPQA": 0.2902}}, "sortkey": "llama 3 youko", "uri": "rinna_llama-3-youko-8b-instruct", "url": "https://huggingface.co/rinna/llama-3-youko-8b-instruct"}, "tiiuae/Falcon3-10B-Instruct": {"base_model": "Falcon3-10B-Base", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-12-19", "id": "tiiuae/Falcon3-10B-Instruct", "name": "Falcon3-10B-Instruct", "params": 10, "radar": {"en_basic": {"id": "en_basic", "series": [0.424, 0.5035, 0.6398, 0.549, 0.8748, 0.7302, 0.793, 0.462, 0.7289, 0.6274], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.6899, 0.2207, 0.1222, 0.853, 0.1919, 0.392, 0.1077, 0.1354, 0.442, 0.5146], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.509, 0.545, 0.382, 0.48, 0.356, 0.335, 0.373, 0.324], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 30, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6333}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 55, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.413}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 88, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3669}}, "results": {"en_basic": {"BBH": 0.7289, "En Avg": 0.6333, "GSM8K": 0.793, "HellaSwag": 0.6398, "HumanEval": 0.6274, "MATH": 0.462, "MMLU": 0.7302, "OpenBookQA": 0.424, "SQuAD2": 0.549, "TriviaQA": 0.5035, "XWINO": 0.8748}, "ja_basic": {"JComQA": 0.6899, "JEMHopQA": 0.2207, "JHumanEval": 0.5146, "JMMLU": 0.442, "JSQuAD": 0.853, "Ja Avg": 0.3669, "MGSM": 0.392, "NIILC": 0.1222, "WMT20-en-ja": 0.1077, "WMT20-ja-en": 0.1354, "XL-Sum": 0.1919}, "ja_mtb": {"JMT Avg": 0.413, "coding": 0.509, "extraction": 0.545, "humanities": 0.382, "math": 0.48, "reasoning": 0.356, "roleplay": 0.335, "stem": 0.373, "writing": 0.324}, "other": {"GPQA": 0.3348}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-10B-Instruct", "url": "https://huggingface.co/tiiuae/Falcon3-10B-Instruct"}, "tiiuae/Falcon3-1B-Instruct": {"base_model": "Falcon3-1B-Base", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-12-19", "id": "tiiuae/Falcon3-1B-Instruct", "name": "Falcon3-1B-Instruct", "params": 1.7, "radar": {"en_basic": {"id": "en_basic", "series": [0.344, 0.2611, 0.4801, 0.5008, 0.8146, 0.4586, 0.3912, 0.13, 0.3301, 0.1006], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.2404, 0.3121, 0.1324, 0.4538, 0.101, 0.02, 0.0279, 0.032, 0.2807, 0.089], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.176, 0.178, 0.121, 0.161, 0.224, 0.154, 0.124, 0.148], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 95, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.3811}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 62, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.161}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 112, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.1689}}, "results": {"en_basic": {"BBH": 0.3301, "En Avg": 0.3811, "GSM8K": 0.3912, "HellaSwag": 0.4801, "HumanEval": 0.1006, "MATH": 0.13, "MMLU": 0.4586, "OpenBookQA": 0.344, "SQuAD2": 0.5008, "TriviaQA": 0.2611, "XWINO": 0.8146}, "ja_basic": {"JComQA": 0.2404, "JEMHopQA": 0.3121, "JHumanEval": 0.089, "JMMLU": 0.2807, "JSQuAD": 0.4538, "Ja Avg": 0.1689, "MGSM": 0.02, "NIILC": 0.1324, "WMT20-en-ja": 0.0279, "WMT20-ja-en": 0.032, "XL-Sum": 0.101}, "ja_mtb": {"JMT Avg": 0.161, "coding": 0.176, "extraction": 0.178, "humanities": 0.121, "math": 0.161, "reasoning": 0.224, "roleplay": 0.154, "stem": 0.124, "writing": 0.148}, "other": {"GPQA": 0.0134}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-1B-Instruct", "url": "https://huggingface.co/tiiuae/Falcon3-1B-Instruct"}, "tiiuae/Falcon3-3B-Instruct": {"base_model": "Falcon3-3B-Base", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-12-19", "id": "tiiuae/Falcon3-3B-Instruct", "name": "Falcon3-3B-Instruct", "params": 3.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.372, 0.2856, 0.5414, 0.5133, 0.8176, 0.5624, 0.7119, 0.44, 0.5617, 0.4537], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.4209, 0.1603, 0.1129, 0.6322, 0.1414, 0.092, 0.0615, 0.0584, 0.3313, 0.3079], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.329, 0.392, 0.219, 0.199, 0.267, 0.234, 0.229, 0.208], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 66, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.526}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 61, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.26}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 109, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.2319}}, "results": {"en_basic": {"BBH": 0.5617, "En Avg": 0.526, "GSM8K": 0.7119, "HellaSwag": 0.5414, "HumanEval": 0.4537, "MATH": 0.44, "MMLU": 0.5624, "OpenBookQA": 0.372, "SQuAD2": 0.5133, "TriviaQA": 0.2856, "XWINO": 0.8176}, "ja_basic": {"JComQA": 0.4209, "JEMHopQA": 0.1603, "JHumanEval": 0.3079, "JMMLU": 0.3313, "JSQuAD": 0.6322, "Ja Avg": 0.2319, "MGSM": 0.092, "NIILC": 0.1129, "WMT20-en-ja": 0.0615, "WMT20-ja-en": 0.0584, "XL-Sum": 0.1414}, "ja_mtb": {"JMT Avg": 0.26, "coding": 0.329, "extraction": 0.392, "humanities": 0.219, "math": 0.199, "reasoning": 0.267, "roleplay": 0.234, "stem": 0.229, "writing": 0.208}, "other": {"GPQA": 0.2076}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-3B-Instruct", "url": "https://huggingface.co/tiiuae/Falcon3-3B-Instruct"}, "tiiuae/Falcon3-7B-Instruct": {"base_model": "Falcon3-7B-Base", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-12-19", "id": "tiiuae/Falcon3-7B-Instruct", "name": "Falcon3-7B-Instruct", "params": 7.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.394, 0.5169, 0.6113, 0.5247, 0.8551, 0.705, 0.7733, 0.542, 0.7108, 0.5506], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.6836, 0.436, 0.1522, 0.8161, 0.1767, 0.32, 0.0936, 0.1256, 0.4149, 0.4165], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.549, 0.506, 0.34, 0.406, 0.257, 0.299, 0.34, 0.317], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 33, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.6184}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 58, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.377}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 90, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3635}}, "results": {"en_basic": {"BBH": 0.7108, "En Avg": 0.6184, "GSM8K": 0.7733, "HellaSwag": 0.6113, "HumanEval": 0.5506, "MATH": 0.542, "MMLU": 0.705, "OpenBookQA": 0.394, "SQuAD2": 0.5247, "TriviaQA": 0.5169, "XWINO": 0.8551}, "ja_basic": {"JComQA": 0.6836, "JEMHopQA": 0.436, "JHumanEval": 0.4165, "JMMLU": 0.4149, "JSQuAD": 0.8161, "Ja Avg": 0.3635, "MGSM": 0.32, "NIILC": 0.1522, "WMT20-en-ja": 0.0936, "WMT20-ja-en": 0.1256, "XL-Sum": 0.1767}, "ja_mtb": {"JMT Avg": 0.377, "coding": 0.549, "extraction": 0.506, "humanities": 0.34, "math": 0.406, "reasoning": 0.257, "roleplay": 0.299, "stem": 0.34, "writing": 0.317}, "other": {"GPQA": 0.2768}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-7B-Instruct", "url": "https://huggingface.co/tiiuae/Falcon3-7B-Instruct"}, "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1": {"base_model": "Llama 3 Swallow 70B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-07-01", "id": "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "name": "Llama 3 Swallow 70B Instruct", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.446, 0.8181, 0.6757, 0.6815, 0.923, 0.7892, 0.8681, 0.46, 0.8162, 0.6799], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9625, 0.6271, 0.5984, 0.9206, 0.1389, 0.672, 0.2715, 0.2547, 0.6572, 0.6079], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.633, 0.823, 0.601, 0.521, 0.482, 0.622, 0.635, 0.63], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 7, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7158}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 29, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.618}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 22, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5711}}, "results": {"en_basic": {"BBH": 0.8162, "En Avg": 0.7158, "GSM8K": 0.8681, "HellaSwag": 0.6757, "HumanEval": 0.6799, "MATH": 0.46, "MMLU": 0.7892, "OpenBookQA": 0.446, "SQuAD2": 0.6815, "TriviaQA": 0.8181, "XWINO": 0.923}, "ja_basic": {"JComQA": 0.9625, "JEMHopQA": 0.6271, "JHumanEval": 0.6079, "JMMLU": 0.6572, "JSQuAD": 0.9206, "Ja Avg": 0.5711, "MGSM": 0.672, "NIILC": 0.5984, "WMT20-en-ja": 0.2715, "WMT20-ja-en": 0.2547, "XL-Sum": 0.1389}, "ja_mtb": {"JMT Avg": 0.618, "coding": 0.633, "extraction": 0.823, "humanities": 0.601, "math": 0.521, "reasoning": 0.482, "roleplay": 0.622, "stem": 0.635, "writing": 0.63}, "other": {"GPQA": 0.3571}}, "sortkey": "llama 3 swallow", "uri": "tokyotech-llm_Llama-3-Swallow-70B-Instruct-v0.1", "url": "https://huggingface.co/tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1"}, "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1": {"base_model": "Llama 3 Swallow 8B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-07-01", "id": "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "name": "Llama 3 Swallow 8B Instruct", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.37, 0.6554, 0.5854, 0.5672, 0.8994, 0.6331, 0.5921, 0.244, 0.6388, 0.4195], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9115, 0.4959, 0.5174, 0.9052, 0.1283, 0.492, 0.2531, 0.2274, 0.4807, 0.3939], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.411, 0.575, 0.476, 0.309, 0.305, 0.499, 0.438, 0.406], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 51, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5605}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 53, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.427}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 50, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4805}}, "results": {"en_basic": {"BBH": 0.6388, "En Avg": 0.5605, "GSM8K": 0.5921, "HellaSwag": 0.5854, "HumanEval": 0.4195, "MATH": 0.244, "MMLU": 0.6331, "OpenBookQA": 0.37, "SQuAD2": 0.5672, "TriviaQA": 0.6554, "XWINO": 0.8994}, "ja_basic": {"JComQA": 0.9115, "JEMHopQA": 0.4959, "JHumanEval": 0.3939, "JMMLU": 0.4807, "JSQuAD": 0.9052, "Ja Avg": 0.4805, "MGSM": 0.492, "NIILC": 0.5174, "WMT20-en-ja": 0.2531, "WMT20-ja-en": 0.2274, "XL-Sum": 0.1283}, "ja_mtb": {"JMT Avg": 0.427, "coding": 0.411, "extraction": 0.575, "humanities": 0.476, "math": 0.309, "reasoning": 0.305, "roleplay": 0.499, "stem": 0.438, "writing": 0.406}, "other": {"GPQA": 0.2567}}, "sortkey": "llama 3 swallow", "uri": "tokyotech-llm_Llama-3-Swallow-8B-Instruct-v0.1", "url": "https://huggingface.co/tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1"}, "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1": {"base_model": "Llama 3.1 Swallow 70B v0.1", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-10-08", "id": "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "name": "Llama 3.1 Swallow 70B Instruct v0.1", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.446, 0.8149, 0.6831, 0.6807, 0.9166, 0.7868, 0.884, 0.474, 0.8481, 0.5683], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9616, 0.6206, 0.6601, 0.9238, 0.1922, 0.776, 0.3119, 0.259, 0.7108, 0.4677], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.654, 0.792, 0.768, 0.704, 0.573, 0.682, 0.653, 0.704], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 10, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7102}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 20, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.691}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 16, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5884}}, "results": {"en_basic": {"BBH": 0.8481, "En Avg": 0.7102, "GSM8K": 0.884, "HellaSwag": 0.6831, "HumanEval": 0.5683, "MATH": 0.474, "MMLU": 0.7868, "OpenBookQA": 0.446, "SQuAD2": 0.6807, "TriviaQA": 0.8149, "XWINO": 0.9166}, "ja_basic": {"JComQA": 0.9616, "JEMHopQA": 0.6206, "JHumanEval": 0.4677, "JMMLU": 0.7108, "JSQuAD": 0.9238, "Ja Avg": 0.5884, "MGSM": 0.776, "NIILC": 0.6601, "WMT20-en-ja": 0.3119, "WMT20-ja-en": 0.259, "XL-Sum": 0.1922}, "ja_mtb": {"JMT Avg": 0.691, "coding": 0.654, "extraction": 0.792, "humanities": 0.768, "math": 0.704, "reasoning": 0.573, "roleplay": 0.682, "stem": 0.653, "writing": 0.704}, "other": {"GPQA": 0.3951}}, "sortkey": "llama 3.1 swallow v0.1", "uri": "tokyotech-llm_Llama-3.1-Swallow-70B-Instruct-v0.1", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1"}, "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3": {"base_model": "Llama 3.1 Swallow 70B v0.1", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-12-30", "id": "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "name": "Llama 3.1 Swallow 70B Instruct v0.3", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.454, 0.8246, 0.6917, 0.6469, 0.9191, 0.7768, 0.8719, 0.458, 0.816, 0.6427], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9643, 0.6322, 0.6539, 0.9105, 0.1956, 0.772, 0.3052, 0.2572, 0.6899, 0.5957], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.678, 0.82, 0.867, 0.776, 0.57, 0.816, 0.769, 0.852], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 10, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7102}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 8, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.769}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 10, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5977}}, "results": {"en_basic": {"BBH": 0.816, "En Avg": 0.7102, "GSM8K": 0.8719, "HellaSwag": 0.6917, "HumanEval": 0.6427, "MATH": 0.458, "MMLU": 0.7768, "OpenBookQA": 0.454, "SQuAD2": 0.6469, "TriviaQA": 0.8246, "XWINO": 0.9191}, "ja_basic": {"JComQA": 0.9643, "JEMHopQA": 0.6322, "JHumanEval": 0.5957, "JMMLU": 0.6899, "JSQuAD": 0.9105, "Ja Avg": 0.5977, "MGSM": 0.772, "NIILC": 0.6539, "WMT20-en-ja": 0.3052, "WMT20-ja-en": 0.2572, "XL-Sum": 0.1956}, "ja_mtb": {"JMT Avg": 0.769, "coding": 0.678, "extraction": 0.82, "humanities": 0.867, "math": 0.776, "reasoning": 0.57, "roleplay": 0.816, "stem": 0.769, "writing": 0.852}, "other": {"GPQA": 0.2589}}, "sortkey": "llama 3.1 swallow v0.3", "uri": "tokyotech-llm_Llama-3.1-Swallow-70B-Instruct-v0.3", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3"}, "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1": {"base_model": "Llama 3.1 Swallow 8B v0.1", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-10-08", "id": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "name": "Llama 3.1 Swallow 8B Instruct v0.1", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.388, 0.6488, 0.6153, 0.5978, 0.8912, 0.6238, 0.605, 0.236, 0.6417, 0.3787], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.924, 0.5874, 0.5736, 0.917, 0.138, 0.508, 0.282, 0.2282, 0.5301, 0.3665], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.427, 0.738, 0.675, 0.527, 0.453, 0.615, 0.593, 0.624], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 50, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5626}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 37, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.581}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 40, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5055}}, "results": {"en_basic": {"BBH": 0.6417, "En Avg": 0.5626, "GSM8K": 0.605, "HellaSwag": 0.6153, "HumanEval": 0.3787, "MATH": 0.236, "MMLU": 0.6238, "OpenBookQA": 0.388, "SQuAD2": 0.5978, "TriviaQA": 0.6488, "XWINO": 0.8912}, "ja_basic": {"JComQA": 0.924, "JEMHopQA": 0.5874, "JHumanEval": 0.3665, "JMMLU": 0.5301, "JSQuAD": 0.917, "Ja Avg": 0.5055, "MGSM": 0.508, "NIILC": 0.5736, "WMT20-en-ja": 0.282, "WMT20-ja-en": 0.2282, "XL-Sum": 0.138}, "ja_mtb": {"JMT Avg": 0.581, "coding": 0.427, "extraction": 0.738, "humanities": 0.675, "math": 0.527, "reasoning": 0.453, "roleplay": 0.615, "stem": 0.593, "writing": 0.624}, "other": {"GPQA": 0.2813}}, "sortkey": "llama 3.1 swallow v0.1", "uri": "tokyotech-llm_Llama-3.1-Swallow-8B-Instruct-v0.1", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1"}, "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2": {"base_model": "Llama 3.1 Swallow 8B v0.2", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-11-11", "id": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "name": "Llama 3.1 Swallow 8B Instruct v0.2", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.38, 0.6252, 0.6034, 0.6066, 0.8873, 0.6343, 0.6202, 0.264, 0.6487, 0.4738], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9294, 0.5601, 0.5988, 0.9148, 0.1372, 0.528, 0.2878, 0.227, 0.5504, 0.4079], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.534, 0.748, 0.705, 0.565, 0.475, 0.646, 0.579, 0.646], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 47, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5743}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 32, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.612}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 35, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5141}}, "results": {"en_basic": {"BBH": 0.6487, "En Avg": 0.5743, "GSM8K": 0.6202, "HellaSwag": 0.6034, "HumanEval": 0.4738, "MATH": 0.264, "MMLU": 0.6343, "OpenBookQA": 0.38, "SQuAD2": 0.6066, "TriviaQA": 0.6252, "XWINO": 0.8873}, "ja_basic": {"JComQA": 0.9294, "JEMHopQA": 0.5601, "JHumanEval": 0.4079, "JMMLU": 0.5504, "JSQuAD": 0.9148, "Ja Avg": 0.5141, "MGSM": 0.528, "NIILC": 0.5988, "WMT20-en-ja": 0.2878, "WMT20-ja-en": 0.227, "XL-Sum": 0.1372}, "ja_mtb": {"JMT Avg": 0.612, "coding": 0.534, "extraction": 0.748, "humanities": 0.705, "math": 0.565, "reasoning": 0.475, "roleplay": 0.646, "stem": 0.579, "writing": 0.646}, "other": {"GPQA": 0.3013}}, "sortkey": "llama 3.1 swallow v0.2", "uri": "tokyotech-llm_Llama-3.1-Swallow-8B-Instruct-v0.2", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2"}, "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3": {"base_model": "Llama 3.1 Swallow 8B v0.2", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-12-23", "id": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "name": "Llama 3.1 Swallow 8B Instruct v0.3", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.396, 0.6291, 0.5933, 0.5698, 0.8843, 0.6293, 0.6224, 0.266, 0.6263, 0.4451], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.924, 0.5278, 0.5825, 0.8956, 0.1909, 0.532, 0.2809, 0.2287, 0.5445, 0.3939], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.562, 0.756, 0.869, 0.61, 0.512, 0.783, 0.748, 0.803], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 49, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5662}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 19, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.705}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 38, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5101}}, "results": {"en_basic": {"BBH": 0.6263, "En Avg": 0.5662, "GSM8K": 0.6224, "HellaSwag": 0.5933, "HumanEval": 0.4451, "MATH": 0.266, "MMLU": 0.6293, "OpenBookQA": 0.396, "SQuAD2": 0.5698, "TriviaQA": 0.6291, "XWINO": 0.8843}, "ja_basic": {"JComQA": 0.924, "JEMHopQA": 0.5278, "JHumanEval": 0.3939, "JMMLU": 0.5445, "JSQuAD": 0.8956, "Ja Avg": 0.5101, "MGSM": 0.532, "NIILC": 0.5825, "WMT20-en-ja": 0.2809, "WMT20-ja-en": 0.2287, "XL-Sum": 0.1909}, "ja_mtb": {"JMT Avg": 0.705, "coding": 0.562, "extraction": 0.756, "humanities": 0.869, "math": 0.61, "reasoning": 0.512, "roleplay": 0.783, "stem": 0.748, "writing": 0.803}, "other": {"GPQA": 0.2009}}, "sortkey": "llama 3.1 swallow v0.3", "uri": "tokyotech-llm_Llama-3.1-Swallow-8B-Instruct-v0.3", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3"}, "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500": {"base_model": "Llama 3.3 Swallow 70B v0.4", "category": ["index-chat", "category-15b-100b-chat"], "date": "2025-03-10", "id": "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "name": "Llama 3.3 Swallow 70B Instruct v0.4", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.448, 0.8171, 0.6859, 0.6539, 0.9123, 0.8028, 0.9075, 0.566, 0.8123, 0.75], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9812, 0.6182, 0.662, 0.9067, 0.162, 0.812, 0.3191, 0.2605, 0.7074, 0.7], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.705, 0.82, 0.87, 0.73, 0.623, 0.811, 0.781, 0.832], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 3, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7356}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 7, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.772}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 7, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.6129}}, "results": {"en_basic": {"BBH": 0.8123, "En Avg": 0.7356, "GSM8K": 0.9075, "HellaSwag": 0.6859, "HumanEval": 0.75, "MATH": 0.566, "MMLU": 0.8028, "OpenBookQA": 0.448, "SQuAD2": 0.6539, "TriviaQA": 0.8171, "XWINO": 0.9123}, "ja_basic": {"JComQA": 0.9812, "JEMHopQA": 0.6182, "JHumanEval": 0.7, "JMMLU": 0.7074, "JSQuAD": 0.9067, "Ja Avg": 0.6129, "MGSM": 0.812, "NIILC": 0.662, "WMT20-en-ja": 0.3191, "WMT20-ja-en": 0.2605, "XL-Sum": 0.162}, "ja_mtb": {"JMT Avg": 0.772, "coding": 0.705, "extraction": 0.82, "humanities": 0.87, "math": 0.73, "reasoning": 0.623, "roleplay": 0.811, "stem": 0.781, "writing": 0.832}, "other": {"GPQA": 0.4018}}, "sortkey": "llama 3.3 swallow v0.4", "uri": "tokyotech-llm_Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "url": "https://huggingface.co/tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500"}, "tokyotech-llm/Swallow-70b-instruct-v0.1": {"base_model": "Swallow 70B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2023-12-19", "id": "tokyotech-llm/Swallow-70b-instruct-v0.1", "name": "Swallow-70b-instruct-v0.1", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.446, 0.7422, 0.6557, 0.5705, 0.9166, 0.6679, 0.5095, 0.108, 0.6643, 0.2805], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9231, 0.566, 0.5654, 0.9034, 0.1865, 0.42, 0.2629, 0.232, 0.571, 0.2927], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.381, 0.604, 0.568, 0.464, 0.402, 0.583, 0.557, 0.51], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 53, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5561}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 47, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.509}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 46, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4923}}, "results": {"en_basic": {"BBH": 0.6643, "En Avg": 0.5561, "GSM8K": 0.5095, "HellaSwag": 0.6557, "HumanEval": 0.2805, "MATH": 0.108, "MMLU": 0.6679, "OpenBookQA": 0.446, "SQuAD2": 0.5705, "TriviaQA": 0.7422, "XWINO": 0.9166}, "ja_basic": {"JComQA": 0.9231, "JEMHopQA": 0.566, "JHumanEval": 0.2927, "JMMLU": 0.571, "JSQuAD": 0.9034, "Ja Avg": 0.4923, "MGSM": 0.42, "NIILC": 0.5654, "WMT20-en-ja": 0.2629, "WMT20-ja-en": 0.232, "XL-Sum": 0.1865}, "ja_mtb": {"JMT Avg": 0.509, "coding": 0.381, "extraction": 0.604, "humanities": 0.568, "math": 0.464, "reasoning": 0.402, "roleplay": 0.583, "stem": 0.557, "writing": 0.51}, "other": {"GPQA": 0.2679}}, "sortkey": "swallow v0.1", "uri": "tokyotech-llm_Swallow-70b-instruct-v0.1", "url": "https://huggingface.co/tokyotech-llm/Swallow-70b-instruct-v0.1"}, "tokyotech-llm/Swallow-7b-instruct-v0.1": {"base_model": "Swallow 7B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2023-12-19", "id": "tokyotech-llm/Swallow-7b-instruct-v0.1", "name": "Swallow-7b-instruct-v0.1", "params": 6.7, "radar": {"en_basic": {"id": "en_basic", "series": [0.33, 0.4806, 0.5502, 0.5009, 0.8796, 0.4074, 0.1236, 0.034, 0.3594, 0.0939], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.5987, 0.4913, 0.5314, 0.8374, 0.1532, 0.128, 0.2283, 0.1789, 0.3522, 0.0274], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.324, 0.401, 0.519, 0.275, 0.344, 0.535, 0.494, 0.462], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 97, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.3759}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 54, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.419}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 94, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3527}}, "results": {"en_basic": {"BBH": 0.3594, "En Avg": 0.3759, "GSM8K": 0.1236, "HellaSwag": 0.5502, "HumanEval": 0.0939, "MATH": 0.034, "MMLU": 0.4074, "OpenBookQA": 0.33, "SQuAD2": 0.5009, "TriviaQA": 0.4806, "XWINO": 0.8796}, "ja_basic": {"JComQA": 0.5987, "JEMHopQA": 0.4913, "JHumanEval": 0.0274, "JMMLU": 0.3522, "JSQuAD": 0.8374, "Ja Avg": 0.3527, "MGSM": 0.128, "NIILC": 0.5314, "WMT20-en-ja": 0.2283, "WMT20-ja-en": 0.1789, "XL-Sum": 0.1532}, "ja_mtb": {"JMT Avg": 0.419, "coding": 0.324, "extraction": 0.401, "humanities": 0.519, "math": 0.275, "reasoning": 0.344, "roleplay": 0.535, "stem": 0.494, "writing": 0.462}, "other": {"GPQA": 0.1183}}, "sortkey": "swallow v0.1", "uri": "tokyotech-llm_Swallow-7b-instruct-v0.1", "url": "https://huggingface.co/tokyotech-llm/Swallow-7b-instruct-v0.1"}, "tokyotech-llm/Swallow-MS-7b-instruct-v0.1": {"base_model": "Swallow-MS 7B v0.1", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-03-11", "id": "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "name": "Swallow-MS-7b-instruct-v0.1", "params": 7.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.36, 0.5003, 0.5865, 0.51, 0.886, 0.5259, 0.2146, 0.082, 0.4411, 0.2555], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.7578, 0.4902, 0.4464, 0.8635, 0.1578, 0.172, 0.2272, 0.1872, 0.4194, 0.2146], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.358, 0.421, 0.501, 0.222, 0.349, 0.458, 0.444, 0.449], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 83, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4362}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 57, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.4}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 78, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.3936}}, "results": {"en_basic": {"BBH": 0.4411, "En Avg": 0.4362, "GSM8K": 0.2146, "HellaSwag": 0.5865, "HumanEval": 0.2555, "MATH": 0.082, "MMLU": 0.5259, "OpenBookQA": 0.36, "SQuAD2": 0.51, "TriviaQA": 0.5003, "XWINO": 0.886}, "ja_basic": {"JComQA": 0.7578, "JEMHopQA": 0.4902, "JHumanEval": 0.2146, "JMMLU": 0.4194, "JSQuAD": 0.8635, "Ja Avg": 0.3936, "MGSM": 0.172, "NIILC": 0.4464, "WMT20-en-ja": 0.2272, "WMT20-ja-en": 0.1872, "XL-Sum": 0.1578}, "ja_mtb": {"JMT Avg": 0.4, "coding": 0.358, "extraction": 0.421, "humanities": 0.501, "math": 0.222, "reasoning": 0.349, "roleplay": 0.458, "stem": 0.444, "writing": 0.449}, "other": {"GPQA": 0.2009}}, "sortkey": "swallow ms v0.1", "uri": "tokyotech-llm_Swallow-MS-7b-instruct-v0.1", "url": "https://huggingface.co/tokyotech-llm/Swallow-MS-7b-instruct-v0.1"}, "turing-motors/Llama-3-heron-brain-70B-v0.3": {"base_model": "Llama 3 Swallow 70B", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-07-01", "id": "turing-motors/Llama-3-heron-brain-70B-v0.3", "name": "Llama 3 heron brain 70B v0.3", "params": 70, "radar": {"en_basic": {"id": "en_basic", "series": [0.446, 0.8107, 0.6679, 0.7056, 0.9191, 0.7896, 0.8772, 0.508, 0.7586, 0.6683], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9651, 0.652, 0.6792, 0.9224, 0.2611, 0.772, 0.3093, 0.2578, 0.7069, 0.6226], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.51, 0.87, 0.776, 0.68, 0.513, 0.727, 0.692, 0.693], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 8, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.7151}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 23, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.683}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 6, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.6148}}, "results": {"en_basic": {"BBH": 0.7586, "En Avg": 0.7151, "GSM8K": 0.8772, "HellaSwag": 0.6679, "HumanEval": 0.6683, "MATH": 0.508, "MMLU": 0.7896, "OpenBookQA": 0.446, "SQuAD2": 0.7056, "TriviaQA": 0.8107, "XWINO": 0.9191}, "ja_basic": {"JComQA": 0.9651, "JEMHopQA": 0.652, "JHumanEval": 0.6226, "JMMLU": 0.7069, "JSQuAD": 0.9224, "Ja Avg": 0.6148, "MGSM": 0.772, "NIILC": 0.6792, "WMT20-en-ja": 0.3093, "WMT20-ja-en": 0.2578, "XL-Sum": 0.2611}, "ja_mtb": {"JMT Avg": 0.683, "coding": 0.51, "extraction": 0.87, "humanities": 0.776, "math": 0.68, "reasoning": 0.513, "roleplay": 0.727, "stem": 0.692, "writing": 0.693}, "other": {"GPQA": 0.346}}, "sortkey": "llama 3 heron brain v0.3", "uri": "turing-motors_Llama-3-heron-brain-70B-v0.3", "url": "https://huggingface.co/turing-motors/Llama-3-heron-brain-70B-v0.3"}, "turing-motors/Llama-3-heron-brain-8B-v0.3": {"base_model": "Llama 3 Swallow 8B", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-07-01", "id": "turing-motors/Llama-3-heron-brain-8B-v0.3", "name": "Llama 3 heron brain 8B v0.3", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.362, 0.6563, 0.5688, 0.5807, 0.9006, 0.6215, 0.5777, 0.222, 0.6409, 0.3805], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.9231, 0.4933, 0.5694, 0.9056, 0.2178, 0.456, 0.2771, 0.2168, 0.4993, 0.3183], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.362, 0.566, 0.602, 0.315, 0.426, 0.586, 0.567, 0.55], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 54, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.5511}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 48, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.497}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 48, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4877}}, "results": {"en_basic": {"BBH": 0.6409, "En Avg": 0.5511, "GSM8K": 0.5777, "HellaSwag": 0.5688, "HumanEval": 0.3805, "MATH": 0.222, "MMLU": 0.6215, "OpenBookQA": 0.362, "SQuAD2": 0.5807, "TriviaQA": 0.6563, "XWINO": 0.9006}, "ja_basic": {"JComQA": 0.9231, "JEMHopQA": 0.4933, "JHumanEval": 0.3183, "JMMLU": 0.4993, "JSQuAD": 0.9056, "Ja Avg": 0.4877, "MGSM": 0.456, "NIILC": 0.5694, "WMT20-en-ja": 0.2771, "WMT20-ja-en": 0.2168, "XL-Sum": 0.2178}, "ja_mtb": {"JMT Avg": 0.497, "coding": 0.362, "extraction": 0.566, "humanities": 0.602, "math": 0.315, "reasoning": 0.426, "roleplay": 0.586, "stem": 0.567, "writing": 0.55}, "other": {"GPQA": 0.0}}, "sortkey": "llama 3 heron brain v0.3", "uri": "turing-motors_Llama-3-heron-brain-8B-v0.3", "url": "https://huggingface.co/turing-motors/Llama-3-heron-brain-8B-v0.3"}, "weblab-GENIAC/Tanuki-8B-dpo-v1.0": {"base_model": "(private)", "category": ["index-chat", "category-5b-15b-chat"], "date": "2024-08-30", "id": "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "name": "Tanuki-8B-dpo-v1.0", "params": 7.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.334, 0.2835, 0.4685, 0.5009, 0.8159, 0.3768, 0.4867, 0.178, 0.3325, 0.2878], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.2779, 0.2843, 0.3699, 0.6702, 0.1018, 0.428, 0.2385, 0.1829, 0.3056, 0.2506], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.461, 0.597, 0.562, 0.495, 0.377, 0.589, 0.509, 0.643], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 91, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4065}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 43, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.529}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 100, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.311}}, "results": {"en_basic": {"BBH": 0.3325, "En Avg": 0.4065, "GSM8K": 0.4867, "HellaSwag": 0.4685, "HumanEval": 0.2878, "MATH": 0.178, "MMLU": 0.3768, "OpenBookQA": 0.334, "SQuAD2": 0.5009, "TriviaQA": 0.2835, "XWINO": 0.8159}, "ja_basic": {"JComQA": 0.2779, "JEMHopQA": 0.2843, "JHumanEval": 0.2506, "JMMLU": 0.3056, "JSQuAD": 0.6702, "Ja Avg": 0.311, "MGSM": 0.428, "NIILC": 0.3699, "WMT20-en-ja": 0.2385, "WMT20-ja-en": 0.1829, "XL-Sum": 0.1018}, "ja_mtb": {"JMT Avg": 0.529, "coding": 0.461, "extraction": 0.597, "humanities": 0.562, "math": 0.495, "reasoning": 0.377, "roleplay": 0.589, "stem": 0.509, "writing": 0.643}, "other": {"GPQA": 0.1362}}, "sortkey": "tanuki dpo v1.0", "uri": "weblab-GENIAC_Tanuki-8B-dpo-v1.0", "url": "https://huggingface.co/weblab-GENIAC/Tanuki-8B-dpo-v1.0"}, "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0": {"base_model": "(private)", "category": ["index-chat", "category-15b-100b-chat"], "date": "2024-08-30", "id": "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "name": "Tanuki-8x8B-dpo-v1.0", "params": 47, "radar": {"en_basic": {"id": "en_basic", "series": [0.348, 0.4811, 0.5548, 0.5214, 0.8499, 0.4934, 0.5444, 0.236, 0.4191, 0.1927], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"id": "ja_basic", "series": [0.7078, 0.5509, 0.612, 0.8673, 0.1421, 0.456, 0.2692, 0.2082, 0.4394, 0.2841], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"id": "ja_mtb", "series": [0.513, 0.489, 0.624, 0.557, 0.445, 0.604, 0.547, 0.594], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "\u65e5\u672c\u8a9e MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 79, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.6336, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.4641}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "Qwen/Qwen2.5-32B-Instruct", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 Swallow 70B Instruct v0.4", "Qwen2.5-32B-Instruct", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 42, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.736, 0.737, 0.75, 0.751, 0.756, 0.762, 0.768, 0.769, 0.769, 0.772, 0.809, 0.824, 0.835, 0.837, 0.848, 0.848], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.546}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 61, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4781, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.4537}}, "results": {"en_basic": {"BBH": 0.4191, "En Avg": 0.4641, "GSM8K": 0.5444, "HellaSwag": 0.5548, "HumanEval": 0.1927, "MATH": 0.236, "MMLU": 0.4934, "OpenBookQA": 0.348, "SQuAD2": 0.5214, "TriviaQA": 0.4811, "XWINO": 0.8499}, "ja_basic": {"JComQA": 0.7078, "JEMHopQA": 0.5509, "JHumanEval": 0.2841, "JMMLU": 0.4394, "JSQuAD": 0.8673, "Ja Avg": 0.4537, "MGSM": 0.456, "NIILC": 0.612, "WMT20-en-ja": 0.2692, "WMT20-ja-en": 0.2082, "XL-Sum": 0.1421}, "ja_mtb": {"JMT Avg": 0.546, "coding": 0.513, "extraction": 0.489, "humanities": 0.624, "math": 0.557, "reasoning": 0.445, "roleplay": 0.604, "stem": 0.547, "writing": 0.594}, "other": {"GPQA": 0.1585}}, "sortkey": "tanuki dpo v1.0", "uri": "weblab-GENIAC_Tanuki-8x8B-dpo-v1.0", "url": "https://huggingface.co/weblab-GENIAC/Tanuki-8x8B-dpo-v1.0"}};
var g_taskcats = {"en_basic": {"category": "\u82f1", "description": "\u8cea\u554f\u5fdc\u7b54\u3084\u8aad\u89e3\u3001\u8a66\u9a13\u554f\u984c\u3067\u8a00\u8a9e\u7406\u89e3\u3084\u5e38\u8b58\u7684\u77e5\u8b58\u3001\u8981\u7d04\u3067\u8a00\u8a9e\u751f\u6210\u3001\u30b3\u30fc\u30c9\u751f\u6210\u3084\u6570\u5b66\u3067\u8ad6\u7406\u63a8\u8ad6\u306e\u80fd\u529b\u3092\u6e2c\u5b9a\u3057\u307e\u3059\u3002\u8a55\u4fa1\u30b9\u30b3\u30a2\u306f0 (\u6700\u4f4e) \u304b\u30891 (\u6700\u9ad8) \u307e\u3067\u306e\u7bc4\u56f2\u306e\u5024\u3092\u3068\u308a\u307e\u3059\u3002", "for": ["base", "inst"], "tasks": {"BBH": {"description": "BIG-Bench\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 (Srivastava et al., 2023) \u306e\u4e2d\u3067\u3082\u96e3\u6613\u5ea6\u306e\u9ad8\u304423\u4ef6\u306e\u30bf\u30b9\u30af", "link": {"author": "Suzgun et al.", "href": "https://aclanthology.org/2023.findings-acl.824/", "year": "2023"}, "metric": "\u6b63\u89e3\u7387, \u5b8c\u5168\u4e00\u81f4", "name": "BBH", "setting": "3-shot, CoT", "short": "BBH", "subtitle": "LLM\u306b\u3068\u3063\u3066\u96e3\u3057\u3044\u30bf\u30b9\u30af\u306e\u30b3\u30ec\u30af\u30b7\u30e7\u30f3", "title": "BIG-Bench-Hard (BBH)"}, "En Avg": {"collective": true, "description": "\u82f1\u8a9e\u306e\u7406\u89e3\u30fb\u751f\u6210\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "metric": "\u5e73\u5747", "name": "En Avg", "setting": "MBPP, GPQA\u306f\u9664\u304f", "short": "En avg", "subtitle": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210\u5e73\u5747", "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210\u5e73\u5747"}, "GSM8K": {"description": "\u5c0f\u5b66\u6821\u306e\u6570\u5b66\u306e\u6587\u7ae0\u984c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8", "link": {"author": "Cobbe et al.", "href": "https://arxiv.org/abs/2110.14168", "year": "2021"}, "metric": "\u6b63\u89e3\u7387, \u5b8c\u5168\u4e00\u81f4", "name": "GSM8K", "setting": "4-shot", "short": "GSM8K", "subtitle": "\u6570\u5b66\uff08\u7b97\u6570\uff09", "title": "GSM8K"}, "HellaSwag": {"description": "\u6b21\u306b\u8d77\u3053\u308b\u51fa\u6765\u4e8b\u3092\u4e88\u6e2c\u3059\u308b4\u629e\u306e\u9078\u629e\u5f0f\u554f\u984c", "link": {"author": "Zellers et al.", "href": "https://aclanthology.org/P19-1472/", "year": "2019"}, "metric": "\u6b63\u89e3\u7387", "name": "HellaSwag", "setting": "4-shot", "short": "HellaSwag", "subtitle": "\u5e38\u8b58\u63a8\u8ad6", "title": "HellaSwag"}, "HumanEval": {"description": "\u5358\u4f53\u30c6\u30b9\u30c8\u306b\u3088\u308b\u30b3\u30fc\u30c9\u751f\u6210\u80fd\u529b\u306e\u8a55\u4fa1", "link": {"author": "Chen et al.", "href": "https://arxiv.org/abs/2107.03374", "year": "2021"}, "metric": "pass@1", "name": "HumanEval", "setting": "0-shot, 10\u56de\u8a66\u884c", "short": "HumanEval", "subtitle": "\u30b3\u30fc\u30c9\u751f\u6210", "title": "HumanEval"}, "MATH": {"description": "\u9ad8\u6821\u751f\u5411\u3051\u6570\u5b66\u30b3\u30f3\u30c6\u30b9\u30c8", "link": {"author": "Hendrycks et al.", "href": "https://arxiv.org/abs/2103.03874", "year": "2021"}, "metric": "\u6b63\u89e3\u7387, \u5b8c\u5168\u4e00\u81f4", "name": "MATH", "setting": "4-shot", "short": "MATH", "subtitle": "\u6570\u5b66", "title": "MATH"}, "MMLU": {"description": "57\u79d1\u76ee\u304b\u3089\u306a\u308b4\u5024\u9078\u629e\u5f0f\u306e\u8a66\u9a13\u554f\u984c", "link": {"author": "Hendrycks et al.", "href": "https://openreview.net/forum?id=d7KBjmI3GmQ", "year": "2021"}, "metric": "\u6b63\u89e3\u7387", "name": "MMLU", "setting": "5-shot", "short": "MMLU", "subtitle": "\u30de\u30eb\u30c1\u30bf\u30b9\u30af\u8a00\u8a9e\u7406\u89e3", "title": "MMLU"}, "OpenBookQA": {"description": "\u79d1\u5b66\u7684\u306a\u77e5\u8b58\u3068\u5e38\u8b58\u306b\u57fa\u3065\u304f4\u629e\u306e\u9078\u629e\u5f0f\u554f\u984c", "link": {"author": "Mihaylov et al.", "href": "https://aclanthology.org/D18-1260/", "year": "2018"}, "metric": "\u6b63\u89e3\u7387", "name": "OpenBookQA", "setting": "4-shot", "short": "OpenBookQA", "subtitle": "\u4e8b\u5b9f\u3068\u5e38\u8b58\u306b\u57fa\u3065\u304f\u8cea\u554f\u5fdc\u7b54", "title": "OpenBookQA"}, "SQuAD2": {"description": "\u6839\u62e0\u6587\u66f8\u306b\u5bfe\u3057\u3066\u4f5c\u6210\u3055\u308c\u305f\u81ea\u7531\u8a18\u8ff0\u5f0f\u8cea\u554f\u5fdc\u7b54", "link": {"author": "Rajpurkar et al.", "href": "https://aclanthology.org/P18-2124/", "year": "2018"}, "metric": "\u6b63\u89e3\u7387, \u5b8c\u5168\u4e00\u81f4", "name": "SQuAD2", "setting": "4-shot", "short": "SQuAD2", "subtitle": "\u6a5f\u68b0\u8aad\u89e3", "title": "SQuAD2"}, "TriviaQA": {"description": "\u96d1\u5b66\u7684\u306a\u77e5\u8b58\u306b\u57fa\u3065\u304f\u81ea\u7531\u8a18\u8ff0\u5f0f\u8cea\u554f\u5fdc\u7b54", "link": {"author": "Joshi et al.", "href": "https://aclanthology.org/P17-1147/", "year": "2017"}, "metric": "\u6b63\u89e3\u7387, \u5b8c\u5168\u4e00\u81f4", "name": "TriviaQA", "setting": "4-shot", "short": "TriviaQA", "subtitle": "\u77e5\u8b58\u306b\u57fa\u3065\u304f\u8cea\u554f\u5fdc\u7b54", "title": "TriviaQA"}, "XWINO": {"description": "\u6587\u4e2d\u306e\u4ee3\u540d\u8a5e\u306e\u5148\u884c\u8a5e\u3092\u63a8\u5b9a\u3059\u308b2\u629e\u306e\u9078\u629e\u5f0f\u554f\u984c", "link": {"author": "Tikhonov and Ryabinin", "href": "https://aclanthology.org/2021.findings-acl.310/", "year": "2021"}, "metric": "\u6b63\u89e3\u7387", "name": "XWINO", "setting": "4-shot", "short": "XWINO", "subtitle": "\u5e38\u8b58\u63a8\u8ad6", "title": "XWINO"}}, "title": "\u82f1\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_basic": {"category": "\u65e5", "description": "\u8cea\u554f\u5fdc\u7b54\u3084\u8aad\u89e3\u3001\u8a66\u9a13\u554f\u984c\u3067\u8a00\u8a9e\u7406\u89e3\u3084\u5e38\u8b58\u7684\u77e5\u8b58\u3001\u8981\u7d04\u3084\u7ffb\u8a33\u3067\u8a00\u8a9e\u751f\u6210\u3001\u30b3\u30fc\u30c9\u751f\u6210\u3084\u6570\u5b66\u3067\u8ad6\u7406\u63a8\u8ad6\u306e\u80fd\u529b\u3092\u6e2c\u5b9a\u3057\u307e\u3059\u3002\u8a55\u4fa1\u30b9\u30b3\u30a2\u306f0 (\u6700\u4f4e) \u304b\u30891 (\u6700\u9ad8) \u307e\u3067\u306e\u7bc4\u56f2\u306e\u5024\u3092\u3068\u308a\u307e\u3059\u3002", "for": ["base", "inst"], "tasks": {"JComQA": {"description": "\u77e5\u8b58\u30d9\u30fc\u30b9\u306b\u57fa\u3065\u3044\u3066\u4f5c\u6210\u3055\u308c\u305f5\u629e\u306e\u9078\u629e\u5f0f\u554f\u984c", "link": {"author": "Kurihara et al.", "href": "https://aclanthology.org/2022.lrec-1.317/", "year": "2022"}, "metric": "\u6b63\u89e3\u7387", "name": "JComQA", "setting": "4-shot", "short": "JComQA", "subtitle": "\u5e38\u8b58\u7684\u306a\u77e5\u8b58\u30fb\u63a8\u8ad6\u306b\u95a2\u3059\u308b\u8cea\u554f\u5fdc\u7b54", "title": "JCommonsenseQA (JComQA)"}, "JEMHopQA": {"description": "\u77e5\u8b58\u91cf\u3084\u63a8\u8ad6\u80fd\u529b\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306e\u81ea\u7531\u8a18\u8ff0\u5f0f\u8cea\u554f\u5fdc\u7b54", "link": {"author": "Ishii et al.", "href": "https://aclanthology.org/2024.lrec-main.831/", "year": "2024"}, "metric": "\u6587\u5b57F1", "name": "JEMHopQA", "setting": "4-shot", "short": "JEMHQA", "subtitle": "\u30de\u30eb\u30c1\u30db\u30c3\u30d7\u8cea\u554f\u5fdc\u7b54", "title": "JEMHopQA"}, "JHumanEval": {"description": "\u30b3\u30fc\u30c9\u751f\u6210\u80fd\u529b\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30afHumanEval\u306e\u65e5\u672c\u8a9e\u8a33", "link": {"author": "\u4f50\u85e4\u3089", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/P10-9.pdf", "year": "2024"}, "metric": "pass@1", "name": "JHumanEval", "setting": "0-shot, 10\u56de\u8a66\u884c", "short": "JHumanEval", "subtitle": "\u30b3\u30fc\u30c9\u751f\u6210", "title": "JHumanEval"}, "JMMLU": {"description": "4\u5024\u9078\u629e\u5f0f\u8a66\u9a13\u554f\u984c\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30afMMLU\u306e\u65e5\u672c\u8a9e\u8a33\uff0853\u79d1\u76ee\uff09", "link": {"author": "\u5c39\u3089", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A7-5.pdf", "year": "2024"}, "metric": "\u6b63\u89e3\u7387", "name": "JMMLU", "setting": "5-shot", "short": "JMMLU", "subtitle": "\u30de\u30eb\u30c1\u30bf\u30b9\u30af\u8a00\u8a9e\u7406\u89e3", "title": "JMMLU"}, "JSQuAD": {"description": "Wikipedia\u8a18\u4e8b\u306b\u5bfe\u3059\u308b\u81ea\u7531\u8a18\u8ff0\u5f0f\u8cea\u554f\u5fdc\u7b54", "link": {"author": "Kurihara et al.", "href": "https://aclanthology.org/2022.lrec-1.317/", "year": "2022"}, "metric": "\u6587\u5b57F1", "name": "JSQuAD", "setting": "4-shot", "short": "JSQuAD", "subtitle": "\u6a5f\u68b0\u8aad\u89e3", "title": "JSQuAD"}, "Ja Avg": {"collective": true, "description": "\u65e5\u672c\u8a9e\u306e\u7406\u89e3\u30fb\u751f\u6210\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "metric": "\u5e73\u5747", "name": "Ja Avg", "setting": "MBPP-Ja\u306f\u9664\u304f", "short": "Ja avg", "subtitle": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210\u5e73\u5747", "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210\u5e73\u5747"}, "MGSM": {"description": "\u5c0f\u5b66\u6821\u306e\u6570\u5b66\u306e\u6587\u7ae0\u984c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\uff08GSM8K\uff09\u306e\u65e5\u672c\u8a9e\u8a33", "link": {"author": "Shi et al.", "href": "https://openreview.net/forum?id=fR3wGCk-IXp", "year": "2023"}, "metric": "\u6b63\u89e3\u7387, \u5b8c\u5168\u4e00\u81f4", "name": "MGSM", "setting": "4-shot", "short": "MGSM", "subtitle": "\u6570\u5b66\uff08\u7b97\u6570\uff09", "title": "MGSM"}, "NIILC": {"description": "\u767e\u79d1\u4e8b\u5178\u3067\u89e3\u7b54\u304c\u5f97\u3089\u308c\u305d\u3046\u306a\u81ea\u7531\u8a18\u8ff0\u5f0f\u8cea\u554f\u5fdc\u7b54", "link": {"author": "\u95a2\u6839", "href": "https://www.anlp.jp/proceedings/annual_meeting/2003/pdf_dir/C7-6.pdf", "year": "2003"}, "metric": "\u6587\u5b57F1", "name": "NIILC", "setting": "4-shot", "short": "NIILC", "subtitle": "\u30af\u30e9\u30b7\u30ab\u30eb\u306a\u8cea\u554f\u5fdc\u7b54", "title": "NIILC"}, "WMT20-en-ja": {"description": "\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u306e\u7ffb\u8a33\uff08\u82f1\u8a9e\u304b\u3089\u65e5\u672c\u8a9e\uff09", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20-en-ja", "setting": "4-shot", "short": "En-Ja", "subtitle": "\u82f1\u65e5\u6a5f\u68b0\u7ffb\u8a33", "title": "WMT20 (en-ja)"}, "WMT20-ja-en": {"description": "\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u306e\u7ffb\u8a33\uff08\u65e5\u672c\u8a9e\u304b\u3089\u82f1\u8a9e\uff09", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20-ja-en", "setting": "4-shot", "short": "Ja-En", "subtitle": "\u65e5\u82f1\u6a5f\u68b0\u7ffb\u8a33", "title": "WMT20 (ja-en)"}, "XL-Sum": {"description": "\u30a4\u30ae\u30ea\u30b9\u56fd\u55b6\u653e\u9001\uff08BBC\uff09\u306e\u8a18\u4e8b\u672c\u6587\u304b\u3089\u30cf\u30a4\u30e9\u30a4\u30c8\uff08\u8981\u7d04\uff09\u3092\u751f\u6210\u3059\u308b\u30bf\u30b9\u30af", "link": {"author": "Hasan et al.", "href": "https://aclanthology.org/2021.findings-acl.413/", "year": "2021"}, "metric": "ROUGE-2", "name": "XL-Sum", "setting": "1-shot", "short": "XL-Sum", "subtitle": "\u81ea\u52d5\u8981\u7d04", "title": "XL-Sum"}}, "title": "\u65e5\u672c\u8a9e\u7406\u89e3\u30fb\u751f\u6210"}, "ja_mtb": {"category": "\u65e5\u672c\u8a9eMTB", "description": "\u5bfe\u8a71\u80fd\u529b\u3092\u6e2c\u5b9a\u3059\u308bMT-Bench\u306e\u65e5\u672c\u8a9e\u7248\uff08Nejumi LLM\u30ea\u30fc\u30c0\u30fc\u30dc\u30fc\u30c9\u7248\uff09\u3092\u7528\u3044\u307e\u3057\u305f\u3002\u8a2d\u554f\u306fv4\u3092\u3001\u6a21\u7bc4\u56de\u7b54\u306fv2\u306e\u8aa4\u7b54\u3092\u4fee\u6b63\u3057\u305f\u3082\u306e\u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3059\u3002\u8a55\u4fa1\u30b9\u30b3\u30a2\u306f0 (\u6700\u4f4e) \u304b\u30891 (\u6700\u9ad8) \u307e\u3067\u306e\u7bc4\u56f2\u306e\u5024\u3092\u3068\u308a\u307e\u3059\u3002", "for": ["inst"], "tasks": {"JMT Avg": {"collective": true, "name": "JMT Avg", "short": "JMT avg", "subtitle": "\u65e5\u672c\u8a9eMT-Bench\u5e73\u5747", "title": "\u65e5\u672c\u8a9eMT-Bench\u5e73\u5747"}, "coding": {"description": "Python\u3084C++\u3067\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u305f\u308a\u3001HTML\u3067\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3092\u4f5c\u6210\u3059\u308b", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "coding", "short": "Code", "subtitle": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0", "title": "Coding"}, "extraction": {"description": "\u6587\u66f8\u304b\u3089\u56fa\u6709\u8868\u73fe\uff08\u8457\u8005\u540d\u3084\u6570\u5024\u306a\u3069\uff09\u3084\u8a55\u5224\uff08\u30dd\u30b8\u30cd\u30ac\u306a\u3069\uff09\u3092\u62bd\u51fa\u3059\u308b", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "extraction", "short": "Ext", "subtitle": "\u60c5\u5831\u62bd\u51fa", "title": "Extraction"}, "humanities": {"description": "\u6cd5\u5f8b\u3084\u7d4c\u6e08\u3001\u6b74\u53f2\u3001\u54f2\u5b66\u3001\u6559\u80b2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3059\u308b\u8ad6\u8aac\u3084\u6226\u7565\u3092\u4f5c\u6210\u3059\u308b", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "humanities", "short": "Human", "subtitle": "\u4eba\u6587\u79d1\u5b66", "title": "Humanities"}, "math": {"description": "\u4ee3\u6570\u3001\u5e7e\u4f55\u3001\u78ba\u7387\u3001\u6574\u6570\u306a\u3069\u306e\u554f\u984c\u3084\u6587\u7ae0\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "math", "short": "Math", "subtitle": "\u6570\u5b66", "title": "Math"}, "reasoning": {"description": "\u5e38\u8b58\u3084\u63a8\u8ad6\u529b\u3092\u6d3b\u7528\u3057\u3066\u554f\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "reasoning", "short": "Reason", "subtitle": "\u63a8\u8ad6", "title": "Reasoning"}, "roleplay": {"description": "\u6709\u540d\u4eba\u3084\u6620\u753b\u4e2d\u306e\u4eba\u7269\u306b\u306a\u308a\u3059\u307e\u3059\u306a\u3069\u3001\u4eee\u60f3\u306e\u72b6\u6cc1\u3092\u60f3\u5b9a\u3057\u3066\u6587\u7ae0\u3092\u4f5c\u6587\u3059\u308b", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "roleplay", "short": "Role", "subtitle": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4", "title": "Roleplay"}, "stem": {"description": "\u7269\u7406\u5b66\u3001\u5316\u5b66\u3001\u751f\u7269\u5b66\u3001\u5730\u7406\u3001\u5efa\u7bc9\u3001\u6a5f\u68b0\u5b66\u7fd2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3057\u3066\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "stem", "short": "STEM", "subtitle": "\u79d1\u5b66\u30fb\u6280\u8853\u30fb\u5de5\u5b66\u30fb\u6570\u5b66", "title": "STEM"}, "writing": {"description": "\u30d6\u30ed\u30b0\u8a18\u4e8b\u3084\u30e1\u30fc\u30eb\u6587\u9762\u3001\u30d5\u30a3\u30af\u30b7\u30e7\u30f3\u306e\u6587\u7ae0\u306a\u3069\u3092\u57f7\u7b46\u3059\u308b\u30bf\u30b9\u30af", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "writing", "short": "Write", "subtitle": "\u30e9\u30a4\u30c6\u30a3\u30f3\u30b0", "title": "Writing"}}, "title": "\u65e5\u672c\u8a9e MT-Bench"}, "other": {"category": "\u305d\u306e\u4ed6\u306e\u30bf\u30b9\u30af", "for": ["base", "inst"], "tasks": {"GPQA": {"name": "GPQA", "short": "GPQA", "subtitle": "GPQA", "title": "GPQA"}}, "title": "\u305d\u306e\u4ed6\u306e\u30bf\u30b9\u30af"}};
