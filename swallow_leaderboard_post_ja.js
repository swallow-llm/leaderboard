const g_models = {"Qwen/Qwen2.5-14B-Instruct": {"active_params": 15, "date": "2024-09-19", "family": "Qwen2.5", "id": "Qwen/Qwen2.5-14B-Instruct", "is_post": true, "model_id": "Qwen/Qwen2.5-14B-Instruct", "name": "Qwen2.5-14B-Instruct", "params": 15, "pre_training": "Qwen2.5-14B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.865, "coding": 0.752, "extraction": 0.873, "humanities": 0.899, "math": 0.932, "reasoning": 0.861, "roleplay": 0.87, "stem": 0.894, "writing": 0.839}, "en_post": {"AIME": 0.133, "GPQA": 0.404, "HellaSwag": 0.886, "LCB": 0.215, "MATH500": 0.794, "MMLU-Pro": 0.652, "avg": 0.514}, "ja_mtb": {"avg": 0.799, "coding": 0.773, "extraction": 0.882, "humanities": 0.85, "math": 0.796, "reasoning": 0.646, "roleplay": 0.829, "stem": 0.795, "writing": 0.822}, "ja_post": {"GPQA": 0.348, "JHumanEval": 0.754, "JamC-QA": 0.444, "MATH100": 0.768, "MMLU-ProX": 0.556, "WMT20enja": 0.207, "WMT20jaen": 0.218, "__MIFEvalJa": 0.606, "avg": 0.471}}, "sortkey": "qwen2.5", "url": "https://huggingface.co/Qwen/Qwen2.5-14B-Instruct"}, "Qwen/Qwen2.5-32B-Instruct": {"active_params": 33, "date": "2024-09-19", "family": "Qwen2.5", "id": "Qwen/Qwen2.5-32B-Instruct", "is_post": true, "model_id": "Qwen/Qwen2.5-32B-Instruct", "name": "Qwen2.5-32B-Instruct", "params": 33, "pre_training": "Qwen2.5-32B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.869, "coding": 0.806, "extraction": 0.862, "humanities": 0.895, "math": 0.954, "reasoning": 0.817, "roleplay": 0.876, "stem": 0.89, "writing": 0.851}, "en_post": {"AIME": 0.15, "GPQA": 0.48, "HellaSwag": 0.908, "LCB": 0.27, "MATH500": 0.812, "MMLU-Pro": 0.64, "avg": 0.543}, "ja_mtb": {"avg": 0.819, "coding": 0.776, "extraction": 0.913, "humanities": 0.845, "math": 0.863, "reasoning": 0.706, "roleplay": 0.839, "stem": 0.802, "writing": 0.811}, "ja_post": {"GPQA": 0.411, "JHumanEval": 0.803, "JamC-QA": 0.476, "MATH100": 0.768, "MMLU-ProX": 0.623, "WMT20enja": 0.221, "WMT20jaen": 0.224, "__MIFEvalJa": 0.673, "avg": 0.504}}, "sortkey": "qwen2.5", "url": "https://huggingface.co/Qwen/Qwen2.5-32B-Instruct"}, "Qwen/Qwen2.5-7B-Instruct": {"active_params": 7.6, "date": "2024-09-19", "family": "Qwen2.5", "id": "Qwen/Qwen2.5-7B-Instruct", "is_post": true, "model_id": "Qwen/Qwen2.5-7B-Instruct", "name": "Qwen2.5-7B-Instruct", "params": 7.6, "pre_training": "Qwen2.5-7B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.797, "coding": 0.656, "extraction": 0.769, "humanities": 0.893, "math": 0.843, "reasoning": 0.662, "roleplay": 0.832, "stem": 0.886, "writing": 0.833}, "en_post": {"AIME": 0.1, "GPQA": 0.348, "HellaSwag": 0.82, "LCB": 0.158, "MATH500": 0.742, "MMLU-Pro": 0.554, "avg": 0.454}, "ja_mtb": {"avg": 0.688, "coding": 0.638, "extraction": 0.711, "humanities": 0.782, "math": 0.685, "reasoning": 0.494, "roleplay": 0.736, "stem": 0.73, "writing": 0.729}, "ja_post": {"GPQA": 0.315, "JHumanEval": 0.737, "JamC-QA": 0.365, "MATH100": 0.636, "MMLU-ProX": 0.452, "WMT20enja": 0.189, "WMT20jaen": 0.184, "__MIFEvalJa": 0.504, "avg": 0.411}}, "sortkey": "qwen2.5", "url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct"}, "Qwen/Qwen3-0.6B": {"active_params": 0.5, "date": "2025-04-29", "family": "Qwen3", "id": "Qwen/Qwen3-0.6B", "is_post": true, "model_id": "Qwen/Qwen3-0.6B", "name": "Qwen3-0.6B", "params": 0.5, "pre_training": "Qwen3-0.6B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.595, "coding": 0.376, "extraction": 0.678, "humanities": 0.673, "math": 0.803, "reasoning": 0.408, "roleplay": 0.551, "stem": 0.633, "writing": 0.637}, "en_post": {"AIME": 0.133, "GPQA": 0.283, "HellaSwag": 0.425, "LCB": 0.135, "MATH500": 0.694, "MMLU-Pro": 0.338, "avg": 0.335}, "ja_mtb": {"avg": 0.431, "coding": 0.332, "extraction": 0.423, "humanities": 0.46, "math": 0.626, "reasoning": 0.346, "roleplay": 0.418, "stem": 0.445, "writing": 0.402}, "ja_post": {"GPQA": 0.237, "JHumanEval": 0.408, "JamC-QA": 0.25, "MATH100": 0.606, "MMLU-ProX": 0.295, "WMT20enja": 0.001, "WMT20jaen": 0.0, "__MIFEvalJa": 0.438, "avg": 0.257}}, "sortkey": "qwen3", "url": "https://huggingface.co/Qwen/Qwen3-0.6B"}, "Qwen/Qwen3-1.7B": {"active_params": 1.5, "date": "2025-04-29", "family": "Qwen3", "id": "Qwen/Qwen3-1.7B", "is_post": true, "model_id": "Qwen/Qwen3-1.7B", "name": "Qwen3-1.7B", "params": 1.5, "pre_training": "Qwen3-1.7B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.779, "coding": 0.642, "extraction": 0.754, "humanities": 0.83, "math": 0.968, "reasoning": 0.686, "roleplay": 0.764, "stem": 0.785, "writing": 0.805}, "en_post": {"AIME": 0.383, "GPQA": 0.394, "HellaSwag": 0.626, "LCB": 0.315, "MATH500": 0.904, "MMLU-Pro": 0.56, "avg": 0.531}, "ja_mtb": {"avg": 0.662, "coding": 0.574, "extraction": 0.591, "humanities": 0.715, "math": 0.841, "reasoning": 0.567, "roleplay": 0.631, "stem": 0.765, "writing": 0.613}, "ja_post": {"GPQA": 0.315, "JHumanEval": 0.747, "JamC-QA": 0.278, "MATH100": 0.859, "MMLU-ProX": 0.514, "WMT20enja": 0.13, "WMT20jaen": 0.156, "__MIFEvalJa": 0.46, "avg": 0.428}}, "sortkey": "qwen3", "url": "https://huggingface.co/Qwen/Qwen3-1.7B"}, "Qwen/Qwen3-14B": {"active_params": 15, "date": "2025-04-29", "family": "Qwen3", "id": "Qwen/Qwen3-14B", "is_post": true, "model_id": "Qwen/Qwen3-14B", "name": "Qwen3-14B", "params": 15, "pre_training": "Qwen3-14B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.882, "coding": 0.843, "extraction": 0.849, "humanities": 0.904, "math": 0.971, "reasoning": 0.805, "roleplay": 0.878, "stem": 0.919, "writing": 0.89}, "en_post": {"AIME": 0.75, "GPQA": 0.611, "HellaSwag": 0.89, "LCB": 0.587, "MATH500": 0.972, "MMLU-Pro": 0.77, "avg": 0.763}, "ja_mtb": {"avg": 0.874, "coding": 0.85, "extraction": 0.839, "humanities": 0.903, "math": 0.994, "reasoning": 0.824, "roleplay": 0.839, "stem": 0.919, "writing": 0.827}, "ja_post": {"GPQA": 0.556, "JHumanEval": 0.91, "JamC-QA": 0.455, "MATH100": 0.939, "MMLU-ProX": 0.737, "WMT20enja": 0.228, "WMT20jaen": 0.22, "__MIFEvalJa": 0.624, "avg": 0.578}}, "sortkey": "qwen3", "url": "https://huggingface.co/Qwen/Qwen3-14B"}, "Qwen/Qwen3-235B-A22B-Instruct-2507": {"active_params": 22, "date": "2025-07-23", "family": "Qwen3", "id": "Qwen/Qwen3-235B-A22B-Instruct-2507", "is_post": true, "model_id": "Qwen/Qwen3-235B-A22B-Instruct-2507", "name": "Qwen3-235B-A22B-Instruct-2507", "params": 235, "pre_training": "(private)", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.911, "coding": 0.888, "extraction": 0.859, "humanities": 0.925, "math": 0.99, "reasoning": 0.873, "roleplay": 0.911, "stem": 0.94, "writing": 0.905}, "en_post": {"AIME": 0.767, "GPQA": 0.586, "HellaSwag": 0.94, "LCB": 0.529, "MATH500": 0.982, "MMLU-Pro": 0.824, "avg": 0.771}, "ja_mtb": {"avg": 0.915, "coding": 0.943, "extraction": 0.938, "humanities": 0.907, "math": 0.987, "reasoning": 0.826, "roleplay": 0.893, "stem": 0.933, "writing": 0.891}, "ja_post": {"GPQA": 0.701, "JHumanEval": 0.9, "JamC-QA": 0.636, "MATH100": 0.97, "MMLU-ProX": 0.799, "WMT20enja": 0.258, "WMT20jaen": 0.23, "__MIFEvalJa": 0.73, "avg": 0.642}}, "sortkey": "qwen3 a 2507", "url": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507"}, "Qwen/Qwen3-235B-A22B-Thinking-2507": {"active_params": 22, "date": "2025-07-23", "family": "Qwen3", "id": "Qwen/Qwen3-235B-A22B-Thinking-2507", "is_post": true, "model_id": "Qwen/Qwen3-235B-A22B-Thinking-2507", "name": "Qwen3-235B-A22B-Thinking-2507", "params": 235, "pre_training": "(private)", "reasoning": "on", "results": {"en_mtb": {"avg": 0.922, "coding": 0.877, "extraction": 0.899, "humanities": 0.945, "math": 0.998, "reasoning": 0.886, "roleplay": 0.908, "stem": 0.952, "writing": 0.908}, "en_post": {"AIME": 0.883, "GPQA": 0.803, "HellaSwag": 0.931, "LCB": 0.692, "MATH500": 0.98, "MMLU-Pro": 0.845, "avg": 0.856}, "ja_mtb": {"avg": 0.904, "coding": 0.896, "extraction": 0.878, "humanities": 0.933, "math": 0.985, "reasoning": 0.851, "roleplay": 0.876, "stem": 0.955, "writing": 0.861}, "ja_post": {"GPQA": 0.739, "JHumanEval": 0.938, "JamC-QA": 0.659, "MATH100": 0.97, "MMLU-ProX": 0.819, "WMT20enja": 0.26, "WMT20jaen": 0.234, "__MIFEvalJa": 0.783, "avg": 0.66}}, "sortkey": "qwen3 a thinking 2507", "url": "https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507"}, "Qwen/Qwen3-30B-A3B": {"active_params": 15, "date": "2025-04-29", "family": "Qwen3", "id": "Qwen/Qwen3-30B-A3B", "is_post": true, "model_id": "Qwen/Qwen3-30B-A3B", "name": "Qwen3-30B-A3B", "params": 15, "pre_training": "Qwen3-30B-A3B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.893, "coding": 0.915, "extraction": 0.909, "humanities": 0.909, "math": 0.972, "reasoning": 0.798, "roleplay": 0.882, "stem": 0.895, "writing": 0.866}, "en_post": {"AIME": 0.733, "GPQA": 0.636, "HellaSwag": 0.883, "LCB": 0.589, "MATH500": 0.964, "MMLU-Pro": 0.782, "avg": 0.764}, "ja_mtb": {"avg": 0.858, "coding": 0.883, "extraction": 0.801, "humanities": 0.91, "math": 0.966, "reasoning": 0.763, "roleplay": 0.86, "stem": 0.853, "writing": 0.832}, "ja_post": {"GPQA": 0.558, "JHumanEval": 0.899, "JamC-QA": 0.46, "MATH100": 0.96, "MMLU-ProX": 0.738, "WMT20enja": 0.17, "WMT20jaen": 0.219, "__MIFEvalJa": 0.655, "avg": 0.572}}, "sortkey": "qwen3 a", "url": "https://huggingface.co/Qwen/Qwen3-30B-A3B"}, "Qwen/Qwen3-32B": {"active_params": 33, "date": "2025-04-29", "family": "Qwen3", "id": "Qwen/Qwen3-32B", "is_post": true, "model_id": "Qwen/Qwen3-32B", "name": "Qwen3-32B", "params": 33, "pre_training": "(private)", "reasoning": "on", "results": {"en_mtb": {"avg": 0.892, "coding": 0.86, "extraction": 0.91, "humanities": 0.905, "math": 0.979, "reasoning": 0.796, "roleplay": 0.899, "stem": 0.919, "writing": 0.869}, "en_post": {"AIME": 0.717, "GPQA": 0.646, "HellaSwag": 0.901, "LCB": 0.602, "MATH500": 0.964, "MMLU-Pro": 0.779, "avg": 0.768}, "ja_mtb": {"avg": 0.875, "coding": 0.794, "extraction": 0.871, "humanities": 0.871, "math": 0.997, "reasoning": 0.836, "roleplay": 0.881, "stem": 0.917, "writing": 0.83}, "ja_post": {"GPQA": 0.571, "JHumanEval": 0.923, "JamC-QA": 0.479, "MATH100": 0.949, "MMLU-ProX": 0.746, "WMT20enja": 0.226, "WMT20jaen": 0.22, "__MIFEvalJa": 0.681, "avg": 0.588}}, "sortkey": "qwen3", "url": "https://huggingface.co/Qwen/Qwen3-32B"}, "Qwen/Qwen3-4B": {"active_params": 3.1, "date": "2025-04-29", "family": "Qwen3", "id": "Qwen/Qwen3-4B", "is_post": true, "model_id": "Qwen/Qwen3-4B", "name": "Qwen3-4B", "params": 3.1, "pre_training": "Qwen3-4B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.839, "coding": 0.737, "extraction": 0.831, "humanities": 0.884, "math": 0.947, "reasoning": 0.735, "roleplay": 0.87, "stem": 0.861, "writing": 0.845}, "en_post": {"AIME": 0.6, "GPQA": 0.515, "HellaSwag": 0.79, "LCB": 0.499, "MATH500": 0.938, "MMLU-Pro": 0.69, "avg": 0.672}, "ja_mtb": {"avg": 0.797, "coding": 0.696, "extraction": 0.818, "humanities": 0.855, "math": 0.947, "reasoning": 0.729, "roleplay": 0.747, "stem": 0.826, "writing": 0.76}, "ja_post": {"GPQA": 0.44, "JHumanEval": 0.838, "JamC-QA": 0.328, "MATH100": 0.919, "MMLU-ProX": 0.643, "WMT20enja": 0.154, "WMT20jaen": 0.189, "__MIFEvalJa": 0.562, "avg": 0.502}}, "sortkey": "qwen3", "url": "https://huggingface.co/Qwen/Qwen3-4B"}, "Qwen/Qwen3-8B": {"active_params": 8.2, "date": "2025-04-29", "family": "Qwen3", "id": "Qwen/Qwen3-8B", "is_post": true, "model_id": "Qwen/Qwen3-8B", "name": "Qwen3-8B", "params": 8.2, "pre_training": "Qwen3-8B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.851, "coding": 0.804, "extraction": 0.831, "humanities": 0.892, "math": 0.98, "reasoning": 0.713, "roleplay": 0.858, "stem": 0.876, "writing": 0.854}, "en_post": {"AIME": 0.7, "GPQA": 0.561, "HellaSwag": 0.851, "LCB": 0.525, "MATH500": 0.942, "MMLU-Pro": 0.713, "avg": 0.715}, "ja_mtb": {"avg": 0.845, "coding": 0.757, "extraction": 0.834, "humanities": 0.89, "math": 0.996, "reasoning": 0.823, "roleplay": 0.829, "stem": 0.822, "writing": 0.806}, "ja_post": {"GPQA": 0.491, "JHumanEval": 0.869, "JamC-QA": 0.398, "MATH100": 0.929, "MMLU-ProX": 0.696, "WMT20enja": 0.209, "WMT20jaen": 0.202, "__MIFEvalJa": 0.575, "avg": 0.542}}, "sortkey": "qwen3", "url": "https://huggingface.co/Qwen/Qwen3-8B"}, "Qwen/Qwen3-Next-80B-A3B-Instruct": {"active_params": 3, "date": "2025-09-11", "family": "Qwen3", "id": "Qwen/Qwen3-Next-80B-A3B-Instruct", "is_post": true, "model_id": "Qwen/Qwen3-Next-80B-A3B-Instruct", "name": "Qwen3-Next-80B-A3B-Instruct", "params": 81, "pre_training": "(private)", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.92, "coding": 0.908, "extraction": 0.925, "humanities": 0.932, "math": 0.966, "reasoning": 0.842, "roleplay": 0.925, "stem": 0.949, "writing": 0.912}, "en_post": {"AIME": 0.733, "GPQA": 0.753, "HellaSwag": 0.929, "LCB": 0.592, "MATH500": 0.98, "MMLU-Pro": 0.824, "avg": 0.802}, "ja_mtb": {"avg": 0.916, "coding": 0.919, "extraction": 0.92, "humanities": 0.931, "math": 0.987, "reasoning": 0.83, "roleplay": 0.89, "stem": 0.945, "writing": 0.906}, "ja_post": {"GPQA": 0.614, "JHumanEval": 0.905, "JamC-QA": 0.599, "MATH100": 0.939, "MMLU-ProX": 0.77, "WMT20enja": 0.24, "WMT20jaen": 0.228, "__MIFEvalJa": 0.681, "avg": 0.614}}, "sortkey": "qwen3 next a", "url": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Instruct"}, "Qwen/Qwen3-Next-80B-A3B-Thinking": {"active_params": 3, "date": "2025-09-11", "family": "Qwen3", "id": "Qwen/Qwen3-Next-80B-A3B-Thinking", "is_post": true, "model_id": "Qwen/Qwen3-Next-80B-A3B-Thinking", "name": "Qwen3-Next-80B-A3B-Thinking", "params": 81, "pre_training": "(private)", "reasoning": "on", "results": {"en_mtb": {"avg": 0.883, "coding": 0.855, "extraction": 0.853, "humanities": 0.934, "math": 0.941, "reasoning": 0.774, "roleplay": 0.889, "stem": 0.964, "writing": 0.851}, "en_post": {"AIME": 0.85, "GPQA": 0.798, "HellaSwag": 0.923, "LCB": 0.67, "MATH500": 0.974, "MMLU-Pro": 0.828, "avg": 0.84}, "ja_mtb": {"avg": 0.879, "coding": 0.871, "extraction": 0.855, "humanities": 0.912, "math": 0.993, "reasoning": 0.811, "roleplay": 0.85, "stem": 0.92, "writing": 0.821}, "ja_post": {"GPQA": 0.71, "JHumanEval": 0.927, "JamC-QA": 0.595, "MATH100": 0.96, "MMLU-ProX": 0.797, "WMT20enja": 0.232, "WMT20jaen": 0.197, "__MIFEvalJa": 0.743, "avg": 0.631}}, "sortkey": "qwen3 next a thinking", "url": "https://huggingface.co/Qwen/Qwen3-Next-80B-A3B-Thinking"}, "abeja/ABEJA-QwQ32b-Reasoning-Japanese-v1.0": {"active_params": 33, "date": "2025-04-25", "family": "Qwen2.5", "id": "abeja/ABEJA-QwQ32b-Reasoning-Japanese-v1.0", "is_post": true, "model_id": "abeja/ABEJA-QwQ32b-Reasoning-Japanese-v1.0", "name": "ABEJA-QwQ32b-Reasoning-Japanese-v1.0", "params": 33, "pre_training": "ABEJA-Qwen2.5-32b-Japanese-v0.1", "reasoning": "on", "results": {"en_mtb": {"avg": 0.866, "coding": 0.808, "extraction": 0.878, "humanities": 0.899, "math": 0.951, "reasoning": 0.757, "roleplay": 0.872, "stem": 0.882, "writing": 0.881}, "en_post": {"AIME": 0.617, "GPQA": 0.606, "HellaSwag": 0.906, "LCB": 0.563, "MATH500": 0.964, "MMLU-Pro": 0.78, "avg": 0.739}, "ja_mtb": {"avg": 0.843, "coding": 0.868, "extraction": 0.893, "humanities": 0.885, "math": 0.889, "reasoning": 0.694, "roleplay": 0.848, "stem": 0.85, "writing": 0.821}, "ja_post": {"GPQA": 0.527, "JHumanEval": 0.866, "JamC-QA": 0.611, "MATH100": 0.899, "MMLU-ProX": 0.712, "WMT20enja": 0.243, "WMT20jaen": 0.215, "__MIFEvalJa": 0.619, "avg": 0.582}}, "sortkey": "abeja qwq reasoning japanese v1.0", "url": "https://huggingface.co/abeja/ABEJA-QwQ32b-Reasoning-Japanese-v1.0"}, "allenai/Olmo-3-32B-Think": {"active_params": 32, "date": "2025-11-20", "family": "Olmo 3", "id": "allenai/Olmo-3-32B-Think", "is_post": true, "model_id": "allenai/Olmo-3-32B-Think", "name": "Olmo 3 32B Think", "params": 32, "pre_training": "Olmo 3 32B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.689, "coding": 0.546, "extraction": 0.647, "humanities": 0.776, "math": 0.748, "reasoning": 0.665, "roleplay": 0.799, "stem": 0.671, "writing": 0.663}, "en_post": {"AIME": 0.75, "GPQA": 0.591, "HellaSwag": 0.851, "LCB": 0.597, "MATH500": 0.962, "MMLU-Pro": 0.753, "avg": 0.751}, "ja_mtb": {"avg": 0.616, "coding": 0.494, "extraction": 0.646, "humanities": 0.67, "math": 0.749, "reasoning": 0.535, "roleplay": 0.673, "stem": 0.584, "writing": 0.579}, "ja_post": {"GPQA": 0.547, "JHumanEval": 0.915, "JamC-QA": 0.353, "MATH100": 0.919, "MMLU-ProX": 0.669, "WMT20enja": 0.174, "WMT20jaen": 0.186, "__MIFEvalJa": 0.332, "avg": 0.537}}, "sortkey": "olmo 3 think", "url": "https://huggingface.co/allenai/Olmo-3-32B-Think"}, "allenai/Olmo-3-7B-Think": {"active_params": 7.3, "date": "2025-11-20", "family": "Olmo 3", "id": "allenai/Olmo-3-7B-Think", "is_post": true, "model_id": "allenai/Olmo-3-7B-Think", "name": "Olmo 3 7B Think", "params": 7.3, "pre_training": "Olmo 3 7B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.621, "coding": 0.472, "extraction": 0.615, "humanities": 0.667, "math": 0.703, "reasoning": 0.543, "roleplay": 0.707, "stem": 0.6, "writing": 0.663}, "en_post": {"AIME": 0.683, "GPQA": 0.49, "HellaSwag": 0.703, "LCB": 0.51, "MATH500": 0.936, "MMLU-Pro": 0.627, "avg": 0.658}, "ja_mtb": {"avg": 0.498, "coding": 0.439, "extraction": 0.604, "humanities": 0.522, "math": 0.705, "reasoning": 0.393, "roleplay": 0.488, "stem": 0.472, "writing": 0.359}, "ja_post": {"GPQA": 0.393, "JHumanEval": 0.885, "JamC-QA": 0.276, "MATH100": 0.949, "MMLU-ProX": 0.512, "WMT20enja": 0.131, "WMT20jaen": 0.143, "__MIFEvalJa": 0.31, "avg": 0.47}}, "sortkey": "olmo 3 think", "url": "https://huggingface.co/allenai/Olmo-3-7B-Think"}, "cyberagent/DeepSeek-R1-Distill-Qwen-14B-Japanese": {"active_params": 15, "date": "2025-01-27", "family": "Qwen2.5", "id": "cyberagent/DeepSeek-R1-Distill-Qwen-14B-Japanese", "is_post": true, "model_id": "cyberagent/DeepSeek-R1-Distill-Qwen-14B-Japanese", "name": "DeepSeek-R1-Distill-Qwen-14B-Japanese", "params": 15, "pre_training": "DeepSeek-R1-Distill-Qwen-14B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.835, "coding": 0.724, "extraction": 0.884, "humanities": 0.87, "math": 0.907, "reasoning": 0.771, "roleplay": 0.867, "stem": 0.817, "writing": 0.838}, "en_post": {"AIME": 0.433, "GPQA": 0.47, "HellaSwag": 0.823, "LCB": 0.451, "MATH500": 0.916, "MMLU-Pro": 0.679, "avg": 0.629}, "ja_mtb": {"avg": 0.771, "coding": 0.557, "extraction": 0.777, "humanities": 0.88, "math": 0.871, "reasoning": 0.664, "roleplay": 0.801, "stem": 0.859, "writing": 0.758}, "ja_post": {"GPQA": 0.4, "JHumanEval": 0.62, "JamC-QA": 0.393, "MATH100": 0.788, "MMLU-ProX": 0.525, "WMT20enja": 0.191, "WMT20jaen": 0.178, "__MIFEvalJa": 0.513, "avg": 0.442}}, "sortkey": "deepseek r1 distill qwen japanese", "url": "https://huggingface.co/cyberagent/DeepSeek-R1-Distill-Qwen-14B-Japanese"}, "cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese": {"active_params": 33, "date": "2025-01-27", "family": "Qwen2.5", "id": "cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese", "is_post": true, "model_id": "cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese", "name": "DeepSeek-R1-Distill-Qwen-32B-Japanese", "params": 33, "pre_training": "DeepSeek-R1-Distill-Qwen-32B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.857, "coding": 0.73, "extraction": 0.893, "humanities": 0.894, "math": 0.964, "reasoning": 0.77, "roleplay": 0.871, "stem": 0.872, "writing": 0.861}, "en_post": {"AIME": 0.55, "GPQA": 0.576, "HellaSwag": 0.872, "LCB": 0.508, "MATH500": 0.94, "MMLU-Pro": 0.737, "avg": 0.697}, "ja_mtb": {"avg": 0.808, "coding": 0.639, "extraction": 0.813, "humanities": 0.917, "math": 0.924, "reasoning": 0.652, "roleplay": 0.842, "stem": 0.872, "writing": 0.802}, "ja_post": {"GPQA": 0.464, "JHumanEval": 0.68, "JamC-QA": 0.434, "MATH100": 0.838, "MMLU-ProX": 0.606, "WMT20enja": 0.215, "WMT20jaen": 0.196, "__MIFEvalJa": 0.544, "avg": 0.491}}, "sortkey": "deepseek r1 distill qwen japanese", "url": "https://huggingface.co/cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese"}, "cyberagent/calm3-22b-chat": {"active_params": 22, "date": "2024-07-09", "family": "CyberAgentLM3", "id": "cyberagent/calm3-22b-chat", "is_post": true, "model_id": "cyberagent/calm3-22b-chat", "name": "CyberAgentLM3-22B-chat", "params": 22, "pre_training": "(private)", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.621, "coding": 0.467, "extraction": 0.695, "humanities": 0.828, "math": 0.479, "reasoning": 0.429, "roleplay": 0.678, "stem": 0.647, "writing": 0.747}, "en_post": {"AIME": 0.017, "GPQA": 0.288, "HellaSwag": 0.77, "LCB": 0.045, "MATH500": 0.298, "MMLU-Pro": 0.26, "avg": 0.28}, "ja_mtb": {"avg": 0.697, "coding": 0.5, "extraction": 0.733, "humanities": 0.859, "math": 0.591, "reasoning": 0.611, "roleplay": 0.791, "stem": 0.721, "writing": 0.769}, "ja_post": {"GPQA": 0.266, "JHumanEval": 0.443, "JamC-QA": 0.495, "MATH100": 0.354, "MMLU-ProX": 0.31, "WMT20enja": 0.237, "WMT20jaen": 0.21, "__MIFEvalJa": 0.429, "avg": 0.331}}, "sortkey": "cyberagentlm3", "url": "https://huggingface.co/cyberagent/calm3-22b-chat"}, "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {"active_params": 70, "date": "2025-01-20", "family": "Llama 3", "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B", "is_post": true, "model_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B", "name": "DeepSeek-R1-Distill-Llama-70B", "params": 70, "pre_training": "Llama 3.3 70B Instruct", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.842, "coding": 0.787, "extraction": 0.931, "humanities": 0.862, "math": 0.919, "reasoning": 0.723, "roleplay": 0.85, "stem": 0.806, "writing": 0.854}, "en_post": {"AIME": 0.617, "GPQA": 0.626, "HellaSwag": 0.891, "LCB": 0.534, "MATH500": 0.936, "MMLU-Pro": 0.776, "avg": 0.73}, "ja_mtb": {"avg": 0.707, "coding": 0.551, "extraction": 0.778, "humanities": 0.838, "math": 0.78, "reasoning": 0.525, "roleplay": 0.768, "stem": 0.733, "writing": 0.681}, "ja_post": {"GPQA": 0.538, "JHumanEval": 0.812, "JamC-QA": 0.461, "MATH100": 0.859, "MMLU-ProX": 0.642, "WMT20enja": 0.21, "WMT20jaen": 0.224, "__MIFEvalJa": 0.558, "avg": 0.535}}, "sortkey": "deepseek r1 distill llama", "url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B"}, "deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {"active_params": 8.0, "date": "2025-01-20", "family": "Llama 3", "id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B", "is_post": true, "model_id": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B", "name": "DeepSeek-R1-Distill-Llama-8B", "params": 8.0, "pre_training": "Llama 3.1 8B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.704, "coding": 0.398, "extraction": 0.745, "humanities": 0.825, "math": 0.827, "reasoning": 0.562, "roleplay": 0.768, "stem": 0.731, "writing": 0.775}, "en_post": {"AIME": 0.367, "GPQA": 0.46, "HellaSwag": 0.688, "LCB": 0.364, "MATH500": 0.866, "MMLU-Pro": 0.549, "avg": 0.549}, "ja_mtb": {"avg": 0.526, "coding": 0.376, "extraction": 0.625, "humanities": 0.681, "math": 0.595, "reasoning": 0.496, "roleplay": 0.483, "stem": 0.51, "writing": 0.442}, "ja_post": {"GPQA": 0.31, "JHumanEval": 0.721, "JamC-QA": 0.279, "MATH100": 0.556, "MMLU-ProX": 0.319, "WMT20enja": 0.096, "WMT20jaen": 0.144, "__MIFEvalJa": 0.319, "avg": 0.346}}, "sortkey": "deepseek r1 distill llama", "url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B"}, "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {"active_params": 15, "date": "2025-01-20", "family": "Qwen2.5", "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B", "is_post": true, "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B", "name": "DeepSeek-R1-Distill-Qwen-14B", "params": 15, "pre_training": "Qwen2.5-14B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.775, "coding": 0.512, "extraction": 0.851, "humanities": 0.815, "math": 0.886, "reasoning": 0.745, "roleplay": 0.841, "stem": 0.75, "writing": 0.803}, "en_post": {"AIME": 0.567, "GPQA": 0.525, "HellaSwag": 0.841, "LCB": 0.486, "MATH500": 0.908, "MMLU-Pro": 0.707, "avg": 0.672}, "ja_mtb": {"avg": 0.7, "coding": 0.632, "extraction": 0.803, "humanities": 0.739, "math": 0.857, "reasoning": 0.563, "roleplay": 0.72, "stem": 0.631, "writing": 0.658}, "ja_post": {"GPQA": 0.496, "JHumanEval": 0.859, "JamC-QA": 0.414, "MATH100": 0.737, "MMLU-ProX": 0.591, "WMT20enja": 0.171, "WMT20jaen": 0.199, "__MIFEvalJa": 0.496, "avg": 0.495}}, "sortkey": "deepseek r1 distill qwen", "url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B"}, "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {"active_params": 33, "date": "2025-01-20", "family": "Qwen2.5", "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B", "is_post": true, "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B", "name": "DeepSeek-R1-Distill-Qwen-32B", "params": 33, "pre_training": "Qwen2.5-32B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.822, "coding": 0.619, "extraction": 0.901, "humanities": 0.869, "math": 0.918, "reasoning": 0.793, "roleplay": 0.861, "stem": 0.768, "writing": 0.85}, "en_post": {"AIME": 0.567, "GPQA": 0.571, "HellaSwag": 0.885, "LCB": 0.523, "MATH500": 0.926, "MMLU-Pro": 0.737, "avg": 0.701}, "ja_mtb": {"avg": 0.753, "coding": 0.669, "extraction": 0.874, "humanities": 0.764, "math": 0.867, "reasoning": 0.606, "roleplay": 0.79, "stem": 0.738, "writing": 0.716}, "ja_post": {"GPQA": 0.536, "JHumanEval": 0.855, "JamC-QA": 0.439, "MATH100": 0.838, "MMLU-ProX": 0.66, "WMT20enja": 0.204, "WMT20jaen": 0.211, "__MIFEvalJa": 0.509, "avg": 0.535}}, "sortkey": "deepseek r1 distill qwen", "url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B"}, "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {"active_params": 7.6, "date": "2025-01-20", "family": "Qwen2.5", "id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B", "is_post": true, "model_id": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B", "name": "DeepSeek-R1-Distill-Qwen-7B", "params": 7.6, "pre_training": "Qwen2.5-Math-7B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.649, "coding": 0.481, "extraction": 0.656, "humanities": 0.708, "math": 0.762, "reasoning": 0.52, "roleplay": 0.686, "stem": 0.7, "writing": 0.677}, "en_post": {"AIME": 0.417, "GPQA": 0.495, "HellaSwag": 0.564, "LCB": 0.351, "MATH500": 0.902, "MMLU-Pro": 0.547, "avg": 0.546}, "ja_mtb": {"avg": 0.411, "coding": 0.371, "extraction": 0.572, "humanities": 0.347, "math": 0.804, "reasoning": 0.346, "roleplay": 0.275, "stem": 0.341, "writing": 0.228}, "ja_post": {"GPQA": 0.4, "JHumanEval": 0.674, "JamC-QA": 0.257, "MATH100": 0.778, "MMLU-ProX": 0.438, "WMT20enja": 0.044, "WMT20jaen": 0.082, "__MIFEvalJa": 0.341, "avg": 0.382}}, "sortkey": "deepseek r1 distill qwen", "url": "https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"}, "elyza/ELYZA-Shortcut-1.0-Qwen-32B": {"active_params": 33, "date": "2025-05-01", "family": "Qwen2.5", "id": "elyza/ELYZA-Shortcut-1.0-Qwen-32B", "is_post": true, "model_id": "elyza/ELYZA-Shortcut-1.0-Qwen-32B", "name": "ELYZA-Shortcut-1.0-Qwen-32B", "params": 33, "pre_training": "Qwen2.5-32B-Instruct", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.868, "coding": 0.834, "extraction": 0.888, "humanities": 0.892, "math": 0.89, "reasoning": 0.841, "roleplay": 0.864, "stem": 0.888, "writing": 0.845}, "en_post": {"AIME": 0.15, "GPQA": 0.46, "HellaSwag": 0.897, "LCB": 0.263, "MATH500": 0.83, "MMLU-Pro": 0.684, "avg": 0.547}, "ja_mtb": {"avg": 0.827, "coding": 0.794, "extraction": 0.876, "humanities": 0.877, "math": 0.875, "reasoning": 0.641, "roleplay": 0.873, "stem": 0.834, "writing": 0.845}, "ja_post": {"GPQA": 0.415, "JHumanEval": 0.77, "JamC-QA": 0.524, "MATH100": 0.788, "MMLU-ProX": 0.631, "WMT20enja": 0.245, "WMT20jaen": 0.228, "__MIFEvalJa": 0.633, "avg": 0.514}}, "sortkey": "elyza shortcut 1.0 qwen", "url": "https://huggingface.co/elyza/ELYZA-Shortcut-1.0-Qwen-32B"}, "elyza/ELYZA-Thinking-1.0-Qwen-32B": {"active_params": 33, "date": "2025-05-01", "family": "Qwen2.5", "id": "elyza/ELYZA-Thinking-1.0-Qwen-32B", "is_post": true, "model_id": "elyza/ELYZA-Thinking-1.0-Qwen-32B", "name": "ELYZA-Thinking-1.0-Qwen-32B", "params": 33, "pre_training": "Qwen2.5-32B-Instruct", "reasoning": "on", "results": {"en_mtb": {"avg": 0.748, "coding": 0.77, "extraction": 0.913, "humanities": 0.754, "math": 0.912, "reasoning": 0.775, "roleplay": 0.617, "stem": 0.639, "writing": 0.606}, "en_post": {"AIME": 0.3, "GPQA": 0.576, "HellaSwag": 0.888, "LCB": 0.093, "MATH500": 0.86, "MMLU-Pro": 0.708, "avg": 0.571}, "ja_mtb": {"avg": 0.694, "coding": 0.687, "extraction": 0.824, "humanities": 0.688, "math": 0.927, "reasoning": 0.641, "roleplay": 0.583, "stem": 0.656, "writing": 0.542}, "ja_post": {"GPQA": 0.455, "JHumanEval": 0.162, "JamC-QA": 0.495, "MATH100": 0.788, "MMLU-ProX": 0.623, "WMT20enja": 0.238, "WMT20jaen": 0.223, "__MIFEvalJa": 0.566, "avg": 0.426}}, "sortkey": "elyza thinking 1.0 qwen", "url": "https://huggingface.co/elyza/ELYZA-Thinking-1.0-Qwen-32B"}, "flux-inc/Flux-Japanese-Qwen2.5-32B-Instruct-V1.0": {"active_params": 33, "date": "2025-09-28", "family": "Qwen2.5", "id": "flux-inc/Flux-Japanese-Qwen2.5-32B-Instruct-V1.0", "is_post": true, "model_id": "flux-inc/Flux-Japanese-Qwen2.5-32B-Instruct-V1.0", "name": "Flux-Japanese-Qwen2.5-32B-Instruct-V1.0", "params": 33, "pre_training": "Qwen2.5-32B-Instruct", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.853, "coding": 0.789, "extraction": 0.852, "humanities": 0.885, "math": 0.957, "reasoning": 0.782, "roleplay": 0.852, "stem": 0.868, "writing": 0.838}, "en_post": {"AIME": 0.15, "GPQA": 0.51, "HellaSwag": 0.929, "LCB": 0.203, "MATH500": 0.838, "MMLU-Pro": 0.677, "avg": 0.551}, "ja_mtb": {"avg": 0.801, "coding": 0.807, "extraction": 0.819, "humanities": 0.856, "math": 0.892, "reasoning": 0.654, "roleplay": 0.791, "stem": 0.818, "writing": 0.768}, "ja_post": {"GPQA": 0.458, "JHumanEval": 0.438, "JamC-QA": 0.487, "MATH100": 0.788, "MMLU-ProX": 0.63, "WMT20enja": 0.0, "WMT20jaen": 0.219, "__MIFEvalJa": 0.54, "avg": 0.431}}, "sortkey": "flux japanese qwen2.5 v1.0", "url": "https://huggingface.co/flux-inc/Flux-Japanese-Qwen2.5-32B-Instruct-V1.0"}, "google/gemini-3-pro-preview": {"active_params": 0, "date": "2025-11-18", "family": "Gemini 3", "id": "google/gemini-3-pro-preview", "is_post": true, "model_id": "google/gemini-3-pro-preview", "name": "Gemini 3 Pro Preview (gemini-3-pro-preview)", "params": 0, "pre_training": "(private)", "reasoning": "on (high)", "results": {"en_mtb": {"avg": 0.907, "coding": 0.882, "extraction": 0.895, "humanities": 0.932, "math": 0.96, "reasoning": 0.835, "roleplay": 0.915, "stem": 0.942, "writing": 0.897}, "en_post": {"AIME": 0.95, "GPQA": 0.924, "HellaSwag": 0.948, "LCB": 0.866, "MATH500": 0.986, "MMLU-Pro": 0.885, "avg": 0.927}, "ja_mtb": {"avg": 0.906, "coding": 0.902, "extraction": 0.897, "humanities": 0.934, "math": 0.994, "reasoning": 0.865, "roleplay": 0.88, "stem": 0.901, "writing": 0.873}, "ja_post": {"GPQA": 0.844, "JHumanEval": 0.97, "JamC-QA": 0.937, "MATH100": 0.949, "MMLU-ProX": 0.873, "WMT20enja": 0.29, "WMT20jaen": 0.268, "__MIFEvalJa": 0.792, "avg": 0.733}}, "sortkey": "gemini 3 pro preview (gemini 3 pro preview)", "url": "https://huggingface.co/google/gemini-3-pro-preview"}, "google/gemma-2-27b-it": {"active_params": 27, "date": "2024-06-27", "family": "Gemma 2", "id": "google/gemma-2-27b-it", "is_post": true, "model_id": "google/gemma-2-27b-it", "name": "Gemma 2 27B IT", "params": 27, "pre_training": "Gemma 2 27B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.8, "coding": 0.701, "extraction": 0.855, "humanities": 0.891, "math": 0.724, "reasoning": 0.702, "roleplay": 0.843, "stem": 0.827, "writing": 0.858}, "en_post": {"AIME": 0.033, "GPQA": 0.404, "HellaSwag": 0.846, "LCB": 0.23, "MATH500": 0.56, "MMLU-Pro": 0.572, "avg": 0.441}, "ja_mtb": {"avg": 0.762, "coding": 0.76, "extraction": 0.825, "humanities": 0.874, "math": 0.697, "reasoning": 0.578, "roleplay": 0.818, "stem": 0.745, "writing": 0.796}, "ja_post": {"GPQA": 0.304, "JHumanEval": 0.7, "JamC-QA": 0.418, "MATH100": 0.505, "MMLU-ProX": 0.462, "WMT20enja": 0.247, "WMT20jaen": 0.236, "__MIFEvalJa": 0.588, "avg": 0.41}}, "sortkey": "gemma 2", "url": "https://huggingface.co/google/gemma-2-27b-it"}, "google/gemma-2-2b-it": {"active_params": 2.6, "date": "2024-06-27", "family": "Gemma 2", "id": "google/gemma-2-2b-it", "is_post": true, "model_id": "google/gemma-2-2b-it", "name": "Gemma 2 2B IT", "params": 2.6, "pre_training": "Gemma 2 2B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.718, "coding": 0.543, "extraction": 0.687, "humanities": 0.868, "math": 0.659, "reasoning": 0.609, "roleplay": 0.78, "stem": 0.78, "writing": 0.816}, "en_post": {"AIME": 0.0, "GPQA": 0.359, "HellaSwag": 0.596, "LCB": 0.034, "MATH500": 0.262, "MMLU-Pro": 0.287, "avg": 0.256}, "ja_mtb": {"avg": 0.555, "coding": 0.46, "extraction": 0.585, "humanities": 0.673, "math": 0.448, "reasoning": 0.422, "roleplay": 0.641, "stem": 0.571, "writing": 0.639}, "ja_post": {"GPQA": 0.248, "JHumanEval": 0.359, "JamC-QA": 0.28, "MATH100": 0.202, "MMLU-ProX": 0.214, "WMT20enja": 0.147, "WMT20jaen": 0.165, "__MIFEvalJa": 0.416, "avg": 0.231}}, "sortkey": "gemma 2", "url": "https://huggingface.co/google/gemma-2-2b-it"}, "google/gemma-2-9b-it": {"active_params": 9.2, "date": "2024-06-27", "family": "Gemma 2", "id": "google/gemma-2-9b-it", "is_post": true, "model_id": "google/gemma-2-9b-it", "name": "Gemma 2 9B IT", "params": 9.2, "pre_training": "Gemma 2 9B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.761, "coding": 0.624, "extraction": 0.799, "humanities": 0.893, "math": 0.682, "reasoning": 0.61, "roleplay": 0.832, "stem": 0.808, "writing": 0.841}, "en_post": {"AIME": 0.017, "GPQA": 0.369, "HellaSwag": 0.829, "LCB": 0.146, "MATH500": 0.488, "MMLU-Pro": 0.503, "avg": 0.392}, "ja_mtb": {"avg": 0.743, "coding": 0.635, "extraction": 0.816, "humanities": 0.865, "math": 0.686, "reasoning": 0.649, "roleplay": 0.784, "stem": 0.734, "writing": 0.773}, "ja_post": {"GPQA": 0.277, "JHumanEval": 0.583, "JamC-QA": 0.385, "MATH100": 0.444, "MMLU-ProX": 0.423, "WMT20enja": 0.223, "WMT20jaen": 0.227, "__MIFEvalJa": 0.558, "avg": 0.366}}, "sortkey": "gemma 2", "url": "https://huggingface.co/google/gemma-2-9b-it"}, "google/gemma-3-12b-it": {"active_params": 12, "date": "2025-03-12", "family": "Gemma 3", "id": "google/gemma-3-12b-it", "is_post": true, "model_id": "google/gemma-3-12b-it", "name": "Gemma 3 12B IT", "params": 12, "pre_training": "Gemma 3 12B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.86, "coding": 0.741, "extraction": 0.862, "humanities": 0.917, "math": 0.932, "reasoning": 0.758, "roleplay": 0.891, "stem": 0.899, "writing": 0.879}, "en_post": {"AIME": 0.217, "GPQA": 0.389, "HellaSwag": 0.816, "LCB": 0.247, "MATH500": 0.862, "MMLU-Pro": 0.617, "avg": 0.524}, "ja_mtb": {"avg": 0.811, "coding": 0.784, "extraction": 0.807, "humanities": 0.88, "math": 0.858, "reasoning": 0.582, "roleplay": 0.856, "stem": 0.878, "writing": 0.844}, "ja_post": {"GPQA": 0.373, "JHumanEval": 0.763, "JamC-QA": 0.401, "MATH100": 0.798, "MMLU-ProX": 0.527, "WMT20enja": 0.225, "WMT20jaen": 0.229, "__MIFEvalJa": 0.619, "avg": 0.474}}, "sortkey": "gemma 3", "url": "https://huggingface.co/google/gemma-3-12b-it"}, "google/gemma-3-1b-it": {"active_params": 1.0, "date": "2025-03-12", "family": "Gemma 3", "id": "google/gemma-3-1b-it", "is_post": true, "model_id": "google/gemma-3-1b-it", "name": "Gemma 3 1B IT", "params": 1.0, "pre_training": "Gemma 3 1B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.578, "coding": 0.503, "extraction": 0.453, "humanities": 0.719, "math": 0.709, "reasoning": 0.366, "roleplay": 0.634, "stem": 0.686, "writing": 0.553}, "en_post": {"AIME": 0.0, "GPQA": 0.237, "HellaSwag": 0.357, "LCB": 0.002, "MATH500": 0.438, "MMLU-Pro": 0.171, "avg": 0.201}, "ja_mtb": {"avg": 0.434, "coding": 0.396, "extraction": 0.484, "humanities": 0.519, "math": 0.343, "reasoning": 0.337, "roleplay": 0.519, "stem": 0.434, "writing": 0.436}, "ja_post": {"GPQA": 0.248, "JHumanEval": 0.112, "JamC-QA": 0.249, "MATH100": 0.172, "MMLU-ProX": 0.148, "WMT20enja": 0.004, "WMT20jaen": 0.083, "__MIFEvalJa": 0.323, "avg": 0.145}}, "sortkey": "gemma 3", "url": "https://huggingface.co/google/gemma-3-1b-it"}, "google/gemma-3-27b-it": {"active_params": 27, "date": "2025-03-12", "family": "Gemma 3", "id": "google/gemma-3-27b-it", "is_post": true, "model_id": "google/gemma-3-27b-it", "name": "Gemma 3 27B IT", "params": 27, "pre_training": "Gemma 3 27B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.88, "coding": 0.767, "extraction": 0.919, "humanities": 0.92, "math": 0.924, "reasoning": 0.797, "roleplay": 0.908, "stem": 0.917, "writing": 0.888}, "en_post": {"AIME": 0.233, "GPQA": 0.475, "HellaSwag": 0.861, "LCB": 0.298, "MATH500": 0.88, "MMLU-Pro": 0.681, "avg": 0.571}, "ja_mtb": {"avg": 0.83, "coding": 0.747, "extraction": 0.942, "humanities": 0.878, "math": 0.808, "reasoning": 0.733, "roleplay": 0.849, "stem": 0.853, "writing": 0.831}, "ja_post": {"GPQA": 0.417, "JHumanEval": 0.796, "JamC-QA": 0.488, "MATH100": 0.859, "MMLU-ProX": 0.609, "WMT20enja": 0.25, "WMT20jaen": 0.238, "__MIFEvalJa": 0.597, "avg": 0.522}}, "sortkey": "gemma 3", "url": "https://huggingface.co/google/gemma-3-27b-it"}, "google/gemma-3-4b-it": {"active_params": 4.3, "date": "2025-03-12", "family": "Gemma 3", "id": "google/gemma-3-4b-it", "is_post": true, "model_id": "google/gemma-3-4b-it", "name": "Gemma 3 4B IT", "params": 4.3, "pre_training": "Gemma 3 4B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.793, "coding": 0.704, "extraction": 0.762, "humanities": 0.901, "math": 0.855, "reasoning": 0.553, "roleplay": 0.869, "stem": 0.845, "writing": 0.857}, "en_post": {"AIME": 0.117, "GPQA": 0.354, "HellaSwag": 0.62, "LCB": 0.151, "MATH500": 0.748, "MMLU-Pro": 0.44, "avg": 0.405}, "ja_mtb": {"avg": 0.735, "coding": 0.727, "extraction": 0.65, "humanities": 0.814, "math": 0.826, "reasoning": 0.482, "roleplay": 0.787, "stem": 0.796, "writing": 0.802}, "ja_post": {"GPQA": 0.246, "JHumanEval": 0.604, "JamC-QA": 0.285, "MATH100": 0.606, "MMLU-ProX": 0.335, "WMT20enja": 0.186, "WMT20jaen": 0.189, "__MIFEvalJa": 0.473, "avg": 0.35}}, "sortkey": "gemma 3", "url": "https://huggingface.co/google/gemma-3-4b-it"}, "google/medgemma-27b-it": {"active_params": 27, "date": "2025-07-09", "family": "Gemma 3", "id": "google/medgemma-27b-it", "is_post": true, "model_id": "google/medgemma-27b-it", "name": "MedGemma 27B IT", "params": 27, "pre_training": "Gemma 3 27B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.83, "coding": 0.722, "extraction": 0.914, "humanities": 0.884, "math": 0.97, "reasoning": 0.735, "roleplay": 0.819, "stem": 0.858, "writing": 0.737}, "en_post": {"AIME": 0.2, "GPQA": 0.434, "HellaSwag": 0.859, "LCB": 0.001, "MATH500": 0.824, "MMLU-Pro": 0.654, "avg": 0.495}, "ja_mtb": {"avg": 0.778, "coding": 0.799, "extraction": 0.926, "humanities": 0.805, "math": 0.883, "reasoning": 0.646, "roleplay": 0.718, "stem": 0.758, "writing": 0.686}, "ja_post": {"GPQA": 0.35, "JHumanEval": 0.001, "JamC-QA": 0.456, "MATH100": 0.818, "MMLU-ProX": 0.606, "WMT20enja": 0.253, "WMT20jaen": 0.24, "__MIFEvalJa": 0.624, "avg": 0.389}}, "sortkey": "medgemma", "url": "https://huggingface.co/google/medgemma-27b-it"}, "gpt-4.1-2025-04-14": {"active_params": 0, "date": "2025-04-14", "family": "GPT-4.1", "id": "gpt-4.1-2025-04-14", "is_post": true, "model_id": "gpt-4.1-2025-04-14", "name": "GPT-4.1 (gpt-4.1-2025-04-14)", "params": 0, "pre_training": "(private)", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.908, "coding": 0.898, "extraction": 0.936, "humanities": 0.903, "math": 0.942, "reasoning": 0.863, "roleplay": 0.901, "stem": 0.925, "writing": 0.898}, "en_post": {"AIME": 0.4, "GPQA": 0.667, "HellaSwag": 0.94, "LCB": 0.387, "MATH500": 0.906, "MMLU-Pro": 0.813, "avg": 0.685}, "ja_mtb": {"avg": 0.892, "coding": 0.917, "extraction": 0.911, "humanities": 0.885, "math": 0.98, "reasoning": 0.819, "roleplay": 0.879, "stem": 0.887, "writing": 0.858}, "ja_post": {"GPQA": 0.603, "JHumanEval": 0.911, "JamC-QA": 0.79, "MATH100": 0.899, "MMLU-ProX": 0.772, "WMT20enja": 0.278, "WMT20jaen": 0.26, "__MIFEvalJa": 0.81, "avg": 0.645}}, "sortkey": "gpt 4.1 (gpt 4.1 2025 04 14)", "url": "https://platform.openai.com/docs/models"}, "gpt-4o-2024-08-06": {"active_params": 0, "date": "2024-08-06", "family": "GPT-4o", "id": "gpt-4o-2024-08-06", "is_post": true, "model_id": "gpt-4o-2024-08-06", "name": "GPT-4o (gpt-4o-2024-08-06)", "params": 0, "pre_training": "(private)", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.922, "coding": 0.943, "extraction": 0.927, "humanities": 0.896, "math": 0.993, "reasoning": 0.976, "roleplay": 0.874, "stem": 0.905, "writing": 0.865}, "en_post": {"AIME": 0.083, "GPQA": 0.556, "HellaSwag": 0.93, "LCB": 0.25, "MATH500": 0.792, "MMLU-Pro": 0.749, "avg": 0.56}, "ja_mtb": {"avg": 0.865, "coding": 0.896, "extraction": 0.929, "humanities": 0.874, "math": 0.895, "reasoning": 0.755, "roleplay": 0.869, "stem": 0.847, "writing": 0.855}, "ja_post": {"GPQA": 0.453, "JHumanEval": 0.844, "JamC-QA": 0.747, "MATH100": 0.758, "MMLU-ProX": 0.685, "WMT20enja": 0.282, "WMT20jaen": 0.265, "__MIFEvalJa": 0.704, "avg": 0.576}}, "sortkey": "gpt 4o (gpt 4o 2024 08 06)", "url": "https://platform.openai.com/docs/models"}, "gpt-5-2025-08-07": {"active_params": 0, "date": "2025-08-07", "family": "GPT-5", "id": "gpt-5-2025-08-07", "is_post": true, "model_id": "gpt-5-2025-08-07", "name": "GPT-5 (gpt-5-2025-08-07)", "params": 0, "pre_training": "(private)", "reasoning": "on (medium)", "results": {"en_mtb": {"avg": 0.888, "coding": 0.876, "extraction": 0.912, "humanities": 0.923, "math": 0.843, "reasoning": 0.811, "roleplay": 0.906, "stem": 0.927, "writing": 0.904}, "en_post": {"AIME": 0.933, "GPQA": 0.828, "HellaSwag": 0.959, "LCB": 0.677, "MATH500": 0.99, "MMLU-Pro": 0.865, "avg": 0.875}, "ja_mtb": {"avg": 0.882, "coding": 0.893, "extraction": 0.883, "humanities": 0.928, "math": 0.882, "reasoning": 0.758, "roleplay": 0.896, "stem": 0.933, "writing": 0.885}, "ja_post": {"GPQA": 0.786, "JHumanEval": 0.943, "JamC-QA": 0.858, "MATH100": 0.98, "MMLU-ProX": 0.849, "WMT20enja": 0.272, "WMT20jaen": 0.236, "__MIFEvalJa": 0.907, "avg": 0.703}}, "sortkey": "gpt 5 (gpt 5 2025 08 07)", "url": "https://platform.openai.com/docs/models"}, "gpt-5-mini-2025-08-07": {"active_params": 0, "date": "2025-08-07", "family": "GPT-5", "id": "gpt-5-mini-2025-08-07", "is_post": true, "model_id": "gpt-5-mini-2025-08-07", "name": "GPT-5 mini (gpt-5-mini-2025-08-07)", "params": 0, "pre_training": "(private)", "reasoning": "on (medium)", "results": {"en_mtb": {"avg": 0.902, "coding": 0.914, "extraction": 0.882, "humanities": 0.925, "math": 0.925, "reasoning": 0.835, "roleplay": 0.905, "stem": 0.939, "writing": 0.89}, "en_post": {"AIME": 0.883, "GPQA": 0.692, "HellaSwag": 0.934, "LCB": 0.686, "MATH500": 0.97, "MMLU-Pro": 0.822, "avg": 0.831}, "ja_mtb": {"avg": 0.898, "coding": 0.912, "extraction": 0.907, "humanities": 0.902, "math": 0.949, "reasoning": 0.834, "roleplay": 0.871, "stem": 0.937, "writing": 0.875}, "ja_post": {"GPQA": 0.75, "JHumanEval": 0.945, "JamC-QA": 0.701, "MATH100": 0.96, "MMLU-ProX": 0.805, "WMT20enja": 0.267, "WMT20jaen": 0.239, "__MIFEvalJa": 0.827, "avg": 0.667}}, "sortkey": "gpt 5 mini (gpt 5 mini 2025 08 07)", "url": "https://platform.openai.com/docs/models"}, "llm-jp/llm-jp-3.1-1.8b-instruct4": {"active_params": 1.8, "date": "2025-05-30", "family": "llm-jp-3", "id": "llm-jp/llm-jp-3.1-1.8b-instruct4", "is_post": true, "model_id": "llm-jp/llm-jp-3.1-1.8b-instruct4", "name": "llm-jp-3.1-1.8b-instruct4", "params": 1.8, "pre_training": "llm-jp-3.1-1.8b", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.548, "coding": 0.454, "extraction": 0.482, "humanities": 0.662, "math": 0.521, "reasoning": 0.364, "roleplay": 0.665, "stem": 0.563, "writing": 0.673}, "en_post": {"AIME": 0.0, "GPQA": 0.278, "HellaSwag": 0.45, "LCB": 0.03, "MATH500": 0.146, "MMLU-Pro": 0.163, "avg": 0.178}, "ja_mtb": {"avg": 0.657, "coding": 0.574, "extraction": 0.601, "humanities": 0.809, "math": 0.672, "reasoning": 0.446, "roleplay": 0.767, "stem": 0.697, "writing": 0.693}, "ja_post": {"GPQA": 0.239, "JHumanEval": 0.365, "JamC-QA": 0.348, "MATH100": 0.212, "MMLU-ProX": 0.195, "WMT20enja": 0.0, "WMT20jaen": 0.159, "__MIFEvalJa": 0.288, "avg": 0.217}}, "sortkey": "llm jp 3.1 4", "url": "https://huggingface.co/llm-jp/llm-jp-3.1-1.8b-instruct4"}, "llm-jp/llm-jp-3.1-13b-instruct4": {"active_params": 14, "date": "2025-05-30", "family": "llm-jp-3", "id": "llm-jp/llm-jp-3.1-13b-instruct4", "is_post": true, "model_id": "llm-jp/llm-jp-3.1-13b-instruct4", "name": "llm-jp-3.1-13b-instruct4", "params": 14, "pre_training": "llm-jp-3.1-13b", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.682, "coding": 0.562, "extraction": 0.681, "humanities": 0.844, "math": 0.625, "reasoning": 0.512, "roleplay": 0.736, "stem": 0.715, "writing": 0.779}, "en_post": {"AIME": 0.0, "GPQA": 0.227, "HellaSwag": 0.717, "LCB": 0.082, "MATH500": 0.188, "MMLU-Pro": 0.252, "avg": 0.244}, "ja_mtb": {"avg": 0.733, "coding": 0.587, "extraction": 0.7, "humanities": 0.87, "math": 0.731, "reasoning": 0.559, "roleplay": 0.831, "stem": 0.775, "writing": 0.807}, "ja_post": {"GPQA": 0.23, "JHumanEval": 0.463, "JamC-QA": 0.509, "MATH100": 0.232, "MMLU-ProX": 0.296, "WMT20enja": 0.007, "WMT20jaen": 0.161, "__MIFEvalJa": 0.372, "avg": 0.271}}, "sortkey": "llm jp 3.1 4", "url": "https://huggingface.co/llm-jp/llm-jp-3.1-13b-instruct4"}, "meta-llama/Llama-3.3-70B-Instruct": {"active_params": 70, "date": "2024-12-06", "family": "Llama 3", "id": "meta-llama/Llama-3.3-70B-Instruct", "is_post": true, "model_id": "meta-llama/Llama-3.3-70B-Instruct", "name": "Llama 3.3 70B Instruct", "params": 70, "pre_training": "Llama 3.1 70B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.863, "coding": 0.795, "extraction": 0.935, "humanities": 0.891, "math": 0.895, "reasoning": 0.861, "roleplay": 0.858, "stem": 0.822, "writing": 0.847}, "en_post": {"AIME": 0.117, "GPQA": 0.48, "HellaSwag": 0.911, "LCB": 0.303, "MATH500": 0.746, "MMLU-Pro": 0.717, "avg": 0.545}, "ja_mtb": {"avg": 0.735, "coding": 0.672, "extraction": 0.878, "humanities": 0.751, "math": 0.742, "reasoning": 0.638, "roleplay": 0.762, "stem": 0.735, "writing": 0.7}, "ja_post": {"GPQA": 0.453, "JHumanEval": 0.752, "JamC-QA": 0.484, "MATH100": 0.646, "MMLU-ProX": 0.607, "WMT20enja": 0.245, "WMT20jaen": 0.246, "__MIFEvalJa": 0.65, "avg": 0.491}}, "sortkey": "llama 3.3", "url": "https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct"}, "meta-llama/Llama-4-Scout-17B-16E-Instruct": {"active_params": 17, "date": "2025-04-04", "family": "Llama 4", "id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "is_post": true, "model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct", "name": "Llama 4 Scout Instruct", "params": 109, "pre_training": "Llama 4 Scout", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.857, "coding": 0.722, "extraction": 0.911, "humanities": 0.86, "math": 0.92, "reasoning": 0.904, "roleplay": 0.836, "stem": 0.84, "writing": 0.862}, "en_post": {"AIME": 0.183, "GPQA": 0.606, "HellaSwag": 0.891, "LCB": 0.309, "MATH500": 0.834, "MMLU-Pro": 0.744, "avg": 0.594}, "ja_mtb": {"avg": 0.789, "coding": 0.763, "extraction": 0.923, "humanities": 0.816, "math": 0.879, "reasoning": 0.615, "roleplay": 0.787, "stem": 0.752, "writing": 0.778}, "ja_post": {"GPQA": 0.54, "JHumanEval": 0.82, "JamC-QA": 0.579, "MATH100": 0.758, "MMLU-ProX": 0.687, "WMT20enja": 0.237, "WMT20jaen": 0.23, "__MIFEvalJa": 0.611, "avg": 0.55}}, "sortkey": "llama 4 scout", "url": "https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct"}, "meta-llama/Meta-Llama-3.1-8B-Instruct": {"active_params": 8.0, "date": "2024-07-23", "family": "Llama 3", "id": "meta-llama/Meta-Llama-3.1-8B-Instruct", "is_post": true, "model_id": "meta-llama/Meta-Llama-3.1-8B-Instruct", "name": "Llama 3.1 8B Instruct", "params": 8.0, "pre_training": "Llama 3.1 8B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.737, "coding": 0.556, "extraction": 0.816, "humanities": 0.871, "math": 0.697, "reasoning": 0.522, "roleplay": 0.821, "stem": 0.765, "writing": 0.85}, "en_post": {"AIME": 0.033, "GPQA": 0.374, "HellaSwag": 0.769, "LCB": 0.131, "MATH500": 0.526, "MMLU-Pro": 0.489, "avg": 0.387}, "ja_mtb": {"avg": 0.592, "coding": 0.528, "extraction": 0.848, "humanities": 0.585, "math": 0.6, "reasoning": 0.465, "roleplay": 0.569, "stem": 0.562, "writing": 0.577}, "ja_post": {"GPQA": 0.261, "JHumanEval": 0.58, "JamC-QA": 0.31, "MATH100": 0.384, "MMLU-ProX": 0.306, "WMT20enja": 0.187, "WMT20jaen": 0.194, "__MIFEvalJa": 0.381, "avg": 0.317}}, "sortkey": "llama 3.1", "url": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct"}, "microsoft/phi-4": {"active_params": 15, "date": "2024-12-13", "family": "Phi 4", "id": "microsoft/phi-4", "is_post": true, "model_id": "microsoft/phi-4", "name": "Phi-4", "params": 15, "pre_training": "(private)", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.881, "coding": 0.771, "extraction": 0.904, "humanities": 0.876, "math": 0.928, "reasoning": 0.933, "roleplay": 0.889, "stem": 0.879, "writing": 0.865}, "en_post": {"AIME": 0.217, "GPQA": 0.551, "HellaSwag": 0.859, "LCB": 0.227, "MATH500": 0.8, "MMLU-Pro": 0.63, "avg": 0.547}, "ja_mtb": {"avg": 0.822, "coding": 0.752, "extraction": 0.933, "humanities": 0.862, "math": 0.89, "reasoning": 0.629, "roleplay": 0.83, "stem": 0.845, "writing": 0.835}, "ja_post": {"GPQA": 0.435, "JHumanEval": 0.77, "JamC-QA": 0.444, "MATH100": 0.798, "MMLU-ProX": 0.638, "WMT20enja": 0.24, "WMT20jaen": 0.221, "__MIFEvalJa": 0.438, "avg": 0.507}}, "sortkey": "phi 4", "url": "https://huggingface.co/microsoft/phi-4"}, "microsoft/phi-4-reasoning-plus": {"active_params": 15, "date": "2025-04-30", "family": "Phi 4", "id": "microsoft/phi-4-reasoning-plus", "is_post": true, "model_id": "microsoft/phi-4-reasoning-plus", "name": "Phi-4-reasoning-plus", "params": 15, "pre_training": "(private)", "reasoning": "on", "results": {"en_mtb": {"avg": 0.426, "coding": 0.281, "extraction": 0.384, "humanities": 0.116, "math": 0.437, "reasoning": 0.322, "roleplay": 0.769, "stem": 0.299, "writing": 0.8}, "en_post": {"AIME": 0.583, "GPQA": 0.611, "HellaSwag": 0.26, "LCB": 0.478, "MATH500": 0.77, "MMLU-Pro": 0.113, "avg": 0.469}, "ja_mtb": {"avg": 0.374, "coding": 0.205, "extraction": 0.376, "humanities": 0.206, "math": 0.379, "reasoning": 0.283, "roleplay": 0.643, "stem": 0.162, "writing": 0.741}, "ja_post": {"GPQA": 0.563, "JHumanEval": 0.751, "JamC-QA": 0.0, "MATH100": 0.737, "MMLU-ProX": 0.118, "WMT20enja": 0.001, "WMT20jaen": 0.001, "__MIFEvalJa": 0.221, "avg": 0.31}}, "sortkey": "phi 4 reasoning plus", "url": "https://huggingface.co/microsoft/phi-4-reasoning-plus"}, "nvidia/Llama-3.1-Nemotron-Nano-8B-v1": {"active_params": 8.0, "date": "2025-03-18", "family": "Llama 3", "id": "nvidia/Llama-3.1-Nemotron-Nano-8B-v1", "is_post": true, "model_id": "nvidia/Llama-3.1-Nemotron-Nano-8B-v1", "name": "Llama-3.1-Nemotron-Nano-8B-v1", "params": 8.0, "pre_training": "Llama 3.1 8B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.701, "coding": 0.658, "extraction": 0.654, "humanities": 0.696, "math": 0.906, "reasoning": 0.526, "roleplay": 0.712, "stem": 0.738, "writing": 0.72}, "en_post": {"AIME": 0.55, "GPQA": 0.47, "HellaSwag": 0.518, "LCB": 0.478, "MATH500": 0.948, "MMLU-Pro": 0.566, "avg": 0.588}, "ja_mtb": {"avg": 0.363, "coding": 0.374, "extraction": 0.503, "humanities": 0.311, "math": 0.564, "reasoning": 0.27, "roleplay": 0.289, "stem": 0.301, "writing": 0.293}, "ja_post": {"GPQA": 0.339, "JHumanEval": 0.802, "JamC-QA": 0.264, "MATH100": 0.919, "MMLU-ProX": 0.489, "WMT20enja": 0.065, "WMT20jaen": 0.08, "__MIFEvalJa": 0.186, "avg": 0.423}}, "sortkey": "llama 3.1 nemotron nano v1", "url": "https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-8B-v1"}, "nvidia/Llama-3_3-Nemotron-Super-49B-v1": {"active_params": 50, "date": "2025-03-18", "family": "Llama 3", "id": "nvidia/Llama-3_3-Nemotron-Super-49B-v1", "is_post": true, "model_id": "nvidia/Llama-3_3-Nemotron-Super-49B-v1", "name": "Llama-3.3-Nemotron-Super-49B-v1", "params": 50, "pre_training": "Llama 3.3 70B Instruct", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.881, "coding": 0.782, "extraction": 0.915, "humanities": 0.91, "math": 0.963, "reasoning": 0.8, "roleplay": 0.878, "stem": 0.908, "writing": 0.893}, "en_post": {"AIME": 0.567, "GPQA": 0.667, "HellaSwag": 0.885, "LCB": 0.408, "MATH500": 0.96, "MMLU-Pro": 0.783, "avg": 0.711}, "ja_mtb": {"avg": 0.806, "coding": 0.731, "extraction": 0.898, "humanities": 0.821, "math": 0.801, "reasoning": 0.755, "roleplay": 0.804, "stem": 0.809, "writing": 0.828}, "ja_post": {"GPQA": 0.531, "JHumanEval": 0.9, "JamC-QA": 0.446, "MATH100": 0.919, "MMLU-ProX": 0.687, "WMT20enja": 0.215, "WMT20jaen": 0.185, "__MIFEvalJa": 0.558, "avg": 0.555}}, "sortkey": "llama 3.3 nemotron super v1", "url": "https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1"}, "o3-2025-04-16": {"active_params": 0, "date": "2025-04-16", "family": "o3", "id": "o3-2025-04-16", "is_post": true, "model_id": "o3-2025-04-16", "name": "o3 (o3-2025-04-16)", "params": 0, "pre_training": "(private)", "reasoning": "on (medium)", "results": {"en_mtb": {"avg": 0.917, "coding": 0.929, "extraction": 0.931, "humanities": 0.945, "math": 0.964, "reasoning": 0.836, "roleplay": 0.9, "stem": 0.938, "writing": 0.892}, "en_post": {"AIME": 0.817, "GPQA": 0.818, "HellaSwag": 0.956, "LCB": 0.649, "MATH500": 0.978, "MMLU-Pro": 0.857, "avg": 0.846}, "ja_mtb": {"avg": 0.903, "coding": 0.935, "extraction": 0.898, "humanities": 0.888, "math": 0.995, "reasoning": 0.809, "roleplay": 0.889, "stem": 0.941, "writing": 0.867}, "ja_post": {"GPQA": 0.766, "JHumanEval": 0.929, "JamC-QA": 0.851, "MATH100": 0.97, "MMLU-ProX": 0.835, "WMT20enja": 0.276, "WMT20jaen": 0.216, "__MIFEvalJa": 0.85, "avg": 0.692}}, "sortkey": "o3 (o3 2025 04 16)", "url": "https://platform.openai.com/docs/models"}, "o3-mini-2025-01-31": {"active_params": 0, "date": "2025-01-31", "family": "o3", "id": "o3-mini-2025-01-31", "is_post": true, "model_id": "o3-mini-2025-01-31", "name": "o3-mini (o3-mini-2025-01-31)", "params": 0, "pre_training": "(private)", "reasoning": "on (medium)", "results": {"en_mtb": {"avg": 0.901, "coding": 0.876, "extraction": 0.913, "humanities": 0.891, "math": 0.969, "reasoning": 0.865, "roleplay": 0.895, "stem": 0.914, "writing": 0.882}, "en_post": {"AIME": 0.733, "GPQA": 0.747, "HellaSwag": 0.869, "LCB": 0.503, "MATH500": 0.958, "MMLU-Pro": 0.792, "avg": 0.767}, "ja_mtb": {"avg": 0.88, "coding": 0.868, "extraction": 0.937, "humanities": 0.86, "math": 0.952, "reasoning": 0.802, "roleplay": 0.863, "stem": 0.893, "writing": 0.868}, "ja_post": {"GPQA": 0.685, "JHumanEval": 0.934, "JamC-QA": 0.507, "MATH100": 0.939, "MMLU-ProX": 0.76, "WMT20enja": 0.243, "WMT20jaen": 0.221, "__MIFEvalJa": 0.841, "avg": 0.613}}, "sortkey": "o3 mini (o3 mini 2025 01 31)", "url": "https://platform.openai.com/docs/models"}, "openai/gpt-5.1-2025-11-13": {"active_params": 0, "date": "2025-11-13", "family": "GPT-5.1", "id": "openai/gpt-5.1-2025-11-13", "is_post": true, "model_id": "openai/gpt-5.1-2025-11-13", "name": "GPT-5.1 Thinking (gpt-5.1-2025-11-13)", "params": 0, "pre_training": "(private)", "reasoning": "on (high)", "results": {"en_mtb": {"avg": 0.907, "coding": 0.896, "extraction": 0.914, "humanities": 0.922, "math": 0.932, "reasoning": 0.848, "roleplay": 0.905, "stem": 0.947, "writing": 0.893}, "en_post": {"AIME": 0.933, "GPQA": 0.874, "HellaSwag": 0.959, "LCB": -0.001, "MATH500": 0.992, "MMLU-Pro": 0.788, "avg": 0.591}, "ja_mtb": {"avg": 0.905, "coding": 0.869, "extraction": 0.923, "humanities": 0.95, "math": 0.98, "reasoning": 0.779, "roleplay": 0.909, "stem": 0.927, "writing": 0.899}, "ja_post": {"GPQA": 0.792, "JHumanEval": 0.954, "JamC-QA": 0.851, "MATH100": 0.97, "MMLU-ProX": 0.851, "WMT20enja": 0.264, "WMT20jaen": 0.225, "__MIFEvalJa": 0.885, "avg": 0.701}}, "sortkey": "gpt 5.1 thinking (gpt 5.1 2025 11 13)", "url": "https://huggingface.co/openai/gpt-5.1-2025-11-13"}, "openai/gpt-oss-120b": {"active_params": 5.1, "date": "2025-08-05", "family": "gpt-oss", "id": "openai/gpt-oss-120b", "is_post": true, "model_id": "openai/gpt-oss-120b", "name": "gpt-oss-120b", "params": 120, "pre_training": "(private)", "reasoning": "on (medium)", "results": {"en_mtb": {"avg": 0.918, "coding": 0.947, "extraction": 0.892, "humanities": 0.915, "math": 0.989, "reasoning": 0.871, "roleplay": 0.886, "stem": 0.96, "writing": 0.886}, "en_post": {"AIME": 0.733, "GPQA": 0.727, "HellaSwag": 0.878, "LCB": 0.67, "MATH500": 0.966, "MMLU-Pro": 0.79, "avg": 0.794}, "ja_mtb": {"avg": 0.907, "coding": 0.898, "extraction": 0.924, "humanities": 0.915, "math": 0.999, "reasoning": 0.862, "roleplay": 0.855, "stem": 0.948, "writing": 0.852}, "ja_post": {"GPQA": 0.663, "JHumanEval": 0.925, "JamC-QA": 0.516, "MATH100": 0.97, "MMLU-ProX": 0.756, "WMT20enja": 0.263, "WMT20jaen": 0.207, "__MIFEvalJa": 0.735, "avg": 0.614}}, "sortkey": "gpt oss", "url": "https://huggingface.co/openai/gpt-oss-120b"}, "openai/gpt-oss-20b": {"active_params": 3.6, "date": "2025-08-05", "family": "gpt-oss", "id": "openai/gpt-oss-20b", "is_post": true, "model_id": "openai/gpt-oss-20b", "name": "gpt-oss-20b", "params": 22, "pre_training": "(private)", "reasoning": "on (medium)", "results": {"en_mtb": {"avg": 0.889, "coding": 0.913, "extraction": 0.881, "humanities": 0.935, "math": 0.913, "reasoning": 0.779, "roleplay": 0.88, "stem": 0.939, "writing": 0.869}, "en_post": {"AIME": 0.617, "GPQA": 0.636, "HellaSwag": 0.847, "LCB": 0.635, "MATH500": 0.944, "MMLU-Pro": 0.741, "avg": 0.737}, "ja_mtb": {"avg": 0.869, "coding": 0.914, "extraction": 0.917, "humanities": 0.853, "math": 0.994, "reasoning": 0.772, "roleplay": 0.772, "stem": 0.909, "writing": 0.824}, "ja_post": {"GPQA": 0.571, "JHumanEval": 0.927, "JamC-QA": 0.403, "MATH100": 0.929, "MMLU-ProX": 0.702, "WMT20enja": 0.239, "WMT20jaen": 0.208, "__MIFEvalJa": 0.549, "avg": 0.568}}, "sortkey": "gpt oss", "url": "https://huggingface.co/openai/gpt-oss-20b"}, "rinna/qwq-bakeneko-32b": {"active_params": 33, "date": "2025-03-13", "family": "Qwen2.5", "id": "rinna/qwq-bakeneko-32b", "is_post": true, "model_id": "rinna/qwq-bakeneko-32b", "name": "QwQ Bakeneko 32B", "params": 33, "pre_training": "Qwen2.5 Bakeneko 32B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.871, "coding": 0.848, "extraction": 0.821, "humanities": 0.883, "math": 0.967, "reasoning": 0.816, "roleplay": 0.851, "stem": 0.892, "writing": 0.89}, "en_post": {"AIME": 0.567, "GPQA": 0.611, "HellaSwag": 0.903, "LCB": 0.513, "MATH500": 0.942, "MMLU-Pro": 0.773, "avg": 0.718}, "ja_mtb": {"avg": 0.879, "coding": 0.839, "extraction": 0.903, "humanities": 0.886, "math": 0.969, "reasoning": 0.838, "roleplay": 0.857, "stem": 0.892, "writing": 0.85}, "ja_post": {"GPQA": 0.487, "JHumanEval": 0.867, "JamC-QA": 0.495, "MATH100": 0.859, "MMLU-ProX": 0.677, "WMT20enja": 0.232, "WMT20jaen": 0.207, "__MIFEvalJa": 0.584, "avg": 0.546}}, "sortkey": "qwq bakeneko", "url": "https://huggingface.co/rinna/qwq-bakeneko-32b"}, "sbintuitions/sarashina2.2-3b-instruct-v0.1": {"active_params": 3.4, "date": "2025-03-07", "family": "Sarashina2", "id": "sbintuitions/sarashina2.2-3b-instruct-v0.1", "is_post": true, "model_id": "sbintuitions/sarashina2.2-3b-instruct-v0.1", "name": "Sarashina2.2 3B Instruct v0.1", "params": 3.4, "pre_training": "Sarashina2.2 3B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.708, "coding": 0.499, "extraction": 0.642, "humanities": 0.863, "math": 0.747, "reasoning": 0.552, "roleplay": 0.783, "stem": 0.827, "writing": 0.75}, "en_post": {"AIME": 0.017, "GPQA": 0.293, "HellaSwag": 0.613, "LCB": 0.086, "MATH500": 0.57, "MMLU-Pro": 0.329, "avg": 0.318}, "ja_mtb": {"avg": 0.721, "coding": 0.579, "extraction": 0.68, "humanities": 0.862, "math": 0.828, "reasoning": 0.467, "roleplay": 0.832, "stem": 0.766, "writing": 0.752}, "ja_post": {"GPQA": 0.301, "JHumanEval": 0.464, "JamC-QA": 0.498, "MATH100": 0.465, "MMLU-ProX": 0.335, "WMT20enja": 0.002, "WMT20jaen": 0.16, "__MIFEvalJa": 0.288, "avg": 0.318}}, "sortkey": "sarashina2.2 v0.1", "url": "https://huggingface.co/sbintuitions/sarashina2.2-3b-instruct-v0.1"}, "swiss-ai/Apertus-70B-Instruct-2509": {"active_params": 71, "date": "2025-09-02", "family": "Apertus", "id": "swiss-ai/Apertus-70B-Instruct-2509", "is_post": true, "model_id": "swiss-ai/Apertus-70B-Instruct-2509", "name": "Apertus-70B-Instruct", "params": 71, "pre_training": "Apertus-70B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.74, "coding": 0.587, "extraction": 0.732, "humanities": 0.896, "math": 0.608, "reasoning": 0.64, "roleplay": 0.8, "stem": 0.815, "writing": 0.844}, "en_post": {"AIME": 0.0, "GPQA": 0.253, "HellaSwag": 0.745, "LCB": 0.084, "MATH500": 0.386, "MMLU-Pro": 0.422, "avg": 0.315}, "ja_mtb": {"avg": 0.675, "coding": 0.558, "extraction": 0.709, "humanities": 0.848, "math": 0.486, "reasoning": 0.443, "roleplay": 0.811, "stem": 0.767, "writing": 0.774}, "ja_post": {"GPQA": 0.266, "JHumanEval": 0.438, "JamC-QA": 0.469, "MATH100": 0.263, "MMLU-ProX": 0.355, "WMT20enja": 0.255, "WMT20jaen": 0.228, "__MIFEvalJa": 0.549, "avg": 0.325}}, "sortkey": "apertus", "url": "https://huggingface.co/swiss-ai/Apertus-70B-Instruct-2509"}, "swiss-ai/Apertus-8B-Instruct-2509": {"active_params": 8.1, "date": "2025-09-02", "family": "Apertus", "id": "swiss-ai/Apertus-8B-Instruct-2509", "is_post": true, "model_id": "swiss-ai/Apertus-8B-Instruct-2509", "name": "Apertus-8B-Instruct", "params": 8.1, "pre_training": "Apertus-8B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.628, "coding": 0.494, "extraction": 0.601, "humanities": 0.817, "math": 0.423, "reasoning": 0.445, "roleplay": 0.787, "stem": 0.682, "writing": 0.775}, "en_post": {"AIME": 0.0, "GPQA": 0.293, "HellaSwag": 0.636, "LCB": 0.075, "MATH500": 0.288, "MMLU-Pro": 0.321, "avg": 0.269}, "ja_mtb": {"avg": 0.576, "coding": 0.478, "extraction": 0.525, "humanities": 0.728, "math": 0.352, "reasoning": 0.446, "roleplay": 0.697, "stem": 0.672, "writing": 0.707}, "ja_post": {"GPQA": 0.214, "JHumanEval": 0.353, "JamC-QA": 0.366, "MATH100": 0.172, "MMLU-ProX": 0.221, "WMT20enja": 0.01, "WMT20jaen": 0.214, "__MIFEvalJa": 0.487, "avg": 0.221}}, "sortkey": "apertus", "url": "https://huggingface.co/swiss-ai/Apertus-8B-Instruct-2509"}, "tokyotech-llm/GPT-OSS-Swallow-120B-RL-v0.1": {"active_params": 5.1, "date": "2026-02-20", "family": "gpt-oss", "id": "tokyotech-llm/GPT-OSS-Swallow-120B-RL-v0.1", "is_post": true, "model_id": "tokyotech-llm/GPT-OSS-Swallow-120B-RL-v0.1", "name": "GPT-OSS-Swallow-120B-RL-v0.1", "params": 120, "pre_training": "GPT-OSS-Swallow-120B-SFT-v0.1", "reasoning": "on", "results": {"en_mtb": {"avg": 0.905, "coding": 0.885, "extraction": 0.9, "humanities": 0.896, "math": 0.934, "reasoning": 0.873, "roleplay": 0.906, "stem": 0.966, "writing": 0.878}, "en_post": {"AIME": 0.883, "GPQA": 0.641, "HellaSwag": 0.855, "LCB": 0.723, "MATH500": 0.988, "MMLU-Pro": 0.732, "avg": 0.804}, "ja_mtb": {"avg": 0.916, "coding": 0.901, "extraction": 0.959, "humanities": 0.928, "math": 0.977, "reasoning": 0.848, "roleplay": 0.915, "stem": 0.937, "writing": 0.864}, "ja_post": {"GPQA": 0.705, "JHumanEval": 0.935, "JamC-QA": 0.63, "MATH100": 0.96, "MMLU-ProX": 0.775, "WMT20enja": 0.266, "WMT20jaen": 0.221, "__MIFEvalJa": 0.695, "avg": 0.642}}, "sortkey": "gpt oss swallow rl v0.1", "url": "https://huggingface.co/tokyotech-llm/GPT-OSS-Swallow-120B-RL-v0.1"}, "tokyotech-llm/GPT-OSS-Swallow-120B-SFT-v0.1": {"active_params": 5.1, "date": "2026-02-20", "family": "gpt-oss", "id": "tokyotech-llm/GPT-OSS-Swallow-120B-SFT-v0.1", "is_post": true, "model_id": "tokyotech-llm/GPT-OSS-Swallow-120B-SFT-v0.1", "name": "GPT-OSS-Swallow-120B-SFT-v0.1", "params": 120, "pre_training": "GPT-OSS-Swallow-120B-CPT-v0.1", "reasoning": "on", "results": {"en_mtb": {"avg": 0.894, "coding": 0.895, "extraction": 0.923, "humanities": 0.903, "math": 0.994, "reasoning": 0.801, "roleplay": 0.873, "stem": 0.912, "writing": 0.852}, "en_post": {"AIME": 0.717, "GPQA": 0.712, "HellaSwag": 0.878, "LCB": 0.655, "MATH500": 0.966, "MMLU-Pro": 0.779, "avg": 0.785}, "ja_mtb": {"avg": 0.902, "coding": 0.934, "extraction": 0.928, "humanities": 0.905, "math": 1.0, "reasoning": 0.793, "roleplay": 0.883, "stem": 0.928, "writing": 0.847}, "ja_post": {"GPQA": 0.636, "JHumanEval": 0.922, "JamC-QA": 0.589, "MATH100": 0.929, "MMLU-ProX": 0.747, "WMT20enja": 0.27, "WMT20jaen": 0.216, "__MIFEvalJa": 0.708, "avg": 0.616}}, "sortkey": "gpt oss swallow sft v0.1", "url": "https://huggingface.co/tokyotech-llm/GPT-OSS-Swallow-120B-SFT-v0.1"}, "tokyotech-llm/GPT-OSS-Swallow-20B-RL-v0.1": {"active_params": 3.6, "date": "2026-02-20", "family": "gpt-oss", "id": "tokyotech-llm/GPT-OSS-Swallow-20B-RL-v0.1", "is_post": true, "model_id": "tokyotech-llm/GPT-OSS-Swallow-20B-RL-v0.1", "name": "GPT-OSS-Swallow-20B-RL-v0.1", "params": 22, "pre_training": "GPT-OSS-Swallow-20B-SFT-v0.1", "reasoning": "on", "results": {"en_mtb": {"avg": 0.846, "coding": 0.873, "extraction": 0.855, "humanities": 0.848, "math": 0.869, "reasoning": 0.7, "roleplay": 0.874, "stem": 0.913, "writing": 0.838}, "en_post": {"AIME": 0.85, "GPQA": 0.646, "HellaSwag": 0.831, "LCB": 0.697, "MATH500": 0.964, "MMLU-Pro": 0.737, "avg": 0.788}, "ja_mtb": {"avg": 0.872, "coding": 0.915, "extraction": 0.888, "humanities": 0.809, "math": 0.938, "reasoning": 0.788, "roleplay": 0.886, "stem": 0.903, "writing": 0.849}, "ja_post": {"GPQA": 0.629, "JHumanEval": 0.924, "JamC-QA": 0.533, "MATH100": 0.97, "MMLU-ProX": 0.722, "WMT20enja": 0.251, "WMT20jaen": 0.213, "__MIFEvalJa": 0.553, "avg": 0.606}}, "sortkey": "gpt oss swallow rl v0.1", "url": "https://huggingface.co/tokyotech-llm/GPT-OSS-Swallow-20B-RL-v0.1"}, "tokyotech-llm/GPT-OSS-Swallow-20B-SFT-v0.1": {"active_params": 3.6, "date": "2026-02-20", "family": "gpt-oss", "id": "tokyotech-llm/GPT-OSS-Swallow-20B-SFT-v0.1", "is_post": true, "model_id": "tokyotech-llm/GPT-OSS-Swallow-20B-SFT-v0.1", "name": "GPT-OSS-Swallow-20B-SFT-v0.1", "params": 22, "pre_training": "GPT-OSS-Swallow-20B-CPT-v0.1", "reasoning": "on", "results": {"en_mtb": {"avg": 0.879, "coding": 0.942, "extraction": 0.894, "humanities": 0.893, "math": 0.91, "reasoning": 0.745, "roleplay": 0.881, "stem": 0.923, "writing": 0.846}, "en_post": {"AIME": 0.683, "GPQA": 0.636, "HellaSwag": 0.818, "LCB": 0.61, "MATH500": 0.948, "MMLU-Pro": 0.733, "avg": 0.738}, "ja_mtb": {"avg": 0.893, "coding": 0.936, "extraction": 0.904, "humanities": 0.858, "math": 1.0, "reasoning": 0.799, "roleplay": 0.881, "stem": 0.917, "writing": 0.851}, "ja_post": {"GPQA": 0.578, "JHumanEval": 0.909, "JamC-QA": 0.513, "MATH100": 0.96, "MMLU-ProX": 0.695, "WMT20enja": 0.254, "WMT20jaen": 0.22, "__MIFEvalJa": 0.575, "avg": 0.59}}, "sortkey": "gpt oss swallow sft v0.1", "url": "https://huggingface.co/tokyotech-llm/GPT-OSS-Swallow-20B-SFT-v0.1"}, "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1": {"active_params": 27, "date": "2025-05-19", "family": "Gemma 2", "id": "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "is_post": true, "model_id": "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "name": "Gemma-2-Llama Swallow 27B IT", "params": 27, "pre_training": "Gemma 2 27B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.771, "coding": 0.626, "extraction": 0.789, "humanities": 0.883, "math": 0.751, "reasoning": 0.622, "roleplay": 0.824, "stem": 0.821, "writing": 0.853}, "en_post": {"AIME": 0.033, "GPQA": 0.343, "HellaSwag": 0.786, "LCB": 0.218, "MATH500": 0.544, "MMLU-Pro": 0.436, "avg": 0.393}, "ja_mtb": {"avg": 0.759, "coding": 0.627, "extraction": 0.846, "humanities": 0.868, "math": 0.767, "reasoning": 0.548, "roleplay": 0.796, "stem": 0.785, "writing": 0.833}, "ja_post": {"GPQA": 0.333, "JHumanEval": 0.656, "JamC-QA": 0.531, "MATH100": 0.465, "MMLU-ProX": 0.452, "WMT20enja": 0.267, "WMT20jaen": 0.247, "__MIFEvalJa": 0.54, "avg": 0.421}}, "sortkey": "gemma 2 llama swallow", "url": "https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1"}, "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1": {"active_params": 2.6, "date": "2025-05-19", "family": "Gemma 2", "id": "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "is_post": true, "model_id": "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "name": "Gemma-2-Llama Swallow 2B IT", "params": 2.6, "pre_training": "Gemma2-Llama Swallow 2B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.584, "coding": 0.461, "extraction": 0.534, "humanities": 0.758, "math": 0.376, "reasoning": 0.452, "roleplay": 0.728, "stem": 0.646, "writing": 0.715}, "en_post": {"AIME": 0.0, "GPQA": 0.268, "HellaSwag": 0.495, "LCB": 0.036, "MATH500": 0.138, "MMLU-Pro": 0.169, "avg": 0.184}, "ja_mtb": {"avg": 0.583, "coding": 0.408, "extraction": 0.551, "humanities": 0.774, "math": 0.42, "reasoning": 0.418, "roleplay": 0.725, "stem": 0.655, "writing": 0.709}, "ja_post": {"GPQA": 0.259, "JHumanEval": 0.241, "JamC-QA": 0.372, "MATH100": 0.263, "MMLU-ProX": 0.19, "WMT20enja": 0.21, "WMT20jaen": 0.142, "__MIFEvalJa": 0.363, "avg": 0.24}}, "sortkey": "gemma 2 llama swallow", "url": "https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1"}, "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1": {"active_params": 9.2, "date": "2025-05-19", "family": "Gemma 2", "id": "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "is_post": true, "model_id": "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "name": "Gemma-2-Llama Swallow 9B IT", "params": 9.2, "pre_training": "Gemma 2 9B", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.734, "coding": 0.523, "extraction": 0.831, "humanities": 0.886, "math": 0.72, "reasoning": 0.518, "roleplay": 0.789, "stem": 0.786, "writing": 0.819}, "en_post": {"AIME": 0.017, "GPQA": 0.283, "HellaSwag": 0.801, "LCB": 0.106, "MATH500": 0.438, "MMLU-Pro": 0.296, "avg": 0.323}, "ja_mtb": {"avg": 0.729, "coding": 0.579, "extraction": 0.787, "humanities": 0.88, "math": 0.661, "reasoning": 0.616, "roleplay": 0.788, "stem": 0.735, "writing": 0.783}, "ja_post": {"GPQA": 0.283, "JHumanEval": 0.518, "JamC-QA": 0.464, "MATH100": 0.374, "MMLU-ProX": 0.372, "WMT20enja": 0.251, "WMT20jaen": 0.218, "__MIFEvalJa": 0.54, "avg": 0.354}}, "sortkey": "gemma 2 llama swallow", "url": "https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1"}, "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3": {"active_params": 8.0, "date": "2024-12-23", "family": "Llama 3", "id": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "is_post": true, "model_id": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "name": "Llama 3.1 Swallow 8B Instruct v0.3", "params": 8.0, "pre_training": "Llama 3.1 Swallow 8B v0.2", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.691, "coding": 0.528, "extraction": 0.714, "humanities": 0.886, "math": 0.562, "reasoning": 0.458, "roleplay": 0.773, "stem": 0.768, "writing": 0.838}, "en_post": {"AIME": 0.0, "GPQA": 0.293, "HellaSwag": 0.725, "LCB": 0.102, "MATH500": 0.338, "MMLU-Pro": 0.287, "avg": 0.291}, "ja_mtb": {"avg": 0.709, "coding": 0.57, "extraction": 0.783, "humanities": 0.869, "math": 0.631, "reasoning": 0.506, "roleplay": 0.782, "stem": 0.716, "writing": 0.813}, "ja_post": {"GPQA": 0.239, "JHumanEval": 0.488, "JamC-QA": 0.414, "MATH100": 0.364, "MMLU-ProX": 0.306, "WMT20enja": 0.249, "WMT20jaen": 0.223, "__MIFEvalJa": 0.491, "avg": 0.326}}, "sortkey": "llama 3.1 swallow v0.3", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3"}, "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5": {"active_params": 8.0, "date": "2025-06-25", "family": "Llama 3", "id": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5", "is_post": true, "model_id": "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5", "name": "Llama 3.1 Swallow 8B Instruct v0.5", "params": 8.0, "pre_training": "Llama 3.1 Swallow 8B v0.2", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.753, "coding": 0.576, "extraction": 0.801, "humanities": 0.9, "math": 0.769, "reasoning": 0.499, "roleplay": 0.848, "stem": 0.796, "writing": 0.833}, "en_post": {"AIME": 0.0, "GPQA": 0.318, "HellaSwag": 0.648, "LCB": 0.072, "MATH500": 0.452, "MMLU-Pro": 0.399, "avg": 0.315}, "ja_mtb": {"avg": 0.726, "coding": 0.59, "extraction": 0.843, "humanities": 0.884, "math": 0.47, "reasoning": 0.618, "roleplay": 0.78, "stem": 0.799, "writing": 0.822}, "ja_post": {"GPQA": 0.295, "JHumanEval": 0.584, "JamC-QA": 0.496, "MATH100": 0.404, "MMLU-ProX": 0.369, "WMT20enja": 0.249, "WMT20jaen": 0.222, "__MIFEvalJa": 0.496, "avg": 0.374}}, "sortkey": "llama 3.1 swallow v0.5", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5"}, "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4": {"active_params": 70, "date": "2025-03-10", "family": "Llama 3", "id": "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "is_post": true, "model_id": "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "name": "Llama 3.3 Swallow 70B Instruct v0.4", "params": 70, "pre_training": "Llama 3.3 Swallow 70B v0.4", "reasoning": "N/A", "results": {"en_mtb": {"avg": 0.816, "coding": 0.672, "extraction": 0.902, "humanities": 0.888, "math": 0.839, "reasoning": 0.706, "roleplay": 0.828, "stem": 0.838, "writing": 0.855}, "en_post": {"AIME": 0.083, "GPQA": 0.409, "HellaSwag": 0.884, "LCB": 0.232, "MATH500": 0.642, "MMLU-Pro": 0.57, "avg": 0.47}, "ja_mtb": {"avg": 0.791, "coding": 0.696, "extraction": 0.856, "humanities": 0.881, "math": 0.807, "reasoning": 0.664, "roleplay": 0.827, "stem": 0.772, "writing": 0.822}, "ja_post": {"GPQA": 0.355, "JHumanEval": 0.727, "JamC-QA": 0.562, "MATH100": 0.697, "MMLU-ProX": 0.533, "WMT20enja": 0.275, "WMT20jaen": 0.251, "__MIFEvalJa": 0.593, "avg": 0.486}}, "sortkey": "llama 3.3 swallow v0.4", "url": "https://huggingface.co/tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4"}, "tokyotech-llm/Qwen-3-Swallow-30B-A3B-CPT-v0.2": {"active_params": 31, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-30B-A3B-CPT-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-30B-A3B-CPT-v0.2", "name": "Qwen3-Swallow-30B-A3B-CPT-v0.2", "params": 31, "pre_training": "Qwen3-30B-A3B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.748, "coding": 0.731, "extraction": 0.737, "humanities": 0.755, "math": 0.773, "reasoning": 0.732, "roleplay": 0.831, "stem": 0.747, "writing": 0.68}, "en_post": {"AIME": 0.533, "GPQA": 0.611, "HellaSwag": 0.849, "LCB": 0.513, "MATH500": 0.922, "MMLU-Pro": 0.745, "avg": 0.696}, "ja_mtb": {"avg": 0.747, "coding": 0.699, "extraction": 0.708, "humanities": 0.784, "math": 0.805, "reasoning": 0.588, "roleplay": 0.87, "stem": 0.857, "writing": 0.669}, "ja_post": {"GPQA": 0.547, "JHumanEval": 0.894, "JamC-QA": 0.528, "MATH100": 0.909, "MMLU-ProX": 0.713, "WMT20enja": 0.248, "WMT20jaen": 0.229, "__MIFEvalJa": 0.518, "avg": 0.581}}, "sortkey": "qwen3 swallow a cpt v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-30B-A3B-CPT-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-30B-A3B-RL-v0.2": {"active_params": 31, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-30B-A3B-RL-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-30B-A3B-RL-v0.2", "name": "Qwen3-Swallow-30B-A3B-RL-v0.2", "params": 31, "pre_training": "Qwen3-Swallow-30B-A3B-SFT-v0.2", "reasoning": "on", "results": {"en_mtb": {"avg": 0.866, "coding": 0.831, "extraction": 0.857, "humanities": 0.883, "math": 0.94, "reasoning": 0.793, "roleplay": 0.889, "stem": 0.906, "writing": 0.827}, "en_post": {"AIME": 0.733, "GPQA": 0.576, "HellaSwag": 0.808, "LCB": 0.646, "MATH500": 0.956, "MMLU-Pro": 0.674, "avg": 0.732}, "ja_mtb": {"avg": 0.889, "coding": 0.908, "extraction": 0.882, "humanities": 0.896, "math": 0.993, "reasoning": 0.785, "roleplay": 0.905, "stem": 0.904, "writing": 0.835}, "ja_post": {"GPQA": 0.596, "JHumanEval": 0.909, "JamC-QA": 0.496, "MATH100": 0.949, "MMLU-ProX": 0.729, "WMT20enja": 0.243, "WMT20jaen": 0.213, "__MIFEvalJa": 0.531, "avg": 0.591}}, "sortkey": "qwen3 swallow a rl v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-30B-A3B-RL-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-30B-A3B-SFT-v0.2": {"active_params": 31, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-30B-A3B-SFT-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-30B-A3B-SFT-v0.2", "name": "Qwen3-Swallow-30B-A3B-SFT-v0.2", "params": 31, "pre_training": "Qwen3-Swallow-30B-A3B-CPT-v0.2", "reasoning": "on", "results": {"en_mtb": {"avg": 0.882, "coding": 0.934, "extraction": 0.844, "humanities": 0.923, "math": 0.964, "reasoning": 0.775, "roleplay": 0.878, "stem": 0.916, "writing": 0.821}, "en_post": {"AIME": 0.667, "GPQA": 0.571, "HellaSwag": 0.832, "LCB": 0.514, "MATH500": 0.932, "MMLU-Pro": 0.711, "avg": 0.704}, "ja_mtb": {"avg": 0.887, "coding": 0.906, "extraction": 0.896, "humanities": 0.919, "math": 0.965, "reasoning": 0.817, "roleplay": 0.889, "stem": 0.882, "writing": 0.825}, "ja_post": {"GPQA": 0.558, "JHumanEval": 0.888, "JamC-QA": 0.504, "MATH100": 0.899, "MMLU-ProX": 0.711, "WMT20enja": 0.242, "WMT20jaen": 0.219, "__MIFEvalJa": 0.553, "avg": 0.574}}, "sortkey": "qwen3 swallow a sft v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-30B-A3B-SFT-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-32B-CPT-v0.2": {"active_params": 33, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-32B-CPT-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-32B-CPT-v0.2", "name": "Qwen3-Swallow-32B-CPT-v0.2", "params": 33, "pre_training": "Qwen3-32B", "reasoning": "on", "results": {"en_mtb": {"avg": 0.766, "coding": 0.684, "extraction": 0.762, "humanities": 0.745, "math": 0.822, "reasoning": 0.743, "roleplay": 0.845, "stem": 0.77, "writing": 0.754}, "en_post": {"AIME": 0.583, "GPQA": 0.636, "HellaSwag": 0.899, "LCB": 0.556, "MATH500": 0.95, "MMLU-Pro": 0.761, "avg": 0.731}, "ja_mtb": {"avg": 0.788, "coding": 0.696, "extraction": 0.785, "humanities": 0.783, "math": 0.887, "reasoning": 0.732, "roleplay": 0.878, "stem": 0.84, "writing": 0.706}, "ja_post": {"GPQA": 0.576, "JHumanEval": 0.91, "JamC-QA": 0.551, "MATH100": 0.939, "MMLU-ProX": 0.735, "WMT20enja": 0.255, "WMT20jaen": 0.235, "__MIFEvalJa": 0.549, "avg": 0.6}}, "sortkey": "qwen3 swallow cpt v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-32B-CPT-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-32B-RL-v0.2": {"active_params": 33, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-32B-RL-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-32B-RL-v0.2", "name": "Qwen3-Swallow-32B-RL-v0.2", "params": 33, "pre_training": "Qwen3-Swallow-32B-SFT-v0.2", "reasoning": "on", "results": {"en_mtb": {"avg": 0.877, "coding": 0.909, "extraction": 0.799, "humanities": 0.902, "math": 0.989, "reasoning": 0.762, "roleplay": 0.886, "stem": 0.911, "writing": 0.855}, "en_post": {"AIME": 0.8, "GPQA": 0.657, "HellaSwag": 0.882, "LCB": 0.662, "MATH500": 0.976, "MMLU-Pro": 0.778, "avg": 0.792}, "ja_mtb": {"avg": 0.894, "coding": 0.915, "extraction": 0.941, "humanities": 0.881, "math": 0.981, "reasoning": 0.803, "roleplay": 0.896, "stem": 0.893, "writing": 0.842}, "ja_post": {"GPQA": 0.607, "JHumanEval": 0.93, "JamC-QA": 0.534, "MATH100": 0.97, "MMLU-ProX": 0.754, "WMT20enja": 0.252, "WMT20jaen": 0.219, "__MIFEvalJa": 0.584, "avg": 0.609}}, "sortkey": "qwen3 swallow rl v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-32B-RL-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-32B-SFT-v0.2": {"active_params": 33, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-32B-SFT-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-32B-SFT-v0.2", "name": "Qwen3-Swallow-32B-SFT-v0.2", "params": 33, "pre_training": "Qwen3-Swallow-32-CPT-v0.2", "reasoning": "on", "results": {"en_mtb": {"avg": 0.89, "coding": 0.887, "extraction": 0.862, "humanities": 0.901, "math": 1.0, "reasoning": 0.752, "roleplay": 0.909, "stem": 0.951, "writing": 0.86}, "en_post": {"AIME": 0.583, "GPQA": 0.631, "HellaSwag": 0.879, "LCB": 0.567, "MATH500": 0.96, "MMLU-Pro": 0.757, "avg": 0.729}, "ja_mtb": {"avg": 0.879, "coding": 0.911, "extraction": 0.841, "humanities": 0.886, "math": 0.933, "reasoning": 0.814, "roleplay": 0.885, "stem": 0.919, "writing": 0.846}, "ja_post": {"GPQA": 0.594, "JHumanEval": 0.904, "JamC-QA": 0.493, "MATH100": 0.96, "MMLU-ProX": 0.723, "WMT20enja": 0.251, "WMT20jaen": 0.216, "__MIFEvalJa": 0.54, "avg": 0.592}}, "sortkey": "qwen3 swallow sft v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-32B-SFT-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-8B-CPT-v0.2": {"active_params": 8.2, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-8B-CPT-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-8B-CPT-v0.2", "name": "Qwen3-Swallow-8B-CPT-v0.2", "params": 8.2, "pre_training": "Qwen3-8B-Base", "reasoning": "on", "results": {"en_mtb": {"avg": 0.683, "coding": 0.612, "extraction": 0.65, "humanities": 0.694, "math": 0.799, "reasoning": 0.507, "roleplay": 0.831, "stem": 0.733, "writing": 0.642}, "en_post": {"AIME": 0.467, "GPQA": 0.515, "HellaSwag": 0.791, "LCB": 0.341, "MATH500": 0.872, "MMLU-Pro": 0.621, "avg": 0.601}, "ja_mtb": {"avg": 0.719, "coding": 0.699, "extraction": 0.618, "humanities": 0.73, "math": 0.82, "reasoning": 0.574, "roleplay": 0.859, "stem": 0.812, "writing": 0.637}, "ja_post": {"GPQA": 0.404, "JHumanEval": 0.833, "JamC-QA": 0.449, "MATH100": 0.838, "MMLU-ProX": 0.628, "WMT20enja": 0.238, "WMT20jaen": 0.215, "__MIFEvalJa": 0.456, "avg": 0.515}}, "sortkey": "qwen3 swallow cpt v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-8B-CPT-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-8B-RL-v0.2": {"active_params": 8.2, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-8B-RL-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-8B-RL-v0.2", "name": "Qwen3-Swallow-8B-RL-v0.2", "params": 8.2, "pre_training": "Qwen3-Swallow-30B-A3B-SFT-v0.2", "reasoning": "on", "results": {"en_mtb": {"avg": 0.855, "coding": 0.819, "extraction": 0.864, "humanities": 0.885, "math": 0.919, "reasoning": 0.72, "roleplay": 0.904, "stem": 0.897, "writing": 0.832}, "en_post": {"AIME": 0.667, "GPQA": 0.54, "HellaSwag": 0.79, "LCB": 0.555, "MATH500": 0.938, "MMLU-Pro": 0.675, "avg": 0.694}, "ja_mtb": {"avg": 0.844, "coding": 0.899, "extraction": 0.775, "humanities": 0.799, "math": 0.927, "reasoning": 0.748, "roleplay": 0.882, "stem": 0.89, "writing": 0.828}, "ja_post": {"GPQA": 0.529, "JHumanEval": 0.885, "JamC-QA": 0.444, "MATH100": 0.929, "MMLU-ProX": 0.675, "WMT20enja": 0.235, "WMT20jaen": 0.204, "__MIFEvalJa": 0.473, "avg": 0.557}}, "sortkey": "qwen3 swallow rl v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-8B-RL-v0.2"}, "tokyotech-llm/Qwen-3-Swallow-8B-SFT-v0.2": {"active_params": 8.2, "date": "2026-02-20", "family": "Qwen3-Swallow", "id": "tokyotech-llm/Qwen-3-Swallow-8B-SFT-v0.2", "is_post": true, "model_id": "tokyotech-llm/Qwen-3-Swallow-8B-SFT-v0.2", "name": "Qwen3-Swallow-8B-SFT-v0.2", "params": 8.2, "pre_training": "Qwen3-Swallow-8B-CPT-v0.2", "reasoning": "on", "results": {"en_mtb": {"avg": 0.855, "coding": 0.877, "extraction": 0.785, "humanities": 0.91, "math": 0.928, "reasoning": 0.752, "roleplay": 0.878, "stem": 0.903, "writing": 0.809}, "en_post": {"AIME": 0.467, "GPQA": 0.545, "HellaSwag": 0.797, "LCB": 0.422, "MATH500": 0.926, "MMLU-Pro": 0.669, "avg": 0.638}, "ja_mtb": {"avg": 0.868, "coding": 0.859, "extraction": 0.821, "humanities": 0.878, "math": 0.965, "reasoning": 0.831, "roleplay": 0.893, "stem": 0.91, "writing": 0.785}, "ja_post": {"GPQA": 0.446, "JHumanEval": 0.83, "JamC-QA": 0.439, "MATH100": 0.929, "MMLU-ProX": 0.653, "WMT20enja": 0.231, "WMT20jaen": 0.205, "__MIFEvalJa": 0.451, "avg": 0.534}}, "sortkey": "qwen3 swallow sft v0.2", "url": "https://huggingface.co/tokyotech-llm/Qwen-3-Swallow-8B-SFT-v0.2"}};
const g_tasks = {"en_mtb": {"description": "\u30de\u30eb\u30c1\u30bf\u30fc\u30f3\u5bfe\u8a71\u80fd\u529b\u3092\u6e2c\u5b9a\u3059\u308b\u82f1\u8a9e MT-Bench\u3002\u8a55\u4fa1\u30b9\u30b3\u30a2\u306f0 (\u6700\u4f4e) \u304b\u30891 (\u6700\u9ad8) \u307e\u3067\u306e\u7bc4\u56f2\u306e\u5024\u3092\u3068\u308a\u307e\u3059\u3002", "for": ["post"], "taskdict": {"avg": {"category": "\u5e73\u5747", "collective": true, "description": "\u82f1\u8a9e MT-Bench 8\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "english_mtbench_average", "metric": "\u5e73\u5747", "name": "avg", "short": "MTB (\u82f1) \u5e73\u5747", "title": "\u5e73\u5747"}, "coding": {"description": "Python\u3084C++\u3067\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u305f\u308a\u3001HTML\u3067\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_coding", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "coding", "short": "\u30b3\u30fc\u30c9", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0"}, "extraction": {"description": "\u6587\u66f8\u304b\u3089\u56fa\u6709\u8868\u73fe\uff08\u8457\u8005\u540d\u3084\u6570\u5024\u306a\u3069\uff09\u3084\u8a55\u5224\uff08\u30dd\u30b8\u30cd\u30ac\u306a\u3069\uff09\u3092\u62bd\u51fa\u3059\u308b", "field": "english_mtbench_extraction", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "extraction", "short": "\u62bd\u51fa", "title": "\u60c5\u5831\u62bd\u51fa"}, "humanities": {"description": "\u6cd5\u5f8b\u3084\u7d4c\u6e08\u3001\u6b74\u53f2\u3001\u54f2\u5b66\u3001\u6559\u80b2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3059\u308b\u8ad6\u8aac\u3084\u6226\u7565\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_humanities", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "humanities", "short": "\u4eba\u6587", "title": "\u4eba\u6587\u79d1\u5b66"}, "math": {"description": "\u4ee3\u6570\u3001\u5e7e\u4f55\u3001\u78ba\u7387\u3001\u6574\u6570\u306a\u3069\u306e\u554f\u984c\u3084\u6587\u7ae0\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_math", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "math", "short": "\u6570\u5b66", "title": "\u6570\u5b66"}, "reasoning": {"description": "\u5e38\u8b58\u3084\u63a8\u8ad6\u529b\u3092\u6d3b\u7528\u3057\u3066\u554f\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_reasoning", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "reasoning", "short": "\u63a8\u8ad6", "title": "\u63a8\u8ad6"}, "roleplay": {"description": "\u6709\u540d\u4eba\u3084\u6620\u753b\u4e2d\u306e\u4eba\u7269\u306b\u306a\u308a\u3059\u307e\u3059\u306a\u3069\u3001\u4eee\u60f3\u306e\u72b6\u6cc1\u3092\u60f3\u5b9a\u3057\u3066\u6587\u7ae0\u3092\u4f5c\u6587\u3059\u308b", "field": "english_mtbench_roleplay", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "roleplay", "short": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4", "title": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4"}, "stem": {"description": "\u7269\u7406\u5b66\u3001\u5316\u5b66\u3001\u751f\u7269\u5b66\u3001\u5730\u7406\u3001\u5efa\u7bc9\u3001\u6a5f\u68b0\u5b66\u7fd2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3057\u3066\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_stem", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "stem", "short": "\u79d1\u30fb\u6280\u30fb\u5de5\u30fb\u6570", "title": "\u79d1\u5b66\u30fb\u6280\u8853\u30fb\u5de5\u5b66\u30fb\u6570\u5b66"}, "writing": {"description": "\u30d6\u30ed\u30b0\u8a18\u4e8b\u3084\u30e1\u30fc\u30eb\u6587\u9762\u3001\u30d5\u30a3\u30af\u30b7\u30e7\u30f3\u306e\u6587\u7ae0\u306a\u3069\u3092\u57f7\u7b46\u3059\u308b\u30bf\u30b9\u30af", "field": "english_mtbench_writing", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "writing", "short": "\u57f7\u7b46", "title": "\u57f7\u7b46"}}, "tasks": [{"category": "\u5e73\u5747", "collective": true, "description": "\u82f1\u8a9e MT-Bench 8\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "english_mtbench_average", "metric": "\u5e73\u5747", "name": "avg", "short": "MTB (\u82f1) \u5e73\u5747", "title": "\u5e73\u5747"}, {"description": "Python\u3084C++\u3067\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u305f\u308a\u3001HTML\u3067\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_coding", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "coding", "short": "\u30b3\u30fc\u30c9", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0"}, {"description": "\u6587\u66f8\u304b\u3089\u56fa\u6709\u8868\u73fe\uff08\u8457\u8005\u540d\u3084\u6570\u5024\u306a\u3069\uff09\u3084\u8a55\u5224\uff08\u30dd\u30b8\u30cd\u30ac\u306a\u3069\uff09\u3092\u62bd\u51fa\u3059\u308b", "field": "english_mtbench_extraction", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "extraction", "short": "\u62bd\u51fa", "title": "\u60c5\u5831\u62bd\u51fa"}, {"description": "\u6cd5\u5f8b\u3084\u7d4c\u6e08\u3001\u6b74\u53f2\u3001\u54f2\u5b66\u3001\u6559\u80b2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3059\u308b\u8ad6\u8aac\u3084\u6226\u7565\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_humanities", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "humanities", "short": "\u4eba\u6587", "title": "\u4eba\u6587\u79d1\u5b66"}, {"description": "\u4ee3\u6570\u3001\u5e7e\u4f55\u3001\u78ba\u7387\u3001\u6574\u6570\u306a\u3069\u306e\u554f\u984c\u3084\u6587\u7ae0\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_math", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "math", "short": "\u6570\u5b66", "title": "\u6570\u5b66"}, {"description": "\u5e38\u8b58\u3084\u63a8\u8ad6\u529b\u3092\u6d3b\u7528\u3057\u3066\u554f\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_reasoning", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "reasoning", "short": "\u63a8\u8ad6", "title": "\u63a8\u8ad6"}, {"description": "\u6709\u540d\u4eba\u3084\u6620\u753b\u4e2d\u306e\u4eba\u7269\u306b\u306a\u308a\u3059\u307e\u3059\u306a\u3069\u3001\u4eee\u60f3\u306e\u72b6\u6cc1\u3092\u60f3\u5b9a\u3057\u3066\u6587\u7ae0\u3092\u4f5c\u6587\u3059\u308b", "field": "english_mtbench_roleplay", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "roleplay", "short": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4", "title": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4"}, {"description": "\u7269\u7406\u5b66\u3001\u5316\u5b66\u3001\u751f\u7269\u5b66\u3001\u5730\u7406\u3001\u5efa\u7bc9\u3001\u6a5f\u68b0\u5b66\u7fd2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3057\u3066\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "english_mtbench_stem", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "stem", "short": "\u79d1\u30fb\u6280\u30fb\u5de5\u30fb\u6570", "title": "\u79d1\u5b66\u30fb\u6280\u8853\u30fb\u5de5\u5b66\u30fb\u6570\u5b66"}, {"description": "\u30d6\u30ed\u30b0\u8a18\u4e8b\u3084\u30e1\u30fc\u30eb\u6587\u9762\u3001\u30d5\u30a3\u30af\u30b7\u30e7\u30f3\u306e\u6587\u7ae0\u306a\u3069\u3092\u57f7\u7b46\u3059\u308b\u30bf\u30b9\u30af", "field": "english_mtbench_writing", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "writing", "short": "\u57f7\u7b46", "title": "\u57f7\u7b46"}], "title": "\u82f1\u8a9e MT-Bench"}, "en_post": {"description": "\u82f1\u8a9e\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u30c7\u30fc\u30bf\u3067\u63a8\u8ad6\u578b\u30e2\u30c7\u30eb\u3092\u542b\u3080\u4e8b\u5f8c\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u80fd\u529b\u3092\u6e2c\u5b9a\u3057\u307e\u3059\u3002\u8a55\u4fa1\u30b9\u30b3\u30a2\u306f0 (\u6700\u4f4e) \u304b\u30891 (\u6700\u9ad8) \u307e\u3067\u306e\u7bc4\u56f2\u306e\u5024\u3092\u3068\u308a\u307e\u3059\u3002", "for": ["post"], "taskdict": {"AIME": {"category": "\u6570\u5b66", "description": "\u7c73\u56fd\u6570\u5b66\u30aa\u30ea\u30f3\u30d4\u30c3\u30af (USAMO) \u306e\u4e88\u9078", "field": "aime_2024_2025", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "metric": "\u6b63\u89e3\u7387", "name": "AIME", "short": "AIME 24-25", "title": "\u6570\u5b66 (AIME 2024-2025)"}, "GPQA": {"category": "\u79d1\u5b66", "description": "\u691c\u7d22\u3067\u306f\u89e3\u3051\u306a\u3044\u5927\u5b66\u9662\u30ec\u30d9\u30eb\u306e\u8cea\u554f\u5fdc\u7b54", "field": "gpqa_diamond", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Rein et al.", "href": "https://openreview.net/forum?id=Ti67584b98", "year": 2024}, "metric": "\u6b63\u89e3\u7387", "name": "GPQA", "short": "GPQA (\u82f1)", "title": "\u79d1\u5b66 (GPQA)"}, "HellaSwag": {"category": "\u81ea\u7136\u8a00\u8a9e\u63a8\u8ad6", "description": "\u6b21\u306b\u8d77\u3053\u308b\u51fa\u6765\u4e8b\u3092\u4e88\u6e2c\u3059\u308b4\u629e\u306e\u9078\u629e\u5f0f\u554f\u984c", "field": "swallow_hellaswag", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "link": {"author": "Zellers et al.", "href": "https://aclanthology.org/P19-1472/", "year": 2019}, "metric": "\u6b63\u89e3\u7387", "name": "HellaSwag", "short": "HellaSwag", "title": "\u81ea\u7136\u8a00\u8a9e\u63a8\u8ad6 (HellaSwag)"}, "LCB": {"category": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0", "description": "\u7af6\u6280\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0 (LeetCode, AtCoder, CodeForces)", "field": "livecodebench_v5_v6_pass@1", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "metric": "Pass@1 (n=10)", "name": "LCB", "short": "LCB", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0 (LCB)"}, "MATH500": {"category": "\u6570\u5b66", "description": "\u30b3\u30f3\u30c6\u30b9\u30c8\u30ec\u30d9\u30eb\u306e\u6570\u5b66", "field": "math_500", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Hendrycks et al.", "href": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html", "year": 2021}, "metric": "\u6b63\u89e3\u7387", "name": "MATH500", "short": "MATH-500 (\u82f1)", "title": "\u6570\u5b66 (MATH-500)"}, "MMLU-Pro": {"category": "\u5927\u5b66\u30ec\u30d9\u30eb\u306e\u8a66\u9a13\u554f\u984c", "description": "\u591a\u5206\u91ce\u306b\u308f\u305f\u308b\u9ad8\u5ea6\u306a\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6\u80fd\u529b", "field": "mmlu_pro_english", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Wang et al.", "href": "https://neurips.cc/virtual/2024/poster/97435", "year": 2024}, "metric": "\u6b63\u89e3\u7387", "name": "MMLU-Pro", "short": "MMLU-Pro (\u82f1)", "title": "\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6 (MMLU-Pro)"}, "avg": {"category": "\u5e73\u5747", "collective": true, "description": "\u4e8b\u5f8c\u5b66\u7fd2\u30e2\u30c7\u30eb\u5411\u3051\u306e\u82f1\u8a9e\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "en_post_avg", "metric": "\u5e73\u5747", "name": "avg", "short": "\u4e8b\u5f8c\uff08\u82f1\uff09\u5e73\u5747", "title": "\u5e73\u5747"}}, "tasks": [{"category": "\u5e73\u5747", "collective": true, "description": "\u4e8b\u5f8c\u5b66\u7fd2\u30e2\u30c7\u30eb\u5411\u3051\u306e\u82f1\u8a9e\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "en_post_avg", "metric": "\u5e73\u5747", "name": "avg", "short": "\u4e8b\u5f8c\uff08\u82f1\uff09\u5e73\u5747", "title": "\u5e73\u5747"}, {"category": "\u81ea\u7136\u8a00\u8a9e\u63a8\u8ad6", "description": "\u6b21\u306b\u8d77\u3053\u308b\u51fa\u6765\u4e8b\u3092\u4e88\u6e2c\u3059\u308b4\u629e\u306e\u9078\u629e\u5f0f\u554f\u984c", "field": "swallow_hellaswag", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "link": {"author": "Zellers et al.", "href": "https://aclanthology.org/P19-1472/", "year": 2019}, "metric": "\u6b63\u89e3\u7387", "name": "HellaSwag", "short": "HellaSwag", "title": "\u81ea\u7136\u8a00\u8a9e\u63a8\u8ad6 (HellaSwag)"}, {"category": "\u5927\u5b66\u30ec\u30d9\u30eb\u306e\u8a66\u9a13\u554f\u984c", "description": "\u591a\u5206\u91ce\u306b\u308f\u305f\u308b\u9ad8\u5ea6\u306a\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6\u80fd\u529b", "field": "mmlu_pro_english", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Wang et al.", "href": "https://neurips.cc/virtual/2024/poster/97435", "year": 2024}, "metric": "\u6b63\u89e3\u7387", "name": "MMLU-Pro", "short": "MMLU-Pro (\u82f1)", "title": "\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6 (MMLU-Pro)"}, {"category": "\u79d1\u5b66", "description": "\u691c\u7d22\u3067\u306f\u89e3\u3051\u306a\u3044\u5927\u5b66\u9662\u30ec\u30d9\u30eb\u306e\u8cea\u554f\u5fdc\u7b54", "field": "gpqa_diamond", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Rein et al.", "href": "https://openreview.net/forum?id=Ti67584b98", "year": 2024}, "metric": "\u6b63\u89e3\u7387", "name": "GPQA", "short": "GPQA (\u82f1)", "title": "\u79d1\u5b66 (GPQA)"}, {"category": "\u6570\u5b66", "description": "\u30b3\u30f3\u30c6\u30b9\u30c8\u30ec\u30d9\u30eb\u306e\u6570\u5b66", "field": "math_500", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Hendrycks et al.", "href": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html", "year": 2021}, "metric": "\u6b63\u89e3\u7387", "name": "MATH500", "short": "MATH-500 (\u82f1)", "title": "\u6570\u5b66 (MATH-500)"}, {"category": "\u6570\u5b66", "description": "\u7c73\u56fd\u6570\u5b66\u30aa\u30ea\u30f3\u30d4\u30c3\u30af (USAMO) \u306e\u4e88\u9078", "field": "aime_2024_2025", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "metric": "\u6b63\u89e3\u7387", "name": "AIME", "short": "AIME 24-25", "title": "\u6570\u5b66 (AIME 2024-2025)"}, {"category": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0", "description": "\u7af6\u6280\u30d7\u30ed\u30b0\u30e9\u30df\u30f3\u30b0 (LeetCode, AtCoder, CodeForces)", "field": "livecodebench_v5_v6_pass@1", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "metric": "Pass@1 (n=10)", "name": "LCB", "short": "LCB", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0 (LCB)"}], "title": "\u4e8b\u5f8c\u5b66\u7fd2\uff08\u82f1\u8a9e\uff09"}, "ja_mtb": {"description": "\u30de\u30eb\u30c1\u30bf\u30fc\u30f3\u5bfe\u8a71\u80fd\u529b\u3092\u6e2c\u5b9a\u3059\u308bMT-Bench\u306e\u65e5\u672c\u8a9e\u7248\uff08Nejumi LLM\u30ea\u30fc\u30c0\u30fc\u30dc\u30fc\u30c9\u7248\uff09\u3092\u7528\u3044\u307e\u3057\u305f\u3002\u8a2d\u554f\u306fv4\u3092\u3001\u6a21\u7bc4\u56de\u7b54\u306fv2\u306e\u8aa4\u7b54\u3092\u4fee\u6b63\u3057\u305f\u3082\u306e\u3092\u63a1\u7528\u3057\u3066\u3044\u307e\u3059\u3002\u8a55\u4fa1\u30b9\u30b3\u30a2\u306f0 (\u6700\u4f4e) \u304b\u30891 (\u6700\u9ad8) \u307e\u3067\u306e\u7bc4\u56f2\u306e\u5024\u3092\u3068\u308a\u307e\u3059\u3002", "for": ["post"], "taskdict": {"avg": {"category": "\u5e73\u5747", "collective": true, "description": "\u65e5\u672c\u8a9e MT-Bench 8\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "japanese_mtbench_average", "metric": "\u5e73\u5747", "name": "avg", "short": "MTB (\u65e5) \u5e73\u5747", "title": "\u5e73\u5747"}, "coding": {"description": "Python\u3084C++\u3067\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u305f\u308a\u3001HTML\u3067\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_coding", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "coding", "short": "\u30b3\u30fc\u30c9", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0"}, "extraction": {"description": "\u6587\u66f8\u304b\u3089\u56fa\u6709\u8868\u73fe\uff08\u8457\u8005\u540d\u3084\u6570\u5024\u306a\u3069\uff09\u3084\u8a55\u5224\uff08\u30dd\u30b8\u30cd\u30ac\u306a\u3069\uff09\u3092\u62bd\u51fa\u3059\u308b", "field": "japanese_mtbench_extraction", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "extraction", "short": "\u62bd\u51fa", "title": "\u60c5\u5831\u62bd\u51fa"}, "humanities": {"description": "\u6cd5\u5f8b\u3084\u7d4c\u6e08\u3001\u6b74\u53f2\u3001\u54f2\u5b66\u3001\u6559\u80b2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3059\u308b\u8ad6\u8aac\u3084\u6226\u7565\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_humanities", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "humanities", "short": "\u4eba\u6587", "title": "\u4eba\u6587\u79d1\u5b66"}, "math": {"description": "\u4ee3\u6570\u3001\u5e7e\u4f55\u3001\u78ba\u7387\u3001\u6574\u6570\u306a\u3069\u306e\u554f\u984c\u3084\u6587\u7ae0\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_math", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "math", "short": "\u6570\u5b66", "title": "\u6570\u5b66"}, "reasoning": {"description": "\u5e38\u8b58\u3084\u63a8\u8ad6\u529b\u3092\u6d3b\u7528\u3057\u3066\u554f\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_reasoning", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "reasoning", "short": "\u63a8\u8ad6", "title": "\u63a8\u8ad6"}, "roleplay": {"description": "\u6709\u540d\u4eba\u3084\u6620\u753b\u4e2d\u306e\u4eba\u7269\u306b\u306a\u308a\u3059\u307e\u3059\u306a\u3069\u3001\u4eee\u60f3\u306e\u72b6\u6cc1\u3092\u60f3\u5b9a\u3057\u3066\u6587\u7ae0\u3092\u4f5c\u6587\u3059\u308b", "field": "japanese_mtbench_roleplay", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "roleplay", "short": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4", "title": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4"}, "stem": {"description": "\u7269\u7406\u5b66\u3001\u5316\u5b66\u3001\u751f\u7269\u5b66\u3001\u5730\u7406\u3001\u5efa\u7bc9\u3001\u6a5f\u68b0\u5b66\u7fd2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3057\u3066\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_stem", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "stem", "short": "\u79d1\u30fb\u6280\u30fb\u5de5\u30fb\u6570", "title": "\u79d1\u5b66\u30fb\u6280\u8853\u30fb\u5de5\u5b66\u30fb\u6570\u5b66"}, "writing": {"description": "\u30d6\u30ed\u30b0\u8a18\u4e8b\u3084\u30e1\u30fc\u30eb\u6587\u9762\u3001\u30d5\u30a3\u30af\u30b7\u30e7\u30f3\u306e\u6587\u7ae0\u306a\u3069\u3092\u57f7\u7b46\u3059\u308b\u30bf\u30b9\u30af", "field": "japanese_mtbench_writing", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "writing", "short": "\u57f7\u7b46", "title": "\u57f7\u7b46"}}, "tasks": [{"category": "\u5e73\u5747", "collective": true, "description": "\u65e5\u672c\u8a9e MT-Bench 8\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "japanese_mtbench_average", "metric": "\u5e73\u5747", "name": "avg", "short": "MTB (\u65e5) \u5e73\u5747", "title": "\u5e73\u5747"}, {"description": "Python\u3084C++\u3067\u30a2\u30eb\u30b4\u30ea\u30ba\u30e0\u3092\u5b9f\u88c5\u3057\u305f\u308a\u3001HTML\u3067\u30a6\u30a7\u30d6\u30b5\u30a4\u30c8\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_coding", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "coding", "short": "\u30b3\u30fc\u30c9", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0"}, {"description": "\u6587\u66f8\u304b\u3089\u56fa\u6709\u8868\u73fe\uff08\u8457\u8005\u540d\u3084\u6570\u5024\u306a\u3069\uff09\u3084\u8a55\u5224\uff08\u30dd\u30b8\u30cd\u30ac\u306a\u3069\uff09\u3092\u62bd\u51fa\u3059\u308b", "field": "japanese_mtbench_extraction", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "extraction", "short": "\u62bd\u51fa", "title": "\u60c5\u5831\u62bd\u51fa"}, {"description": "\u6cd5\u5f8b\u3084\u7d4c\u6e08\u3001\u6b74\u53f2\u3001\u54f2\u5b66\u3001\u6559\u80b2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3059\u308b\u8ad6\u8aac\u3084\u6226\u7565\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_humanities", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "humanities", "short": "\u4eba\u6587", "title": "\u4eba\u6587\u79d1\u5b66"}, {"description": "\u4ee3\u6570\u3001\u5e7e\u4f55\u3001\u78ba\u7387\u3001\u6574\u6570\u306a\u3069\u306e\u554f\u984c\u3084\u6587\u7ae0\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_math", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "math", "short": "\u6570\u5b66", "title": "\u6570\u5b66"}, {"description": "\u5e38\u8b58\u3084\u63a8\u8ad6\u529b\u3092\u6d3b\u7528\u3057\u3066\u554f\u984c\u306b\u5bfe\u3059\u308b\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_reasoning", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "reasoning", "short": "\u63a8\u8ad6", "title": "\u63a8\u8ad6"}, {"description": "\u6709\u540d\u4eba\u3084\u6620\u753b\u4e2d\u306e\u4eba\u7269\u306b\u306a\u308a\u3059\u307e\u3059\u306a\u3069\u3001\u4eee\u60f3\u306e\u72b6\u6cc1\u3092\u60f3\u5b9a\u3057\u3066\u6587\u7ae0\u3092\u4f5c\u6587\u3059\u308b", "field": "japanese_mtbench_roleplay", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "roleplay", "short": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4", "title": "\u30ed\u30fc\u30eb\u30d7\u30ec\u30a4"}, {"description": "\u7269\u7406\u5b66\u3001\u5316\u5b66\u3001\u751f\u7269\u5b66\u3001\u5730\u7406\u3001\u5efa\u7bc9\u3001\u6a5f\u68b0\u5b66\u7fd2\u306a\u3069\u306e\u8a71\u984c\u306b\u95a2\u3057\u3066\u89e3\u7b54\u3092\u4f5c\u6210\u3059\u308b", "field": "japanese_mtbench_stem", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "stem", "short": "\u79d1\u30fb\u6280\u30fb\u5de5\u30fb\u6570", "title": "\u79d1\u5b66\u30fb\u6280\u8853\u30fb\u5de5\u5b66\u30fb\u6570\u5b66"}, {"description": "\u30d6\u30ed\u30b0\u8a18\u4e8b\u3084\u30e1\u30fc\u30eb\u6587\u9762\u3001\u30d5\u30a3\u30af\u30b7\u30e7\u30f3\u306e\u6587\u7ae0\u306a\u3069\u3092\u57f7\u7b46\u3059\u308b\u30bf\u30b9\u30af", "field": "japanese_mtbench_writing", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "GPT-4o (gpt-4o-2024-08-06) \u306b\u3088\u308b\u81ea\u52d5\u63a1\u70b9", "name": "writing", "short": "\u57f7\u7b46", "title": "\u57f7\u7b46"}], "title": "\u65e5\u672c\u8a9e MT-Bench"}, "ja_post": {"description": "\u65e5\u672c\u8a9e\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30af\u30c7\u30fc\u30bf\u3067\u63a8\u8ad6\u578b\u30e2\u30c7\u30eb\u3092\u542b\u3080\u4e8b\u5f8c\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u80fd\u529b\u3092\u6e2c\u5b9a\u3057\u307e\u3059\u3002\u8a55\u4fa1\u30b9\u30b3\u30a2\u306f0 (\u6700\u4f4e) \u304b\u30891 (\u6700\u9ad8) \u307e\u3067\u306e\u7bc4\u56f2\u306e\u5024\u3092\u3068\u308a\u307e\u3059\u3002", "for": ["post"], "taskdict": {"GPQA": {"category": "\u79d1\u5b66", "description": "\u691c\u7d22\u3067\u306f\u89e3\u3051\u306a\u3044\u5927\u5b66\u9662\u30ec\u30d9\u30eb\u306e\u65e5\u672c\u8a9e\u8cea\u554f\u5fdc\u7b54", "field": "gpqa_main_ja", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Huang et al.", "href": "https://arxiv.org/abs/2502.07346", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "GPQA", "short": "GPQA (\u65e5)", "title": "\u79d1\u5b66 (GPQA, \u65e5\u672c\u8a9e)"}, "JHumanEval": {"category": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0", "description": "\u30b3\u30fc\u30c9\u751f\u6210\u80fd\u529b\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30afHumanEval\u306e\u65e5\u672c\u8a9e\u8a33", "field": "jhumaneval_pass@1", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "link": {"author": "\u4f50\u85e4\u3089", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/P10-9.pdf", "year": 2024}, "metric": "Pass@1 (n=10)", "name": "JHumanEval", "short": "JHumanEval", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0 (JHumanEval)"}, "JamC-QA": {"category": "\u8cea\u554f\u5fdc\u7b54", "description": "\u65e5\u672c\u56fa\u6709\u306e\u77e5\u8b58\u3092\u554f\u3046\u8cea\u554f\u5fdc\u7b54", "field": "jamcqa", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "\u5ca1\u3089", "href": "https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "JamC-QA", "short": "JamC-QA", "title": "\u8cea\u554f\u5fdc\u7b54 (JamC-QA)", "version": "v1.0"}, "MATH100": {"category": "\u6570\u5b66", "description": "\u30b3\u30f3\u30c6\u30b9\u30c8\u30ec\u30d9\u30eb\u306e\u6570\u5b66", "field": "mclm_math_100_japanese", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Son et al.", "href": "https://aclanthology.org/2025.acl-long.699/", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "MATH100", "short": "MATH-100 (\u65e5)", "title": "\u6570\u5b66 (MATH-100)"}, "MMLU-ProX": {"category": "\u5927\u5b66\u30ec\u30d9\u30eb\u306e\u8a66\u9a13\u554f\u984c", "description": "\u591a\u5206\u91ce\u306b\u308f\u305f\u308b\u9ad8\u5ea6\u306a\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6\u80fd\u529b", "field": "mmlu_prox_japanese", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Xuan et al.", "href": "https://arxiv.org/abs/2503.10497", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "MMLU-ProX", "short": "MMLU-ProX (\u65e5)", "title": "\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6 (MMLU-ProX)"}, "WMT20enja": {"category": "\u82f1\u65e5\u6a5f\u68b0\u7ffb\u8a33", "description": "\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u306e\u7ffb\u8a33\uff08\u82f1\u8a9e\u304b\u3089\u65e5\u672c\u8a9e\uff09", "field": "wmt20_en_ja_bleu", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20enja", "short": "\u82f1\u65e5\u7ffb\u8a33", "title": "\u82f1\u65e5\u7ffb\u8a33 (WMT20)"}, "WMT20jaen": {"category": "\u65e5\u82f1\u6a5f\u68b0\u7ffb\u8a33", "description": "\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u306e\u7ffb\u8a33\uff08\u65e5\u672c\u8a9e\u304b\u3089\u82f1\u8a9e\uff09", "field": "wmt20_ja_en_bleu", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20jaen", "short": "\u65e5\u82f1\u7ffb\u8a33", "title": "\u65e5\u82f1\u7ffb\u8a33 (WMT20)"}, "__MIFEvalJa": {"category": "\u6307\u793a\u8ffd\u5f93", "description": "\u6307\u793a\u8ffd\u5f93\u80fd\u529b\u306e\u5236\u5fa1\u6027", "exclude_from_avg": true, "field": "mifeval_ja_inst_level_strict_acc", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "link": {"author": "Dussolle et al.", "href": "https://aclanthology.org/2025.findings-naacl.344/", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "__MIFEvalJa", "remark": "\u3053\u306e\u30bf\u30b9\u30af\u306e\u8a55\u4fa1\u7d50\u679c\u306f\u5e73\u5747\u306e\u7b97\u51fa\u304b\u3089\u9664\u5916\u3055\u308c\u307e\u3059", "short": "M-IFEval-Ja", "title": "M-IFEval-Ja"}, "avg": {"category": "\u5e73\u5747", "collective": true, "description": "\u4e8b\u5f8c\u5b66\u7fd2\u30e2\u30c7\u30eb\u5411\u3051\u306e\u65e5\u672c\u8a9e\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "ja_post_avg", "metric": "\u5e73\u5747", "name": "avg", "short": "\u4e8b\u5f8c\uff08\u65e5\uff09\u5e73\u5747", "title": "\u5e73\u5747"}}, "tasks": [{"category": "\u5e73\u5747", "collective": true, "description": "\u4e8b\u5f8c\u5b66\u7fd2\u30e2\u30c7\u30eb\u5411\u3051\u306e\u65e5\u672c\u8a9e\u30bf\u30b9\u30af\u306e\u5e73\u5747\u30b9\u30b3\u30a2", "field": "ja_post_avg", "metric": "\u5e73\u5747", "name": "avg", "short": "\u4e8b\u5f8c\uff08\u65e5\uff09\u5e73\u5747", "title": "\u5e73\u5747"}, {"category": "\u8cea\u554f\u5fdc\u7b54", "description": "\u65e5\u672c\u56fa\u6709\u306e\u77e5\u8b58\u3092\u554f\u3046\u8cea\u554f\u5fdc\u7b54", "field": "jamcqa", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "\u5ca1\u3089", "href": "https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q2-18.pdf", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "JamC-QA", "short": "JamC-QA", "title": "\u8cea\u554f\u5fdc\u7b54 (JamC-QA)", "version": "v1.0"}, {"category": "\u82f1\u65e5\u6a5f\u68b0\u7ffb\u8a33", "description": "\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u306e\u7ffb\u8a33\uff08\u82f1\u8a9e\u304b\u3089\u65e5\u672c\u8a9e\uff09", "field": "wmt20_en_ja_bleu", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20enja", "short": "\u82f1\u65e5\u7ffb\u8a33", "title": "\u82f1\u65e5\u7ffb\u8a33 (WMT20)"}, {"category": "\u65e5\u82f1\u6a5f\u68b0\u7ffb\u8a33", "description": "\u30cb\u30e5\u30fc\u30b9\u8a18\u4e8b\u306e\u7ffb\u8a33\uff08\u65e5\u672c\u8a9e\u304b\u3089\u82f1\u8a9e\uff09", "field": "wmt20_ja_en_bleu", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20jaen", "short": "\u65e5\u82f1\u7ffb\u8a33", "title": "\u65e5\u82f1\u7ffb\u8a33 (WMT20)"}, {"category": "\u5927\u5b66\u30ec\u30d9\u30eb\u306e\u8a66\u9a13\u554f\u984c", "description": "\u591a\u5206\u91ce\u306b\u308f\u305f\u308b\u9ad8\u5ea6\u306a\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6\u80fd\u529b", "field": "mmlu_prox_japanese", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Xuan et al.", "href": "https://arxiv.org/abs/2503.10497", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "MMLU-ProX", "short": "MMLU-ProX (\u65e5)", "title": "\u8a00\u8a9e\u7406\u89e3\u3068\u63a8\u8ad6 (MMLU-ProX)"}, {"category": "\u79d1\u5b66", "description": "\u691c\u7d22\u3067\u306f\u89e3\u3051\u306a\u3044\u5927\u5b66\u9662\u30ec\u30d9\u30eb\u306e\u65e5\u672c\u8a9e\u8cea\u554f\u5fdc\u7b54", "field": "gpqa_main_ja", "format": "\u591a\u80a2\u9078\u629e", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Huang et al.", "href": "https://arxiv.org/abs/2502.07346", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "GPQA", "short": "GPQA (\u65e5)", "title": "\u79d1\u5b66 (GPQA, \u65e5\u672c\u8a9e)"}, {"category": "\u6570\u5b66", "description": "\u30b3\u30f3\u30c6\u30b9\u30c8\u30ec\u30d9\u30eb\u306e\u6570\u5b66", "field": "mclm_math_100_japanese", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8\u3001\u601d\u8003\u306e\u9023\u9396\u30d7\u30ed\u30f3\u30d7\u30c8", "link": {"author": "Son et al.", "href": "https://aclanthology.org/2025.acl-long.699/", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "MATH100", "short": "MATH-100 (\u65e5)", "title": "\u6570\u5b66 (MATH-100)"}, {"category": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0", "description": "\u30b3\u30fc\u30c9\u751f\u6210\u80fd\u529b\u306e\u30d9\u30f3\u30c1\u30de\u30fc\u30afHumanEval\u306e\u65e5\u672c\u8a9e\u8a33", "field": "jhumaneval_pass@1", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "link": {"author": "\u4f50\u85e4\u3089", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/P10-9.pdf", "year": 2024}, "metric": "Pass@1 (n=10)", "name": "JHumanEval", "short": "JHumanEval", "title": "\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0 (JHumanEval)"}, {"category": "\u6307\u793a\u8ffd\u5f93", "description": "\u6307\u793a\u8ffd\u5f93\u80fd\u529b\u306e\u5236\u5fa1\u6027", "exclude_from_avg": true, "field": "mifeval_ja_inst_level_strict_acc", "format": "\u81ea\u7531\u8a18\u8ff0", "input": "\u30bc\u30ed\u30b7\u30e7\u30c3\u30c8", "link": {"author": "Dussolle et al.", "href": "https://aclanthology.org/2025.findings-naacl.344/", "year": 2025}, "metric": "\u6b63\u89e3\u7387", "name": "__MIFEvalJa", "remark": "\u3053\u306e\u30bf\u30b9\u30af\u306e\u8a55\u4fa1\u7d50\u679c\u306f\u5e73\u5747\u306e\u7b97\u51fa\u304b\u3089\u9664\u5916\u3055\u308c\u307e\u3059", "short": "M-IFEval-Ja", "title": "M-IFEval-Ja"}], "title": "\u4e8b\u5f8c\u5b66\u7fd2\uff08\u65e5\u672c\u8a9e\uff09"}};
const g_updater = [];

var swallow_leaderboard_models = function(query, sortkey) {
  let models = [];

  if ("name" in query) {
    // Return a single model specified by a name.
    return g_models[query.name];

  } else if ("includes" in query) {
    for (let name of query.includes) {
      if (name in g_models) {
        models.push(g_models[name]);
      }
    }

  } else {
    for (let key in g_models) {
      const model = g_models[key];

      // Filter by the model family.
      if ("family" in query) {
        const family = model.family.toLowerCase();
        if (Array.isArray(query.family)) {
          let m = false;
          for (let f of query.family) {
            if (family.startsWith(f.toLowerCase())) {
              m = true;
              break;
            }
          }
          if (!m) {
            continue;
          }
        } else {
          if (!family.startsWith(query.family.toLowerCase())) {
            continue;
          }
        }
      }

      // Filter by the model size.
      if ("minp" in query && model['params'] < query.minp) {
        continue;
      }
      if ("maxp" in query && query.maxp <= model['params']) {
        continue;
      }

      // Filter by the exclude list.
      if ("excludes" in query && query.excludes.includes(model['id'])) {
        continue;
      }
      
      models.push(model);
    }
  }

  // Sort models.
  if (sortkey !== undefined) {
    models.sort((a, b) => a.results[sortkey[0]][sortkey[1]] - b.results[sortkey[0]][sortkey[1]]);
  }

  return models;
};

var swallow_leaderboard_get_taskdef = function(query) {
  for (let t of g_tasks[query[0]].tasks) {
    if (query[1] == t.name) {
      return t;
    }
  }
  return null;
};

var swallow_leaderboard_tasks = function(queries) {
  let tasks = [];

  for (let query of queries) {
    for (let t of g_tasks[query[0]].tasks) {
      if (query[1] == t.name || query[1] == "__ALL__" || (query[1] == "*" && !t.collective) || (query[1] == "+" && !t.collective && !t.exclude_from_avg)) {
        tasks.push({category: query[0], task: t});
      }
    }
  }

  return tasks;
};

var swallow_leaderboard_chart_bar = function(element, config) {
  var onclick = function(chartContext, options) {
    config.sort = (config.sort + 1) % config.tasks.length;
    option = get_option(element, config);
    ApexCharts.exec(element, 'updateOptions', option, false, true);
  };

  var get_option = function(element, config) {
    const models = "sort" in config ?
      swallow_leaderboard_models(config.models, config.tasks[config.sort]) :
      swallow_leaderboard_models(config.models);

    // Build series.
    let series = [];
    let labels = [];
    let tasks = swallow_leaderboard_tasks(config.tasks);

    if ("groupby" in config && config.groupby == "task") {
      for (var model of models) {
        let data = [];
        for (var q of tasks) {
          data.push(model.results[q.category][q.task.name]);
        }
        series.push({name: model.name, data: data});
      }

      // Build labels.
      for (var q of tasks) {
        labels.push(q.task.title);
      }

    } else {
      for (var query of config.tasks) {
        let data = [];
        for (var model of models) {
          data.push(model.results[query[0]][query[1]]);
        }
        const t = swallow_leaderboard_get_taskdef(query);
        let title = ("show_category" in config && config.show_category) ? g_tasks[query[0]].title : "";
        title += " " + t.title;
        series.push({name: title, data: data});
      }

      // Build labels.
      for (var model of models) {
        labels.push(model.name);
      }
    }

    const pb = "pb" in config ? config.pb : 0;
  
    // Determine the orientation.
    const horizontal = (window.outerWidth < window.outerHeight);
    const height = horizontal ? Math.max(480, labels.length * 16 + 64) : 480;
    const padding = horizontal ? {} : { left: 48, right: 48, top: 0, bottom: pb };
    return {
      chart: {
        type: "bar",
        id: element,
        fontFamily: 'inherit',
        height: height,
        parentHeightOffset: 0,
        animations: {
          enabled: true
        },
        events: {
          xAxisLabelClick: onclick,
        },
      },
      plotOptions: {
        bar: {
          horizontal: horizontal,
        },
      },
      grid: {
        padding: padding,
      },
      series: series,
      xaxis: {
        categories: labels,
        labels: {
          rotateAlways: true,
          hideOverlappingLabels: false,
          style: {
//            fontSize: '9px',
          }
        }
      },
      yaxis: {
        tickAmount: 5,
        min: 0.,
        max: 1.,
        labels: {
          formatter: function(val) {
            return typeof val == "string" ? val : parseFloat(val).toFixed(1);
          }
        },
      },
      dataLabels: {
        enabled: false
      },
      stroke: {
        show: true,
        width: 2,
        colors: ['transparent']
      },
      legend: {
        position: 'top',
      },
      tooltip: {
        shared: false,
        intersect: true,
        marker: {
          show: false,
        },
        y: {
          formatter: function(val) {
            return typeof val == "string" ? val : parseFloat(val).toFixed(4);
          }
        },
      },
      noData: {
        text: " (Select a model)",
      },
      theme: {
        mode: document.documentElement.getAttribute("data-bs-theme") == "dark" ? "dark" : "light",
      },
    }
  };

  // Create the bar chart.
  option = get_option(element, config);
  window.ApexCharts && (new ApexCharts(document.getElementById(element), option)).render();

  // Register an update function.
  g_updater.push(function(target, updates) {
    if (target == "" || target == element) {
      Object.assign(config, updates);
      option = get_option(element, config);
      ApexCharts.exec(element, 'updateOptions', option, false, true);
    }
  });
};

var swallow_leaderboard_chart_radar = function(element, config) {
  var get_option = function(element, config) {
    const models = swallow_leaderboard_models(config.models);

    // Build series.
    let series = [];
    var labels = [];
    for (var model of models) {
      let data = [];
      labels = [];

      for (let query of config.tasks) {
        for (let t of g_tasks[query[0]].tasks) {
          if (query[1] == t.name || (query[1] == "*" && !t.collective) || (query[1] == "+" && !t.collective && !t.exclude_from_avg)) {
            data.push(model.results[query[0]][t.name]);
            labels.push(t.short);
          }
        }
      }
      series.push({
        name: model.name,
        data: data,
      });
    }

    return {
      chart: {
        type: "radar",
        id: element,
        fontFamily: 'inherit',
        height: config.height,
        parentHeightOffset: 0,
      },
      series: series,
      xaxis: {
        categories: labels,
      },
      yaxis: {
        show: false,
        tickAmount: 5,
        min: 0.,
        max: 1.,
      },
      legend: {
        position: 'top',
      },
      tooltip: {
        marker: {
          show: false,
        },
      },
      noData: {
        text: " (Select a model)",
      },
      theme: {
        mode: document.documentElement.getAttribute("data-bs-theme") == "dark" ? "dark" : "light",
      },
    };
  };
  
  // Create the radar chart.
  option = get_option(element, config);
  window.ApexCharts && (new ApexCharts(document.getElementById(element), option)).render();

  // Register an update function.
  g_updater.push(function(target, updates) {
    if (target == "" || target == element) {
      Object.assign(config, updates);
      option = get_option(element, config);
      ApexCharts.exec(element, 'updateOptions', option, false, true);
    }
  });
};

var swallow_leaderboard_chart_scatter = function(element, config) {
  var get_option = function(element, config) {
    const models = swallow_leaderboard_models(config.models);
    const xcat = config.xaxis[0];
    const xname = config.xaxis[1]
    const ycat = config.yaxis[0];
    const yname = config.yaxis[1];
    // There seems to be no way to obtain a color palette from ApexCharts,
    // so these colors are hard coded.
    const theme_colors = document.documentElement.getAttribute("data-bs-theme") == "dark" ? 
      ['#4ECDC4', '#C7F464', '#81D4FA', '#FD6A6A', '#546E7A']: 
      ['#008FFB', '#00E396', '#FEB019', '#FF4560', '#775DD0'];

    var format_params = function(val) {
      const v = Math.pow(2, parseFloat(val));
      return v < 10 ? v.toFixed(1) : v.toFixed(0);
    };

    var format_value = function(val) {
      return typeof val == "string" ? val : parseFloat(val).toFixed(4);
    };

    var build_axis = function(category, name) {
      if (category == "params" || category == "active_params") {
        
        title = category == "active_params" ? "" : "";
        
        return {
          min: 0, // 2^0 = 1.
          max: 8, // 2^8 = 256.
          title: {text: title + " [B]"},
          tickAmount: 10,
          labels: {
            formatter: function(val) {
              const v = Math.pow(2, parseFloat(val));
              return v < 10 ? v.toFixed(1) : v.toFixed(0);
            }
          }
        }
      } else {
        return {
          min: 0,
          max: 1,
          title: {text: g_tasks[category].taskdict[name].title },
          tickAmount: 10,
          labels: {
            formatter: function(val) {
              return parseFloat(val).toFixed(1)
            }
          }
        }
      }
    };

    // Build series.
    let series = [];
    for (let model of models) {
      const x = (xcat == "params" || xcat == "active_params") ? Math.log2(model[xcat]) : model.results[xcat][xname];
      const y = (ycat == "params" || ycat == "active_params") ? Math.log2(model[ycat]) : model.results[ycat][yname];
      const family = model.family.toLowerCase();
      let color_index = 4;
      if (family.startsWith("gpt") || family.startsWith("o3") || family.startsWith("o4")) {
        color_index = 0;
      } else if (family.startsWith("llama")) {
        color_index = 1;
      } else if (family.startsWith("gemma")) {
        color_index = 2;
      } else if (family.startsWith("qwen")) {
        color_index = 3;
      }
      series.push({name: model.name, data: [[x, y]], color: theme_colors[color_index]});
    }
    const xaxis = build_axis(xcat, xname);
    const yaxis = build_axis(ycat, yname);

    return {
      chart: {
        type: "scatter",
        fontFamily: 'inherit',
        height: 480,
        parentHeightOffset: 0,
        toolbar: {
          tools: {
            download: true,
            selection: false,
            zoom: false,
            zoomin: false,
            zoomout: false,
            pan: false,
            reset: false,
          },
        },
        zoom: {
          enabled: false,
          allowMouseWheelZoom: false,
        },
      },
      series: series,
      xaxis: xaxis,
      yaxis: yaxis,
      legend: {
        show: false,
      },
      markers: {
        size: 4,
      },
      tooltip: {
        marker: {show: false},
        x: {formatter: (xcat == "params" || xcat == "active_params") ? format_params : format_value},
        y: {formatter: (ycat == "params" || ycat == "active_params") ? format_params : format_value},
      },
      theme: {
        mode: document.documentElement.getAttribute("data-bs-theme") == "dark" ? "dark" : "light",
      },
    };
  };

  // Create the radar chart.
  option = get_option(element, config);
  let obj_scatter = new ApexCharts(document.getElementById(element), option);
  console.log(obj_scatter);
  obj_scatter.render();

  // Register an update function.
  g_updater.push(function(target, updates) {
    if (target == "" || target == element) {
      Object.assign(config, updates);
      option = get_option(element, config);
      obj_scatter.updateOptions(option, false, true);
    }
  });
};

var swallow_leaderboard_chart = function(element, config) {
  //
  if (config.type == "bar") {
    swallow_leaderboard_chart_bar(element, config);
  } else if (config.type == "radar") {
    swallow_leaderboard_chart_radar(element, config);
  } else if (config.type == "scatter") {
    swallow_leaderboard_chart_scatter(element, config);
  }
};

var swallow_leaderboard_update = function(target, updates) {
  for (let i = 0; i < g_updater.length; ++i) {
    g_updater[i](target, updates);
  }
}
