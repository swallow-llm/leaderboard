const g_models = {"Qwen/Qwen2.5-0.5B-Instruct": {"base_model": "Qwen2.5-0.5B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-0.5B-Instruct", "name": "Qwen2.5-0.5B-Instruct", "params": 0.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.272, 0.184, 0.398, 0.501, 0.767, 0.471, 0.19, 0.236, 0.106, 0.24], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.382, 0.401, 0.157, 0.687, 0.112, 0.08, 0.095, 0.067, 0.318, 0.135], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.335, 0.284, 0.285, 0.317, 0.248, 0.294, 0.279, 0.313], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 118, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.336}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 69, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.294}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 121, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.243}}, "results": {"en_basic": {"BBH": 0.106, "En Avg": 0.336, "GSM8K": 0.19, "HellaSwag": 0.398, "HumanEval": 0.24, "MATH": 0.236, "MMLU": 0.471, "OpenBookQA": 0.272, "SQuAD2": 0.501, "TriviaQA": 0.184, "XWINO": 0.767}, "ja_basic": {"JComQA": 0.382, "JEMHopQA": 0.401, "JHumanEval": 0.135, "JMMLU": 0.318, "JSQuAD": 0.687, "Ja Avg": 0.243, "MGSM": 0.08, "NIILC": 0.157, "WMT20-en-ja": 0.095, "WMT20-ja-en": 0.067, "XL-Sum": 0.112}, "ja_mtb": {"JMT Avg": 0.294, "coding": 0.335, "extraction": 0.284, "humanities": 0.285, "math": 0.317, "reasoning": 0.248, "roleplay": 0.294, "stem": 0.279, "writing": 0.313}, "other": {"GPQA": 0.045}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-0.5B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct"}, "Qwen/Qwen2.5-1.5B-Instruct": {"base_model": "Qwen2.5-1.5B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-1.5B-Instruct", "name": "Qwen2.5-1.5B-Instruct", "params": 1.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.334, 0.378, 0.503, 0.501, 0.844, 0.604, 0.257, 0.272, 0.272, 0.277], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.812, 0.276, 0.241, 0.847, 0.128, 0.292, 0.147, 0.119, 0.447, 0.242], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.408, 0.513, 0.456, 0.527, 0.352, 0.473, 0.406, 0.469], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 99, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.424}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 61, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.45}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 107, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.355}}, "results": {"en_basic": {"BBH": 0.272, "En Avg": 0.424, "GSM8K": 0.257, "HellaSwag": 0.503, "HumanEval": 0.277, "MATH": 0.272, "MMLU": 0.604, "OpenBookQA": 0.334, "SQuAD2": 0.501, "TriviaQA": 0.378, "XWINO": 0.844}, "ja_basic": {"JComQA": 0.812, "JEMHopQA": 0.276, "JHumanEval": 0.242, "JMMLU": 0.447, "JSQuAD": 0.847, "Ja Avg": 0.355, "MGSM": 0.292, "NIILC": 0.241, "WMT20-en-ja": 0.147, "WMT20-ja-en": 0.119, "XL-Sum": 0.128}, "ja_mtb": {"JMT Avg": 0.45, "coding": 0.408, "extraction": 0.513, "humanities": 0.456, "math": 0.527, "reasoning": 0.352, "roleplay": 0.473, "stem": 0.406, "writing": 0.469}, "other": {"GPQA": 0.141}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-1.5B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-1.5B-Instruct"}, "Qwen/Qwen2.5-3B-Instruct": {"base_model": "Qwen2.5-3B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-3B-Instruct", "name": "Qwen2.5-3B-Instruct", "params": 3.1, "radar": {"en_basic": {"id": "en_basic", "series": [0.364, 0.446, 0.562, 0.504, 0.869, 0.664, 0.096, 0.612, 0.128, 0.471], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.876, 0.304, 0.293, 0.866, 0.144, 0.228, 0.198, 0.168, 0.536, 0.474], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.567, 0.647, 0.597, 0.665, 0.457, 0.649, 0.526, 0.637], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 89, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.472}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 42, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.593}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 89, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.409}}, "results": {"en_basic": {"BBH": 0.128, "En Avg": 0.472, "GSM8K": 0.096, "HellaSwag": 0.562, "HumanEval": 0.471, "MATH": 0.612, "MMLU": 0.664, "OpenBookQA": 0.364, "SQuAD2": 0.504, "TriviaQA": 0.446, "XWINO": 0.869}, "ja_basic": {"JComQA": 0.876, "JEMHopQA": 0.304, "JHumanEval": 0.474, "JMMLU": 0.536, "JSQuAD": 0.866, "Ja Avg": 0.409, "MGSM": 0.228, "NIILC": 0.293, "WMT20-en-ja": 0.198, "WMT20-ja-en": 0.168, "XL-Sum": 0.144}, "ja_mtb": {"JMT Avg": 0.593, "coding": 0.567, "extraction": 0.647, "humanities": 0.597, "math": 0.665, "reasoning": 0.457, "roleplay": 0.649, "stem": 0.526, "writing": 0.637}, "other": {"GPQA": 0.304}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-3B-Instruct", "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct"}, "SakanaAI/TinySwallow-1.5B-Instruct": {"base_model": "TinySwallow-1.5B", "category": ["index-chat", "category-under-5b-chat"], "date": "2025-01-30", "id": "SakanaAI/TinySwallow-1.5B-Instruct", "name": "TinySwallow-1.5B-Instruct", "params": 1.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.31, 0.309, 0.487, 0.501, 0.843, 0.56, 0.398, 0.162, 0.25, 0.294], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.803, 0.345, 0.447, 0.856, 0.159, 0.308, 0.203, 0.143, 0.461, 0.251], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.434, 0.572, 0.772, 0.453, 0.392, 0.645, 0.61, 0.643], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 103, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.411}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 49, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.565}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 91, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.398}}, "results": {"en_basic": {"BBH": 0.25, "En Avg": 0.411, "GSM8K": 0.398, "HellaSwag": 0.487, "HumanEval": 0.294, "MATH": 0.162, "MMLU": 0.56, "OpenBookQA": 0.31, "SQuAD2": 0.501, "TriviaQA": 0.309, "XWINO": 0.843}, "ja_basic": {"JComQA": 0.803, "JEMHopQA": 0.345, "JHumanEval": 0.251, "JMMLU": 0.461, "JSQuAD": 0.856, "Ja Avg": 0.398, "MGSM": 0.308, "NIILC": 0.447, "WMT20-en-ja": 0.203, "WMT20-ja-en": 0.143, "XL-Sum": 0.159}, "ja_mtb": {"JMT Avg": 0.565, "coding": 0.434, "extraction": 0.572, "humanities": 0.772, "math": 0.453, "reasoning": 0.392, "roleplay": 0.645, "stem": 0.61, "writing": 0.643}, "other": {"GPQA": 0.013}}, "sortkey": "tinyswallow", "uri": "SakanaAI_TinySwallow-1.5B-Instruct", "url": "https://huggingface.co/SakanaAI/TinySwallow-1.5B-Instruct"}, "google/gemma-2-2b-it": {"base_model": "Gemma 2 2B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-06-27", "id": "google/gemma-2-2b-it", "name": "Gemma 2 2B IT", "params": 2.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.354, 0.502, 0.52, 0.548, 0.878, 0.569, 0.44, 0.23, 0.464, 0.382], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.862, 0.348, 0.315, 0.879, 0.117, 0.252, 0.207, 0.183, 0.437, 0.321], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.454, 0.587, 0.693, 0.524, 0.445, 0.654, 0.567, 0.63], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 86, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.489}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 47, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.569}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 95, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.392}}, "results": {"en_basic": {"BBH": 0.464, "En Avg": 0.489, "GSM8K": 0.44, "HellaSwag": 0.52, "HumanEval": 0.382, "MATH": 0.23, "MMLU": 0.569, "OpenBookQA": 0.354, "SQuAD2": 0.548, "TriviaQA": 0.502, "XWINO": 0.878}, "ja_basic": {"JComQA": 0.862, "JEMHopQA": 0.348, "JHumanEval": 0.321, "JMMLU": 0.437, "JSQuAD": 0.879, "Ja Avg": 0.392, "MGSM": 0.252, "NIILC": 0.315, "WMT20-en-ja": 0.207, "WMT20-ja-en": 0.183, "XL-Sum": 0.117}, "ja_mtb": {"JMT Avg": 0.569, "coding": 0.454, "extraction": 0.587, "humanities": 0.693, "math": 0.524, "reasoning": 0.445, "roleplay": 0.654, "stem": 0.567, "writing": 0.63}, "other": {"GPQA": 0.08}}, "sortkey": "gemma 2", "uri": "google_gemma-2-2b-it", "url": "https://huggingface.co/google/gemma-2-2b-it"}, "google/gemma-2-2b-jpn-it": {"base_model": "Gemma 2 2B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-06-27", "id": "google/gemma-2-2b-jpn-it", "name": "Gemma 2 JPN", "params": 2.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.37, 0.503, 0.532, 0.539, 0.879, 0.557, 0.351, 0.132, 0.451, 0.392], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.845, 0.321, 0.291, 0.877, 0.131, 0.192, 0.204, 0.18, 0.418, 0.311], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.467, 0.488, 0.741, 0.379, 0.406, 0.66, 0.589, 0.672], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 90, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.471}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 50, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.55}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 100, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.377}}, "results": {"en_basic": {"BBH": 0.451, "En Avg": 0.471, "GSM8K": 0.351, "HellaSwag": 0.532, "HumanEval": 0.392, "MATH": 0.132, "MMLU": 0.557, "OpenBookQA": 0.37, "SQuAD2": 0.539, "TriviaQA": 0.503, "XWINO": 0.879}, "ja_basic": {"JComQA": 0.845, "JEMHopQA": 0.321, "JHumanEval": 0.311, "JMMLU": 0.418, "JSQuAD": 0.877, "Ja Avg": 0.377, "MGSM": 0.192, "NIILC": 0.291, "WMT20-en-ja": 0.204, "WMT20-ja-en": 0.18, "XL-Sum": 0.131}, "ja_mtb": {"JMT Avg": 0.55, "coding": 0.467, "extraction": 0.488, "humanities": 0.741, "math": 0.379, "reasoning": 0.406, "roleplay": 0.66, "stem": 0.589, "writing": 0.672}, "other": {"GPQA": 0.033}}, "sortkey": "gemma 2 jpn", "uri": "google_gemma-2-2b-jpn-it", "url": "https://huggingface.co/google/gemma-2-2b-jpn-it"}, "google/gemma-3-1b-it": {"base_model": "Gemma 3 1B", "category": ["index-chat", "category-under-5b-chat"], "date": "2025-03-12", "id": "google/gemma-3-1b-it", "name": "Gemma 3 1B IT", "params": 1, "radar": {"en_basic": {"id": "en_basic", "series": [0.272, 0.229, 0.421, 0.501, 0.786, 0.398, 0.256, 0.34, 0.379, 0.335], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.526, 0.33, 0.237, 0.7, 0.113, 0.088, 0.166, 0.115, 0.332, 0.245], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.379, 0.497, 0.68, 0.385, 0.322, 0.628, 0.54, 0.651], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 108, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.392}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 56, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.51}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 117, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.285}}, "results": {"en_basic": {"BBH": 0.379, "En Avg": 0.392, "GSM8K": 0.256, "HellaSwag": 0.421, "HumanEval": 0.335, "MATH": 0.34, "MMLU": 0.398, "OpenBookQA": 0.272, "SQuAD2": 0.501, "TriviaQA": 0.229, "XWINO": 0.786}, "ja_basic": {"JComQA": 0.526, "JEMHopQA": 0.33, "JHumanEval": 0.245, "JMMLU": 0.332, "JSQuAD": 0.7, "Ja Avg": 0.285, "MGSM": 0.088, "NIILC": 0.237, "WMT20-en-ja": 0.166, "WMT20-ja-en": 0.115, "XL-Sum": 0.113}, "ja_mtb": {"JMT Avg": 0.51, "coding": 0.379, "extraction": 0.497, "humanities": 0.68, "math": 0.385, "reasoning": 0.322, "roleplay": 0.628, "stem": 0.54, "writing": 0.651}, "other": {"GPQA": 0.167}}, "sortkey": "gemma 3", "uri": "google_gemma-3-1b-it", "url": "https://huggingface.co/google/gemma-3-1b-it"}, "google/gemma-3-4b-it": {"base_model": "Gemma 3 4B", "category": ["index-chat", "category-under-5b-chat"], "date": "2025-03-12", "id": "google/gemma-3-4b-it", "name": "Gemma 3 4B IT", "params": 4.3, "radar": {"en_basic": {"id": "en_basic", "series": [0.412, 0.5, 0.56, 0.552, 0.872, 0.583, 0.769, 0.306, 0.598, 0.513], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.818, 0.444, 0.404, 0.801, 0.134, 0.332, 0.217, 0.169, 0.477, 0.365], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.603, 0.724, 0.798, 0.767, 0.498, 0.803, 0.775, 0.822], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 59, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.566}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 24, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.724}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 87, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.416}}, "results": {"en_basic": {"BBH": 0.598, "En Avg": 0.566, "GSM8K": 0.769, "HellaSwag": 0.56, "HumanEval": 0.513, "MATH": 0.306, "MMLU": 0.583, "OpenBookQA": 0.412, "SQuAD2": 0.552, "TriviaQA": 0.5, "XWINO": 0.872}, "ja_basic": {"JComQA": 0.818, "JEMHopQA": 0.444, "JHumanEval": 0.365, "JMMLU": 0.477, "JSQuAD": 0.801, "Ja Avg": 0.416, "MGSM": 0.332, "NIILC": 0.404, "WMT20-en-ja": 0.217, "WMT20-ja-en": 0.169, "XL-Sum": 0.134}, "ja_mtb": {"JMT Avg": 0.724, "coding": 0.603, "extraction": 0.724, "humanities": 0.798, "math": 0.767, "reasoning": 0.498, "roleplay": 0.803, "stem": 0.775, "writing": 0.822}, "other": {"GPQA": 0.25}}, "sortkey": "gemma 3", "uri": "google_gemma-3-4b-it", "url": "https://huggingface.co/google/gemma-3-4b-it"}, "llm-jp/llm-jp-3-1.8b-instruct": {"base_model": "llm-jp-3-1.8b", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "llm-jp/llm-jp-3-1.8b-instruct", "name": "llm-jp-3-1.8b-instruct", "params": 1.8, "radar": {"en_basic": {"id": "en_basic", "series": [0.286, 0.296, 0.485, 0.502, 0.847, 0.277, 0.043, 0.016, 0.29, 0.087], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.324, 0.413, 0.466, 0.837, 0.105, 0.08, 0.206, 0.142, 0.292, 0.061], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.274, 0.321, 0.68, 0.281, 0.301, 0.628, 0.504, 0.617], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 120, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.313}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 60, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.451}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 116, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.293}}, "results": {"en_basic": {"BBH": 0.29, "En Avg": 0.313, "GSM8K": 0.043, "HellaSwag": 0.485, "HumanEval": 0.087, "MATH": 0.016, "MMLU": 0.277, "OpenBookQA": 0.286, "SQuAD2": 0.502, "TriviaQA": 0.296, "XWINO": 0.847}, "ja_basic": {"JComQA": 0.324, "JEMHopQA": 0.413, "JHumanEval": 0.061, "JMMLU": 0.292, "JSQuAD": 0.837, "Ja Avg": 0.293, "MGSM": 0.08, "NIILC": 0.466, "WMT20-en-ja": 0.206, "WMT20-ja-en": 0.142, "XL-Sum": 0.105}, "ja_mtb": {"JMT Avg": 0.451, "coding": 0.274, "extraction": 0.321, "humanities": 0.68, "math": 0.281, "reasoning": 0.301, "roleplay": 0.628, "stem": 0.504, "writing": 0.617}, "other": {"GPQA": 0.123}}, "sortkey": "llm jp 3", "uri": "llm-jp_llm-jp-3-1.8b-instruct", "url": "https://huggingface.co/llm-jp/llm-jp-3-1.8b-instruct"}, "llm-jp/llm-jp-3-3.7b-instruct": {"base_model": "llm-jp-3-3.7b", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "llm-jp/llm-jp-3-3.7b-instruct", "name": "llm-jp-3-3.7b-instruct", "params": 3.7, "radar": {"en_basic": {"id": "en_basic", "series": [0.31, 0.398, 0.534, 0.503, 0.862, 0.349, 0.071, 0.022, 0.324, 0.099], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.533, 0.464, 0.529, 0.847, 0.139, 0.152, 0.224, 0.17, 0.359, 0.085], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.311, 0.418, 0.73, 0.311, 0.339, 0.618, 0.551, 0.6], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 116, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.347}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 59, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.485}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 110, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.35}}, "results": {"en_basic": {"BBH": 0.324, "En Avg": 0.347, "GSM8K": 0.071, "HellaSwag": 0.534, "HumanEval": 0.099, "MATH": 0.022, "MMLU": 0.349, "OpenBookQA": 0.31, "SQuAD2": 0.503, "TriviaQA": 0.398, "XWINO": 0.862}, "ja_basic": {"JComQA": 0.533, "JEMHopQA": 0.464, "JHumanEval": 0.085, "JMMLU": 0.359, "JSQuAD": 0.847, "Ja Avg": 0.35, "MGSM": 0.152, "NIILC": 0.529, "WMT20-en-ja": 0.224, "WMT20-ja-en": 0.17, "XL-Sum": 0.139}, "ja_mtb": {"JMT Avg": 0.485, "coding": 0.311, "extraction": 0.418, "humanities": 0.73, "math": 0.311, "reasoning": 0.339, "roleplay": 0.618, "stem": 0.551, "writing": 0.6}, "other": {"GPQA": 0.112}}, "sortkey": "llm jp 3", "uri": "llm-jp_llm-jp-3-3.7b-instruct", "url": "https://huggingface.co/llm-jp/llm-jp-3-3.7b-instruct"}, "meta-llama/Llama-3.2-1B-Instruct": {"base_model": "Llama 3.2 1B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "meta-llama/Llama-3.2-1B-Instruct", "name": "Llama 3.2 1B Instruct", "params": 1.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.274, 0.375, 0.44, 0.501, 0.837, 0.454, 0.318, 0.172, 0.362, 0.347], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.397, 0.346, 0.179, 0.57, 0.075, 0.164, 0.07, 0.091, 0.287, 0.207], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.254, 0.376, 0.218, 0.307, 0.267, 0.262, 0.246, 0.258], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 104, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.408}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 70, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.273}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 122, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.239}}, "results": {"en_basic": {"BBH": 0.362, "En Avg": 0.408, "GSM8K": 0.318, "HellaSwag": 0.44, "HumanEval": 0.347, "MATH": 0.172, "MMLU": 0.454, "OpenBookQA": 0.274, "SQuAD2": 0.501, "TriviaQA": 0.375, "XWINO": 0.837}, "ja_basic": {"JComQA": 0.397, "JEMHopQA": 0.346, "JHumanEval": 0.207, "JMMLU": 0.287, "JSQuAD": 0.57, "Ja Avg": 0.239, "MGSM": 0.164, "NIILC": 0.179, "WMT20-en-ja": 0.07, "WMT20-ja-en": 0.091, "XL-Sum": 0.075}, "ja_mtb": {"JMT Avg": 0.273, "coding": 0.254, "extraction": 0.376, "humanities": 0.218, "math": 0.307, "reasoning": 0.267, "roleplay": 0.262, "stem": 0.246, "writing": 0.258}, "other": {"GPQA": 0.051}}, "sortkey": "llama 3.2", "uri": "meta-llama_Llama-3.2-1B-Instruct", "url": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct"}, "meta-llama/Llama-3.2-3B-Instruct": {"base_model": "Llama 3.2 3B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-09-25", "id": "meta-llama/Llama-3.2-3B-Instruct", "name": "Llama 3.2 3B Instruct", "params": 3.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.306, 0.556, 0.524, 0.54, 0.874, 0.597, 0.629, 0.324, 0.512, 0.511], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.783, 0.304, 0.268, 0.846, 0.112, 0.372, 0.173, 0.155, 0.404, 0.387], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.426, 0.593, 0.431, 0.389, 0.292, 0.35, 0.38, 0.38], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 74, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.537}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 66, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.405}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 98, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.38}}, "results": {"en_basic": {"BBH": 0.512, "En Avg": 0.537, "GSM8K": 0.629, "HellaSwag": 0.524, "HumanEval": 0.511, "MATH": 0.324, "MMLU": 0.597, "OpenBookQA": 0.306, "SQuAD2": 0.54, "TriviaQA": 0.556, "XWINO": 0.874}, "ja_basic": {"JComQA": 0.783, "JEMHopQA": 0.304, "JHumanEval": 0.387, "JMMLU": 0.404, "JSQuAD": 0.846, "Ja Avg": 0.38, "MGSM": 0.372, "NIILC": 0.268, "WMT20-en-ja": 0.173, "WMT20-ja-en": 0.155, "XL-Sum": 0.112}, "ja_mtb": {"JMT Avg": 0.405, "coding": 0.426, "extraction": 0.593, "humanities": 0.431, "math": 0.389, "reasoning": 0.292, "roleplay": 0.35, "stem": 0.38, "writing": 0.38}, "other": {"GPQA": 0.259}}, "sortkey": "llama 3.2", "uri": "meta-llama_Llama-3.2-3B-Instruct", "url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct"}, "microsoft/Phi-3-mini-128k-instruct": {"base_model": "(private)", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-04-23", "id": "microsoft/Phi-3-mini-128k-instruct", "name": "Phi-3-Mini-128K-Instruct", "params": 3.8, "radar": {"en_basic": {"id": "en_basic", "series": [0.422, 0.526, 0.605, 0.559, 0.871, 0.695, 0.759, 0.368, 0.711, 0.627], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.72, 0.394, 0.208, 0.832, 0.132, 0.408, 0.15, 0.136, 0.409, 0.428], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.535, 0.68, 0.553, 0.514, 0.416, 0.505, 0.465, 0.525], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 42, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.614}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 54, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.524}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 97, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.382}}, "results": {"en_basic": {"BBH": 0.711, "En Avg": 0.614, "GSM8K": 0.759, "HellaSwag": 0.605, "HumanEval": 0.627, "MATH": 0.368, "MMLU": 0.695, "OpenBookQA": 0.422, "SQuAD2": 0.559, "TriviaQA": 0.526, "XWINO": 0.871}, "ja_basic": {"JComQA": 0.72, "JEMHopQA": 0.394, "JHumanEval": 0.428, "JMMLU": 0.409, "JSQuAD": 0.832, "Ja Avg": 0.382, "MGSM": 0.408, "NIILC": 0.208, "WMT20-en-ja": 0.15, "WMT20-ja-en": 0.136, "XL-Sum": 0.132}, "ja_mtb": {"JMT Avg": 0.524, "coding": 0.535, "extraction": 0.68, "humanities": 0.553, "math": 0.514, "reasoning": 0.416, "roleplay": 0.505, "stem": 0.465, "writing": 0.525}, "other": {"GPQA": 0.275}}, "sortkey": "phi 3 mini 128k", "uri": "microsoft_Phi-3-mini-128k-instruct", "url": "https://huggingface.co/microsoft/Phi-3-mini-128k-instruct"}, "rinna/gemma-2-baku-2b-it": {"base_model": "Gemma 2 Baku 2B", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-10-03", "id": "rinna/gemma-2-baku-2b-it", "name": "Gemma 2 Baku 2B IT", "params": 2.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.342, 0.416, 0.511, 0.522, 0.871, 0.526, 0.027, 0.174, 0.063, 0.158], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.855, 0.228, 0.39, 0.877, 0.115, 0.172, 0.255, 0.19, 0.415, 0.165], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.47, 0.625, 0.81, 0.414, 0.382, 0.713, 0.609, 0.697], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 115, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.361}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 43, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.59}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 104, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.366}}, "results": {"en_basic": {"BBH": 0.063, "En Avg": 0.361, "GSM8K": 0.027, "HellaSwag": 0.511, "HumanEval": 0.158, "MATH": 0.174, "MMLU": 0.526, "OpenBookQA": 0.342, "SQuAD2": 0.522, "TriviaQA": 0.416, "XWINO": 0.871}, "ja_basic": {"JComQA": 0.855, "JEMHopQA": 0.228, "JHumanEval": 0.165, "JMMLU": 0.415, "JSQuAD": 0.877, "Ja Avg": 0.366, "MGSM": 0.172, "NIILC": 0.39, "WMT20-en-ja": 0.255, "WMT20-ja-en": 0.19, "XL-Sum": 0.115}, "ja_mtb": {"JMT Avg": 0.59, "coding": 0.47, "extraction": 0.625, "humanities": 0.81, "math": 0.414, "reasoning": 0.382, "roleplay": 0.713, "stem": 0.609, "writing": 0.697}, "other": {"GPQA": 0.051}}, "sortkey": "gemma 2 baku", "uri": "rinna_gemma-2-baku-2b-it", "url": "https://huggingface.co/rinna/gemma-2-baku-2b-it"}, "tiiuae/Falcon3-1B-Instruct": {"base_model": "Falcon3-1B-Base", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-12-19", "id": "tiiuae/Falcon3-1B-Instruct", "name": "Falcon3-1B-Instruct", "params": 1.7, "radar": {"en_basic": {"id": "en_basic", "series": [0.344, 0.261, 0.48, 0.501, 0.815, 0.459, 0.391, 0.13, 0.33, 0.101], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.24, 0.312, 0.132, 0.454, 0.101, 0.02, 0.028, 0.032, 0.281, 0.089], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.176, 0.178, 0.121, 0.161, 0.224, 0.154, 0.124, 0.148], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 110, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.381}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 72, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.161}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 129, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.169}}, "results": {"en_basic": {"BBH": 0.33, "En Avg": 0.381, "GSM8K": 0.391, "HellaSwag": 0.48, "HumanEval": 0.101, "MATH": 0.13, "MMLU": 0.459, "OpenBookQA": 0.344, "SQuAD2": 0.501, "TriviaQA": 0.261, "XWINO": 0.815}, "ja_basic": {"JComQA": 0.24, "JEMHopQA": 0.312, "JHumanEval": 0.089, "JMMLU": 0.281, "JSQuAD": 0.454, "Ja Avg": 0.169, "MGSM": 0.02, "NIILC": 0.132, "WMT20-en-ja": 0.028, "WMT20-ja-en": 0.032, "XL-Sum": 0.101}, "ja_mtb": {"JMT Avg": 0.161, "coding": 0.176, "extraction": 0.178, "humanities": 0.121, "math": 0.161, "reasoning": 0.224, "roleplay": 0.154, "stem": 0.124, "writing": 0.148}, "other": {"GPQA": 0.013}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-1B-Instruct", "url": "https://huggingface.co/tiiuae/Falcon3-1B-Instruct"}, "tiiuae/Falcon3-3B-Instruct": {"base_model": "Falcon3-3B-Base", "category": ["index-chat", "category-under-5b-chat"], "date": "2024-12-19", "id": "tiiuae/Falcon3-3B-Instruct", "name": "Falcon3-3B-Instruct", "params": 3.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.372, 0.286, 0.541, 0.513, 0.818, 0.562, 0.712, 0.44, 0.562, 0.454], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.421, 0.16, 0.113, 0.632, 0.141, 0.092, 0.062, 0.058, 0.331, 0.308], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.329, 0.392, 0.219, 0.199, 0.267, 0.234, 0.229, 0.208], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 77, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.526}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 71, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.26}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 125, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.232}}, "results": {"en_basic": {"BBH": 0.562, "En Avg": 0.526, "GSM8K": 0.712, "HellaSwag": 0.541, "HumanEval": 0.454, "MATH": 0.44, "MMLU": 0.562, "OpenBookQA": 0.372, "SQuAD2": 0.513, "TriviaQA": 0.286, "XWINO": 0.818}, "ja_basic": {"JComQA": 0.421, "JEMHopQA": 0.16, "JHumanEval": 0.308, "JMMLU": 0.331, "JSQuAD": 0.632, "Ja Avg": 0.232, "MGSM": 0.092, "NIILC": 0.113, "WMT20-en-ja": 0.062, "WMT20-ja-en": 0.058, "XL-Sum": 0.141}, "ja_mtb": {"JMT Avg": 0.26, "coding": 0.329, "extraction": 0.392, "humanities": 0.219, "math": 0.199, "reasoning": 0.267, "roleplay": 0.234, "stem": 0.229, "writing": 0.208}, "other": {"GPQA": 0.208}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-3B-Instruct", "url": "https://huggingface.co/tiiuae/Falcon3-3B-Instruct"}, "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1": {"base_model": "Gemma2-Llama Swallow 2B", "category": ["index-chat", "category-under-5b-chat"], "date": "", "id": "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "name": "Gemma-2-Llama Swallow 2B IT", "params": 2.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.332, 0.417, 0.529, 0.506, 0.856, 0.53, 0.284, 0.15, 0.405, 0.301], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.862, 0.367, 0.483, 0.881, 0.145, 0.288, 0.258, 0.2, 0.485, 0.267], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"id": "ja_mtb", "series": [0.438, 0.533, 0.781, 0.557, 0.404, 0.706, 0.674, 0.682], "tasks": ["Code", "Ext", "Human", "Math", "Reason", "Role", "STEM", "Write"], "title": "Japanese MT-Bench"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "google/gemma-3-1b-pt", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "elyza/Llama-3-ELYZA-JP-8B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-4b-pt", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "google/gemma-3-4b-it", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "CohereForAI/aya-expanse-32b", "tiiuae/Falcon3-7B-Instruct", "google/gemma-3-12b-pt", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "Qwen/Qwen2-72B-Instruct", "Qwen/Qwen2.5-32B", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "google/gemma-3-27b-pt", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "google/gemma-3-12b-it", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "meta-llama/Meta-Llama-3.1-70B-Instruct", "google/gemma-3-27b-it", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "Gemma 3 1B", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "Gemma 3 1B IT", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Llama-3-ELYZA-JP-8B", "Falcon3-3B-Base", "Gemma 3 4B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Gemma 3 4B IT", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Gemma2-Llama Swallow 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma-2-Llama Swallow 9B IT", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Aya Expanse 32B", "Falcon3-7B-Instruct", "Gemma 3 12B", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2.5-14B", "Gemma2-Llama Swallow 27B", "Qwen2-72B-Instruct", "Qwen2.5-32B", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Gemma 3 27B", "Llama 3.1 Swallow 70B v0.1", "Gemma-2-Llama Swallow 27B IT", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Gemma 3 12B IT", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Gemma 3 27B IT", "Llama 3.3 70B Instruct"], "rank": 97, "series": [0.274, 0.293, 0.302, 0.31, 0.313, 0.324, 0.336, 0.339, 0.347, 0.361, 0.363, 0.365, 0.376, 0.376, 0.381, 0.383, 0.392, 0.399, 0.4, 0.406, 0.408, 0.411, 0.412, 0.413, 0.418, 0.424, 0.426, 0.431, 0.432, 0.436, 0.439, 0.45, 0.461, 0.464, 0.471, 0.472, 0.474, 0.486, 0.489, 0.49, 0.491, 0.495, 0.495, 0.501, 0.507, 0.507, 0.523, 0.526, 0.527, 0.534, 0.537, 0.538, 0.539, 0.539, 0.54, 0.541, 0.542, 0.543, 0.545, 0.551, 0.556, 0.559, 0.56, 0.563, 0.566, 0.566, 0.572, 0.574, 0.582, 0.588, 0.589, 0.592, 0.595, 0.596, 0.597, 0.602, 0.604, 0.605, 0.608, 0.611, 0.614, 0.614, 0.614, 0.618, 0.619, 0.627, 0.63, 0.633, 0.634, 0.639, 0.649, 0.65, 0.652, 0.655, 0.66, 0.665, 0.669, 0.67, 0.671, 0.671, 0.672, 0.677, 0.677, 0.679, 0.687, 0.689, 0.691, 0.702, 0.703, 0.708, 0.709, 0.71, 0.71, 0.711, 0.715, 0.716, 0.717, 0.72, 0.725, 0.729, 0.736, 0.738, 0.758, 0.762], "task": "En Avg", "taskcat": "en_basic", "value": 0.431}, "JMT Avg": {"ids": ["tiiuae/Falcon3-1B-Instruct", "tiiuae/Falcon3-3B-Instruct", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "tiiuae/Falcon3-7B-Instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "meta-llama/Llama-3.2-3B-Instruct", "tiiuae/Falcon3-10B-Instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "mistralai/Mistral-7B-Instruct-v0.3", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b-instruct", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "google/gemma-3-1b-it", "meta-llama/Meta-Llama-3.1-8B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Meta-Llama-3-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "SakanaAI/TinySwallow-1.5B-Instruct", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "google/gemma-2-2b-it", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "llm-jp/llm-jp-3-13b-instruct", "rinna/gemma-2-baku-2b-it", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "CohereForAI/aya-expanse-8b", "meta-llama/Meta-Llama-3-70B-Instruct", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-7B-Instruct", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "gpt-3.5-turbo-0125", "cyberagent/calm3-22b-chat", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "meta-llama/Meta-Llama-3.1-70B-Instruct", "CohereForAI/aya-expanse-32b", "google/gemma-3-4b-it", "google/gemma-2-9b-it", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "rinna/llama-3-youko-70b-instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-2-27b-it", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "gpt-4-0613", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "o1-2024-12-17", "Qwen/Qwen2.5-32B-Instruct", "google/gemma-3-12b-it", "gpt-4o-mini-2024-07-18", "Qwen/Qwen2.5-72B-Instruct", "gpt-4-turbo-2024-04-09", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13", "google/gemma-3-27b-it", "gpt-4.5-preview-2025-02-27"], "labels": ["Falcon3-1B-Instruct", "Falcon3-3B-Instruct", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "Falcon3-7B-Instruct", "Swallow-MS-7b-instruct-v0.1", "Llama 3.2 3B Instruct", "Falcon3-10B-Instruct", "Swallow-7b-instruct-v0.1", "Llama 3 Swallow 8B Instruct", "Mistral-7B-Instruct-v0.3", "Qwen2.5-1.5B-Instruct", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b-instruct", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Gemma 3 1B IT", "Llama 3.1 8B Instruct", "Phi-3-Mini-128K-Instruct", "Tanuki-8B-dpo-v1.0", "Llama 3 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "TinySwallow-1.5B-Instruct", "Mistral-NeMo-Minitron 8B Instruct", "Gemma 2 2B IT", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama-3-ELYZA-JP-8B", "llm-jp-3-13b-instruct", "Gemma 2 Baku 2B IT", "Qwen2.5-3B-Instruct", "Gemma-2-Llama Swallow 2B IT", "Llama 3.1 Swallow 8B Instruct v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Aya Expanse 8B", "Llama 3 70B Instruct", "Qwen2-7B-Instruct", "Qwen2.5-7B-Instruct", "Llama 3 heron brain 70B v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "GPT-3.5 (gpt-3.5-turbo-0125)", "CyberAgentLM3-22B-chat", "Llama 3.1 Swallow 8B Instruct v0.3", "Llama 3.1 70B Instruct", "Aya Expanse 32B", "Gemma 3 4B IT", "Gemma 2 9B IT", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 9B IT", "Llama 3 Youko 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Gemma-2-Llama Swallow 27B IT", "Qwen2.5-14B-Instruct", "Gemma 2 27B IT", "Phi-4", "Llama 3.1 Swallow 70B Instruct v0.3", "GPT-4 (gpt-4-0613)", "Llama 3.3 Swallow 70B Instruct v0.4", "o1 (o1-2024-12-17)", "Qwen2.5-32B-Instruct", "Gemma 3 12B IT", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Qwen2.5-72B-Instruct", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)", "Gemma 3 27B IT", "GPT-4.5 (gpt-4.5-preview-2025-02-27)"], "rank": 41, "series": [0.161, 0.26, 0.273, 0.294, 0.377, 0.4, 0.405, 0.413, 0.419, 0.427, 0.428, 0.45, 0.451, 0.485, 0.497, 0.509, 0.51, 0.519, 0.524, 0.529, 0.529, 0.546, 0.55, 0.565, 0.567, 0.569, 0.581, 0.587, 0.588, 0.59, 0.593, 0.597, 0.612, 0.616, 0.616, 0.618, 0.622, 0.637, 0.64, 0.646, 0.665, 0.683, 0.691, 0.691, 0.691, 0.705, 0.706, 0.713, 0.724, 0.736, 0.737, 0.749, 0.75, 0.751, 0.756, 0.759, 0.762, 0.768, 0.769, 0.769, 0.771, 0.772, 0.807, 0.809, 0.821, 0.824, 0.835, 0.837, 0.848, 0.848, 0.855, 0.884], "task": "JMT Avg", "taskcat": "ja_mtb", "value": 0.597}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "google/gemma-3-1b-pt", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "google/gemma-3-1b-it", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "google/gemma-3-4b-it", "google/gemma-3-4b-pt", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-pt-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "sbintuitions/sarashina2-13b", "CohereForAI/aya-expanse-8b", "nvidia/Mistral-NeMo-Minitron-8B-Instruct", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "01-ai/Yi-1.5-34B", "rinna/llama-3-youko-8b-instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "pfnet/plamo-2-8b", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "mistralai/Mistral-Nemo-Instruct-2407", "google/gemma-2-9b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "Qwen/Qwen2.5-7B", "CohereForAI/aya-expanse-32b", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "google/gemma-3-12b-pt", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-it-v0.1", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "google/gemma-3-12b-it", "tokyotech-llm/Gemma-2-Llama-Swallow-9b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "Qwen/Qwen2.5-14B", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "google/gemma-3-27b-pt", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-32B", "google/gemma-3-27b-it", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-pt-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "Qwen/Qwen2-72B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Gemma-2-Llama-Swallow-27b-it-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "gpt-4-0613", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Gemma 3 1B", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "Gemma 3 1B IT", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Gemma 3 4B IT", "Gemma 3 4B", "Gemma2-Llama Swallow 2B", "Gemma-2-Llama Swallow 2B IT", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Sarashina2-13B", "Aya Expanse 8B", "Mistral-NeMo-Minitron 8B Instruct", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Yi-1.5 34B", "Llama 3 Youko 8B Instruct", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "PLaMo 2 8B", "Llama 3 Swallow 8B Instruct", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Mistral-NeMo-Instruct-2407 (12B)", "Gemma 2 9B", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Qwen2.5-7B", "Aya Expanse 32B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Gemma 3 12B", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma-2-Llama Swallow 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Gemma 3 12B IT", "Gemma2-Llama Swallow 9B", "Llama 3.1 70B", "Gemma 2 27B IT", "Qwen2.5-14B", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Gemma 3 27B", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2.5-32B", "Gemma 3 27B IT", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Gemma2-Llama Swallow 27B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Qwen2-72B-Instruct", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.3 70B Instruct", "Gemma-2-Llama Swallow 27B IT", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "GPT-4 (gpt-4-0613)", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 84, "series": [0.129, 0.169, 0.201, 0.209, 0.223, 0.232, 0.234, 0.238, 0.239, 0.243, 0.25, 0.251, 0.281, 0.285, 0.293, 0.311, 0.337, 0.337, 0.346, 0.348, 0.35, 0.353, 0.354, 0.355, 0.361, 0.364, 0.366, 0.367, 0.372, 0.372, 0.377, 0.378, 0.38, 0.382, 0.383, 0.392, 0.393, 0.394, 0.395, 0.398, 0.402, 0.409, 0.415, 0.416, 0.417, 0.421, 0.424, 0.429, 0.43, 0.432, 0.436, 0.437, 0.439, 0.442, 0.442, 0.444, 0.445, 0.445, 0.446, 0.454, 0.46, 0.468, 0.468, 0.47, 0.471, 0.471, 0.471, 0.472, 0.478, 0.481, 0.481, 0.488, 0.49, 0.492, 0.496, 0.498, 0.499, 0.5, 0.5, 0.505, 0.506, 0.51, 0.512, 0.512, 0.514, 0.515, 0.518, 0.519, 0.53, 0.532, 0.535, 0.546, 0.546, 0.553, 0.553, 0.558, 0.566, 0.567, 0.568, 0.569, 0.571, 0.571, 0.571, 0.574, 0.574, 0.578, 0.58, 0.58, 0.582, 0.588, 0.591, 0.591, 0.593, 0.593, 0.594, 0.594, 0.595, 0.597, 0.598, 0.598, 0.601, 0.602, 0.613, 0.615, 0.621, 0.623, 0.626, 0.629, 0.646, 0.649], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.424}}, "results": {"en_basic": {"BBH": 0.405, "En Avg": 0.431, "GSM8K": 0.284, "HellaSwag": 0.529, "HumanEval": 0.301, "MATH": 0.15, "MMLU": 0.53, "OpenBookQA": 0.332, "SQuAD2": 0.506, "TriviaQA": 0.417, "XWINO": 0.856}, "ja_basic": {"JComQA": 0.862, "JEMHopQA": 0.367, "JHumanEval": 0.267, "JMMLU": 0.485, "JSQuAD": 0.881, "Ja Avg": 0.424, "MGSM": 0.288, "NIILC": 0.483, "WMT20-en-ja": 0.258, "WMT20-ja-en": 0.2, "XL-Sum": 0.145}, "ja_mtb": {"JMT Avg": 0.597, "coding": 0.438, "extraction": 0.533, "humanities": 0.781, "math": 0.557, "reasoning": 0.404, "roleplay": 0.706, "stem": 0.674, "writing": 0.682}, "other": {"GPQA": 0.141}}, "sortkey": "gemma 2 llama swallow", "uri": "tokyotech-llm_Gemma-2-Llama-Swallow-2b-it-v0.1", "url": "https://huggingface.co/tokyotech-llm/Gemma-2-Llama-Swallow-2b-it-v0.1"}};
const g_taskcats = {"en_basic": {"category": "En", "description": "We evaluate LLMs on question answering, reading comprehension, and exam questions to assess language understanding and common knowledge, summarization to measure language generation, and code generation and mathematics to test logical reasoning abilities. The evaluation scores range from 0 (lowest) to 1 (highest).", "for": ["base", "inst"], "tasks": {"BBH": {"description": "23 tasks that are difficult in BIG-Bench dataset (Srivastava et al., 2023)", "link": {"author": "Suzgun et al.", "href": "https://aclanthology.org/2023.findings-acl.824/", "year": "2023"}, "metric": "Accuracy (exact match)", "name": "BBH", "setting": "3-shot, CoT", "short": "BBH", "subtitle": "Collection of hard-to-solve tasks for LLM", "title": "BIG-Bench-Hard (BBH)"}, "En Avg": {"collective": true, "description": "Average score of English understanding and generation", "metric": "Average", "name": "En Avg", "setting": "Excluding MBPP and GPQA", "short": "En avg", "subtitle": "English Understanding and Generation (avg)", "title": "English average"}, "GSM8K": {"description": "Math word problems", "link": {"author": "Cobbe et al.", "href": "https://arxiv.org/abs/2110.14168", "year": "2021"}, "metric": "Accuracy (exact match)", "name": "GSM8K", "setting": "4-shot", "short": "GSM8K", "subtitle": "Mathematics", "title": "GSM8K"}, "HellaSwag": {"description": "Four-choice questions to predict the next event", "link": {"author": "Zellers et al.", "href": "https://aclanthology.org/P19-1472/", "year": "2019"}, "metric": "Accuracy", "name": "HellaSwag", "setting": "4-shot", "short": "HellaSwag", "subtitle": "Commonsense inference", "title": "HellaSwag"}, "HumanEval": {"description": "Ability of code generation measured by unit test", "link": {"author": "Chen et al.", "href": "https://arxiv.org/abs/2107.03374", "year": "2021"}, "metric": "pass@1", "name": "HumanEval", "setting": "0-shot, 10 trials", "short": "HumanEval", "subtitle": "Code generation", "title": "HumanEval"}, "MATH": {"description": "High school math competitions", "link": {"author": "Hendrycks et al.", "href": "https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html", "year": "2021"}, "metric": "Accuracy (exact match)", "name": "MATH", "setting": "4-shot", "short": "MATH", "subtitle": "Mathematics", "title": "MATH"}, "MMLU": {"description": "Four-choice exam questions benchmark MMLU (53 subjects)", "link": {"author": "Hendrycks et al.", "href": "https://openreview.net/forum?id=d7KBjmI3GmQ", "year": "2021"}, "metric": "Accuracy", "name": "MMLU", "setting": "5-shot", "short": "MMLU", "subtitle": "Multitask natural language understanding", "title": "MMLU"}, "OpenBookQA": {"description": "Four-choice questions based on scientific knowledge and common sense", "link": {"author": "Mihaylov et al.", "href": "https://aclanthology.org/D18-1260/", "year": "2018"}, "metric": "Accuracy", "name": "OpenBookQA", "setting": "4-shot", "short": "OpenBookQA", "subtitle": "Q\u0026A based on facts and common sense", "title": "OpenBookQA"}, "SQuAD2": {"description": "Open-ended Q\u0026A developed for the evidence document", "link": {"author": "Rajpurkar et al.", "href": "https://aclanthology.org/P18-2124/", "year": "2018"}, "metric": "Accuracy (exact match)", "name": "SQuAD2", "setting": "4-shot", "short": "SQuAD2", "subtitle": "Reading comprehension", "title": "SQuAD2"}, "TriviaQA": {"description": "Open-ended Q\u0026A based on trivias", "link": {"author": "Joshi et al.", "href": "https://aclanthology.org/P17-1147/", "year": "2017"}, "metric": "Accuracy (exact match)", "name": "TriviaQA", "setting": "4-shot", "short": "TriviaQA", "subtitle": "Q\u0026A based on knowledge", "title": "TriviaQA"}, "XWINO": {"description": "Two-choice question to predict the antecedent of a pronoun", "link": {"author": "Tikhonov and Ryabinin", "href": "https://aclanthology.org/2021.findings-acl.310/", "year": "2021"}, "metric": "Accuracy", "name": "XWINO", "setting": "4-shot", "short": "XWINO", "subtitle": "Commonsense inference", "title": "XWINO"}}, "title": "English understanding \u0026 generation"}, "ja_basic": {"category": "Ja", "description": "We evaluate LLMs on question answering and reading comprehension to assess language understanding and common knowledge, summarization and translation to measure language generation, and code generation and mathematics to test logical reasoning abilities. The evaluation scores range from 0 (lowest) to 1 (highest).", "for": ["base", "inst"], "tasks": {"JComQA": {"description": "Five-choice questions created with a knowledge base", "link": {"author": "Kurihara et al.", "href": "https://aclanthology.org/2022.lrec-1.317/", "year": "2022"}, "metric": "Accuracy", "name": "JComQA", "setting": "4-shot", "short": "JComQA", "subtitle": "Q\u0026A regarding commonsense and inference", "title": "JCommonsenseQA (JComQA)"}, "JEMHopQA": {"description": "Open-ended Q\u0026A to assess the amount of knowledge and reasoning ability", "link": {"author": "Ishii et al.", "href": "https://aclanthology.org/2024.lrec-main.831/", "year": "2024"}, "metric": "Character F1", "name": "JEMHopQA", "setting": "4-shot", "short": "JEMHQA", "subtitle": "Multi-hop Q\u0026A", "title": "JEMHopQA"}, "JHumanEval": {"description": "Japanese translation of HumanEval (code genration benchmark)", "link": {"author": "Sato et al.", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/P10-9.pdf", "year": "2024"}, "metric": "pass@1", "name": "JHumanEval", "setting": "0-shot, 10 trials", "short": "JHumanEval", "subtitle": "Code generation", "title": "JHumanEval"}, "JMMLU": {"description": "Japanese translation of four-choice exam questions benchmark MMLU (53 subjects)", "link": {"author": "Yin et al", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A7-5.pdf", "year": "2024"}, "metric": "Accuracy", "name": "JMMLU", "setting": "5-shot", "short": "JMMLU", "subtitle": "Multi-task natural language understanding", "title": "JMMLU"}, "JSQuAD": {"description": "Open-ended Q\u0026A for Wikipedia article", "link": {"author": "Kurihara et al.", "href": "https://aclanthology.org/2022.lrec-1.317/", "year": "2022"}, "metric": "Character F1", "name": "JSQuAD", "setting": "4-shot", "short": "JSQuAD", "subtitle": "Reading comprehension", "title": "JSQuAD"}, "Ja Avg": {"collective": true, "description": "Average score of Japanese understanding and generation", "metric": "Average", "name": "Ja Avg", "setting": "Excluding MBPP-Ja", "short": "Ja avg", "subtitle": "Japanese Understanding and Generation (avg)", "title": "Japanese average"}, "MGSM": {"description": "Japanese translation of math word problems (GSM8K)", "link": {"author": "Shi et al.", "href": "https://openreview.net/forum?id=fR3wGCk-IXp", "year": "2023"}, "metric": "Accuracy (exact match)", "name": "MGSM", "setting": "4-shot", "short": "MGSM", "subtitle": "Mathematics", "title": "MGSM"}, "NIILC": {"description": "Open-ended Q\u0026A that can be answered by an encyclopedia", "link": {"author": "Sekine", "href": "https://www.anlp.jp/proceedings/annual_meeting/2003/pdf_dir/C7-6.pdf", "year": "2003"}, "metric": "Character F1", "name": "NIILC", "setting": "4-shot", "short": "NIILC", "subtitle": "Classical Q\u0026A", "title": "NIILC"}, "WMT20-en-ja": {"description": "Translation of news articles (English to Japanese)", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20-en-ja", "setting": "4-shot", "short": "En-Ja", "subtitle": "English-Japanese translation", "title": "WMT20 (en-ja)"}, "WMT20-ja-en": {"description": "Translation of news articles (Japanese to English)", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20-ja-en", "setting": "4-shot", "short": "Ja-En", "subtitle": "Japanese-English translation", "title": "WMT20 (ja-en)"}, "XL-Sum": {"description": "Task to generate a highlight from a news article of BBC", "link": {"author": "Hasan et al.", "href": "https://aclanthology.org/2021.findings-acl.413/", "year": "2021"}, "metric": "ROUGE-2", "name": "XL-Sum", "setting": "1-shot", "short": "XL-Sum", "subtitle": "Summarization", "title": "XL-Sum"}}, "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"category": "Ja-MTB", "description": "We used the Japanese version of MT-Bench (Nejumi LLM Leaderboard edition) to evaluate dialogue capabilities. The test questions are based on v4, and the reference answers are derived from v2 with corrections to incorrect responses. The evaluation scores range from 0 (lowest) to 1 (highest).", "for": ["inst"], "tasks": {"JMT Avg": {"collective": true, "name": "JMT Avg", "short": "JMT avg", "subtitle": "Japanese MT-Bench (avg)", "title": "Japanese MT-Bench average"}, "coding": {"description": "Implementing algorithms in Python or C++, and creating websites using HTML.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "coding", "short": "Code", "subtitle": "", "title": "Coding"}, "extraction": {"description": "Extracting named entities (such as author names and numerical values) and sentiment (e.g., positive or negative) from text.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "extraction", "short": "Ext", "subtitle": "", "title": "Extraction"}, "humanities": {"description": "Creating essays and strategies on topics related to law, economics, history, philosophy, and education.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "humanities", "short": "Human", "subtitle": "", "title": "Humanities"}, "math": {"description": "Generating solutions for problems and word problems in algebra, geometry, probability, and number theory.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "math", "short": "Math", "subtitle": "", "title": "Math"}, "reasoning": {"description": "Generating answers to questions by leveraging common knowledge and reasoning skills.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "reasoning", "short": "Reason", "subtitle": "", "title": "Reasoning"}, "roleplay": {"description": "Writing creative texts by assuming the persona of famous individuals or fictional characters and imagining hypothetical scenarios.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "roleplay", "short": "Role", "subtitle": "", "title": "Roleplay"}, "stem": {"description": "Generating answers and explanations on topics related to physics, chemistry, biology, geography, architecture, and machine learning.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "stem", "short": "STEM", "subtitle": "", "title": "STEM"}, "writing": {"description": "Writing blog articles, email drafts, and fictional narratives.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "writing", "short": "Write", "subtitle": "", "title": "Writing"}}, "title": "Japanese MT-Bench"}, "other": {"category": "Other", "for": ["base", "inst"], "tasks": {"GPQA": {"name": "GPQA", "short": "GPQA", "subtitle": "GPQA", "title": "GPQA"}}, "title": "Other tasks"}};

function query_models(type = "all", minp = null, maxp = null, includes = null, excludes = null)
{
  let models = [];
  for (let key in g_models) {
    const model = g_models[key];

    if (type == "base" && model['base_model'] != "") {
      continue;
    } else if (type == "chat" && model['base_model'] == "") {
      continue;
    }

    if (includes !== null && includes.includes(model['id'])) {
      models.push(model);
      continue;
    }

    if (minp !== null && model['params'] < minp) {
      continue;
    }
    if (maxp !== null && maxp < model['params']) {
      continue;
    }
    if (excludes !== null && excludes.includes(model['id'])) {
      continue;
    }
    models.push(model);
  }

  return models;
}
