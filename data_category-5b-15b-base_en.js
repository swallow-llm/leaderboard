var g_models = {"01-ai/Yi-1.5-6B": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-05-13", "id": "01-ai/Yi-1.5-6B", "name": "Yi-1.5 6B", "params": 6.1, "radar": {"en_basic": {"id": "en_basic", "series": [0.344, 0.593, 0.575, 0.651, 0.898, 0.636, 0.522, 0.244, 0.583, 0.352], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.658, 0.38, 0.226, 0.829, 0.198, 0.24, 0.13, 0.147, 0.423, 0.313], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 58, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.54}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 92, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.354}}, "results": {"en_basic": {"BBH": 0.583, "En Avg": 0.54, "GSM8K": 0.522, "HellaSwag": 0.575, "HumanEval": 0.352, "MATH": 0.244, "MMLU": 0.636, "OpenBookQA": 0.344, "SQuAD2": 0.651, "TriviaQA": 0.593, "XWINO": 0.898}, "ja_basic": {"JComQA": 0.658, "JEMHopQA": 0.38, "JHumanEval": 0.313, "JMMLU": 0.423, "JSQuAD": 0.829, "Ja Avg": 0.354, "MGSM": 0.24, "NIILC": 0.226, "WMT20-en-ja": 0.13, "WMT20-ja-en": 0.147, "XL-Sum": 0.198}, "other": {"GPQA": 0.266}}, "sortkey": "yi 1.5", "uri": "01-ai_Yi-1.5-6B", "url": "https://huggingface.co/01-ai/Yi-1.5-6B"}, "01-ai/Yi-1.5-9B": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-05-13", "id": "01-ai/Yi-1.5-9B", "name": "Yi-1.5 9B", "params": 8.8, "radar": {"en_basic": {"id": "en_basic", "series": [0.39, 0.619, 0.601, 0.693, 0.902, 0.696, 0.62, 0.3, 0.71, 0.384], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.834, 0.417, 0.265, 0.894, 0.224, 0.42, 0.174, 0.187, 0.516, 0.391], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 42, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.592}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 69, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.432}}, "results": {"en_basic": {"BBH": 0.71, "En Avg": 0.592, "GSM8K": 0.62, "HellaSwag": 0.601, "HumanEval": 0.384, "MATH": 0.3, "MMLU": 0.696, "OpenBookQA": 0.39, "SQuAD2": 0.693, "TriviaQA": 0.619, "XWINO": 0.902}, "ja_basic": {"JComQA": 0.834, "JEMHopQA": 0.417, "JHumanEval": 0.391, "JMMLU": 0.516, "JSQuAD": 0.894, "Ja Avg": 0.432, "MGSM": 0.42, "NIILC": 0.265, "WMT20-en-ja": 0.174, "WMT20-ja-en": 0.187, "XL-Sum": 0.224}, "other": {"GPQA": 0.275}}, "sortkey": "yi 1.5", "uri": "01-ai_Yi-1.5-9B", "url": "https://huggingface.co/01-ai/Yi-1.5-9B"}, "Qwen/Qwen2-7B": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-06-07", "id": "Qwen/Qwen2-7B", "name": "Qwen2-7B", "params": 7.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.374, 0.61, 0.602, 0.574, 0.891, 0.705, 0.781, 0.492, 0.53, 0.46], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.875, 0.463, 0.372, 0.899, 0.172, 0.524, 0.209, 0.195, 0.587, 0.422], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 39, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.602}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 52, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.472}}, "results": {"en_basic": {"BBH": 0.53, "En Avg": 0.602, "GSM8K": 0.781, "HellaSwag": 0.602, "HumanEval": 0.46, "MATH": 0.492, "MMLU": 0.705, "OpenBookQA": 0.374, "SQuAD2": 0.574, "TriviaQA": 0.61, "XWINO": 0.891}, "ja_basic": {"JComQA": 0.875, "JEMHopQA": 0.463, "JHumanEval": 0.422, "JMMLU": 0.587, "JSQuAD": 0.899, "Ja Avg": 0.472, "MGSM": 0.524, "NIILC": 0.372, "WMT20-en-ja": 0.209, "WMT20-ja-en": 0.195, "XL-Sum": 0.172}, "other": {"GPQA": 0.246}}, "sortkey": "qwen2", "uri": "Qwen_Qwen2-7B", "url": "https://huggingface.co/Qwen/Qwen2-7B"}, "Qwen/Qwen2.5-7B": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-09-19", "id": "Qwen/Qwen2.5-7B", "name": "Qwen2.5-7B", "params": 7.6, "radar": {"en_basic": {"id": "en_basic", "series": [0.392, 0.601, 0.6, 0.618, 0.888, 0.742, 0.832, 0.51, 0.562, 0.554], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.924, 0.459, 0.426, 0.907, 0.216, 0.616, 0.229, 0.199, 0.634, 0.507], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 30, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.63}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 36, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.512}}, "results": {"en_basic": {"BBH": 0.562, "En Avg": 0.63, "GSM8K": 0.832, "HellaSwag": 0.6, "HumanEval": 0.554, "MATH": 0.51, "MMLU": 0.742, "OpenBookQA": 0.392, "SQuAD2": 0.618, "TriviaQA": 0.601, "XWINO": 0.888}, "ja_basic": {"JComQA": 0.924, "JEMHopQA": 0.459, "JHumanEval": 0.507, "JMMLU": 0.634, "JSQuAD": 0.907, "Ja Avg": 0.512, "MGSM": 0.616, "NIILC": 0.426, "WMT20-en-ja": 0.229, "WMT20-ja-en": 0.199, "XL-Sum": 0.216}, "other": {"GPQA": 0.295}}, "sortkey": "qwen2.5", "uri": "Qwen_Qwen2.5-7B", "url": "https://huggingface.co/Qwen/Qwen2.5-7B"}, "google/gemma-2-9b": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-06-27", "id": "google/gemma-2-9b", "name": "Gemma 2 9B", "params": 9.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.382, 0.718, 0.626, 0.506, 0.907, 0.706, 0.688, 0.338, 0.704, 0.39], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.904, 0.573, 0.524, 0.898, 0.168, 0.456, 0.269, 0.236, 0.623, 0.345], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 40, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.597}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 42, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.5}}, "results": {"en_basic": {"BBH": 0.704, "En Avg": 0.597, "GSM8K": 0.688, "HellaSwag": 0.626, "HumanEval": 0.39, "MATH": 0.338, "MMLU": 0.706, "OpenBookQA": 0.382, "SQuAD2": 0.506, "TriviaQA": 0.718, "XWINO": 0.907}, "ja_basic": {"JComQA": 0.904, "JEMHopQA": 0.573, "JHumanEval": 0.345, "JMMLU": 0.623, "JSQuAD": 0.898, "Ja Avg": 0.5, "MGSM": 0.456, "NIILC": 0.524, "WMT20-en-ja": 0.269, "WMT20-ja-en": 0.236, "XL-Sum": 0.168}, "other": {"GPQA": 0.221}}, "sortkey": "gemma 2", "uri": "google_gemma-2-9b", "url": "https://huggingface.co/google/gemma-2-9b"}, "llm-jp/llm-jp-3-13b": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-09-25", "id": "llm-jp/llm-jp-3-13b", "name": "llm-jp-3-13b", "params": 13, "radar": {"en_basic": {"id": "en_basic", "series": [0.332, 0.602, 0.57, 0.501, 0.902, 0.462, 0.158, 0.026, 0.402, 0.032], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.65, 0.525, 0.649, 0.882, 0.164, 0.16, 0.273, 0.21, 0.399, 0.023], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 92, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.399}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 78, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.393}}, "results": {"en_basic": {"BBH": 0.402, "En Avg": 0.399, "GSM8K": 0.158, "HellaSwag": 0.57, "HumanEval": 0.032, "MATH": 0.026, "MMLU": 0.462, "OpenBookQA": 0.332, "SQuAD2": 0.501, "TriviaQA": 0.602, "XWINO": 0.902}, "ja_basic": {"JComQA": 0.65, "JEMHopQA": 0.525, "JHumanEval": 0.023, "JMMLU": 0.399, "JSQuAD": 0.882, "Ja Avg": 0.393, "MGSM": 0.16, "NIILC": 0.649, "WMT20-en-ja": 0.273, "WMT20-ja-en": 0.21, "XL-Sum": 0.164}, "other": {"GPQA": 0.094}}, "sortkey": "llm jp 3", "uri": "llm-jp_llm-jp-3-13b", "url": "https://huggingface.co/llm-jp/llm-jp-3-13b"}, "meta-llama/Meta-Llama-3-8B": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-04-18", "id": "meta-llama/Meta-Llama-3-8B", "name": "Llama 3 8B", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.38, 0.712, 0.612, 0.502, 0.905, 0.651, 0.487, 0.18, 0.62, 0.376], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.835, 0.436, 0.41, 0.892, 0.177, 0.312, 0.221, 0.206, 0.455, 0.344], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 56, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.542}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 71, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.429}}, "results": {"en_basic": {"BBH": 0.62, "En Avg": 0.542, "GSM8K": 0.487, "HellaSwag": 0.612, "HumanEval": 0.376, "MATH": 0.18, "MMLU": 0.651, "OpenBookQA": 0.38, "SQuAD2": 0.502, "TriviaQA": 0.712, "XWINO": 0.905}, "ja_basic": {"JComQA": 0.835, "JEMHopQA": 0.436, "JHumanEval": 0.344, "JMMLU": 0.455, "JSQuAD": 0.892, "Ja Avg": 0.429, "MGSM": 0.312, "NIILC": 0.41, "WMT20-en-ja": 0.221, "WMT20-ja-en": 0.206, "XL-Sum": 0.177}, "other": {"GPQA": 0.136}}, "sortkey": "llama 3", "uri": "meta-llama_Meta-Llama-3-8B", "url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B"}, "meta-llama/Meta-Llama-3.1-8B": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-07-23", "id": "meta-llama/Meta-Llama-3.1-8B", "name": "Llama 3.1 8B", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.38, 0.702, 0.609, 0.503, 0.907, 0.651, 0.507, 0.214, 0.616, 0.364], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.845, 0.461, 0.405, 0.895, 0.179, 0.356, 0.221, 0.21, 0.479, 0.32], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 54, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.545}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 67, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.437}}, "results": {"en_basic": {"BBH": 0.616, "En Avg": 0.545, "GSM8K": 0.507, "HellaSwag": 0.609, "HumanEval": 0.364, "MATH": 0.214, "MMLU": 0.651, "OpenBookQA": 0.38, "SQuAD2": 0.503, "TriviaQA": 0.702, "XWINO": 0.907}, "ja_basic": {"JComQA": 0.845, "JEMHopQA": 0.461, "JHumanEval": 0.32, "JMMLU": 0.479, "JSQuAD": 0.895, "Ja Avg": 0.437, "MGSM": 0.356, "NIILC": 0.405, "WMT20-en-ja": 0.221, "WMT20-ja-en": 0.21, "XL-Sum": 0.179}, "other": {"GPQA": 0.17}}, "sortkey": "llama 3.1", "uri": "meta-llama_Meta-Llama-3.1-8B", "url": "https://huggingface.co/meta-llama/Meta-Llama-3.1-8B"}, "mistralai/Mistral-7B-v0.3": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-05-22", "id": "mistralai/Mistral-7B-v0.3", "name": "Mistral-7B-v0.3", "params": 7.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.374, 0.695, 0.622, 0.511, 0.909, 0.623, 0.361, 0.116, 0.585, 0.273], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.714, 0.474, 0.245, 0.847, 0.212, 0.156, 0.142, 0.171, 0.404, 0.242], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 68, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.507}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 90, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.361}}, "results": {"en_basic": {"BBH": 0.585, "En Avg": 0.507, "GSM8K": 0.361, "HellaSwag": 0.622, "HumanEval": 0.273, "MATH": 0.116, "MMLU": 0.623, "OpenBookQA": 0.374, "SQuAD2": 0.511, "TriviaQA": 0.695, "XWINO": 0.909}, "ja_basic": {"JComQA": 0.714, "JEMHopQA": 0.474, "JHumanEval": 0.242, "JMMLU": 0.404, "JSQuAD": 0.847, "Ja Avg": 0.361, "MGSM": 0.156, "NIILC": 0.245, "WMT20-en-ja": 0.142, "WMT20-ja-en": 0.171, "XL-Sum": 0.212}, "other": {"GPQA": 0.129}}, "sortkey": "mistral v0.3", "uri": "mistralai_Mistral-7B-v0.3", "url": "https://huggingface.co/mistralai/Mistral-7B-v0.3"}, "mistralai/Mistral-Nemo-Base-2407": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-07-18", "id": "mistralai/Mistral-Nemo-Base-2407", "name": "Mistral-Nemo-Base-2407 (12B)", "params": 12, "radar": {"en_basic": {"id": "en_basic", "series": [0.422, 0.741, 0.647, 0.528, 0.914, 0.69, 0.55, 0.184, 0.657, 0.259], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.911, 0.516, 0.475, 0.904, 0.192, 0.416, 0.244, 0.212, 0.538, 0.194], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 51, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.559}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 59, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.46}}, "results": {"en_basic": {"BBH": 0.657, "En Avg": 0.559, "GSM8K": 0.55, "HellaSwag": 0.647, "HumanEval": 0.259, "MATH": 0.184, "MMLU": 0.69, "OpenBookQA": 0.422, "SQuAD2": 0.528, "TriviaQA": 0.741, "XWINO": 0.914}, "ja_basic": {"JComQA": 0.911, "JEMHopQA": 0.516, "JHumanEval": 0.194, "JMMLU": 0.538, "JSQuAD": 0.904, "Ja Avg": 0.46, "MGSM": 0.416, "NIILC": 0.475, "WMT20-en-ja": 0.244, "WMT20-ja-en": 0.212, "XL-Sum": 0.192}, "other": {"GPQA": 0.007}}, "sortkey": "mistral nemo 2407 ()", "uri": "mistralai_Mistral-Nemo-Base-2407", "url": "https://huggingface.co/mistralai/Mistral-Nemo-Base-2407"}, "nvidia/Mistral-NeMo-Minitron-8B-Base": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-08-21", "id": "nvidia/Mistral-NeMo-Minitron-8B-Base", "name": "Mistral-NeMo-Minitron 8B", "params": 8.4, "radar": {"en_basic": {"id": "en_basic", "series": [0.406, 0.728, 0.621, 0.525, 0.915, 0.694, 0.585, 0.202, 0.658, 0.382], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.887, 0.486, 0.374, 0.902, 0.157, 0.424, 0.186, 0.193, 0.494, 0.332], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 47, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.572}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 63, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.444}}, "results": {"en_basic": {"BBH": 0.658, "En Avg": 0.572, "GSM8K": 0.585, "HellaSwag": 0.621, "HumanEval": 0.382, "MATH": 0.202, "MMLU": 0.694, "OpenBookQA": 0.406, "SQuAD2": 0.525, "TriviaQA": 0.728, "XWINO": 0.915}, "ja_basic": {"JComQA": 0.887, "JEMHopQA": 0.486, "JHumanEval": 0.332, "JMMLU": 0.494, "JSQuAD": 0.902, "Ja Avg": 0.444, "MGSM": 0.424, "NIILC": 0.374, "WMT20-en-ja": 0.186, "WMT20-ja-en": 0.193, "XL-Sum": 0.157}, "other": {"GPQA": 0.179}}, "sortkey": "mistral nemo minitron", "uri": "nvidia_Mistral-NeMo-Minitron-8B-Base", "url": "https://huggingface.co/nvidia/Mistral-NeMo-Minitron-8B-Base"}, "pfnet/plamo-2-8b": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2025-02-21", "id": "pfnet/plamo-2-8b", "name": "PLaMo 2 8B", "params": 9.1, "radar": {"en_basic": {"id": "en_basic", "series": [0.346, 0.584, 0.56, 0.511, 0.89, 0.575, 0.55, 0.2, 0.26, 0.26], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.909, 0.474, 0.655, 0.91, 0.12, 0.508, 0.28, 0.205, 0.536, 0.213], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 75, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.474}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 49, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.481}}, "results": {"en_basic": {"BBH": 0.26, "En Avg": 0.474, "GSM8K": 0.55, "HellaSwag": 0.56, "HumanEval": 0.26, "MATH": 0.2, "MMLU": 0.575, "OpenBookQA": 0.346, "SQuAD2": 0.511, "TriviaQA": 0.584, "XWINO": 0.89}, "ja_basic": {"JComQA": 0.909, "JEMHopQA": 0.474, "JHumanEval": 0.213, "JMMLU": 0.536, "JSQuAD": 0.91, "Ja Avg": 0.481, "MGSM": 0.508, "NIILC": 0.655, "WMT20-en-ja": 0.28, "WMT20-ja-en": 0.205, "XL-Sum": 0.12}, "other": {"GPQA": 0.022}}, "sortkey": "plamo 2", "uri": "pfnet_plamo-2-8b", "url": "https://huggingface.co/pfnet/plamo-2-8b"}, "rinna/llama-3-youko-8b": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-05-07", "id": "rinna/llama-3-youko-8b", "name": "Llama 3 Youko 8B", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.348, 0.625, 0.589, 0.502, 0.896, 0.601, 0.355, 0.096, 0.571, 0.281], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.87, 0.493, 0.513, 0.895, 0.213, 0.276, 0.276, 0.219, 0.449, 0.222], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 74, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.486}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 64, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.442}}, "results": {"en_basic": {"BBH": 0.571, "En Avg": 0.486, "GSM8K": 0.355, "HellaSwag": 0.589, "HumanEval": 0.281, "MATH": 0.096, "MMLU": 0.601, "OpenBookQA": 0.348, "SQuAD2": 0.502, "TriviaQA": 0.625, "XWINO": 0.896}, "ja_basic": {"JComQA": 0.87, "JEMHopQA": 0.493, "JHumanEval": 0.222, "JMMLU": 0.449, "JSQuAD": 0.895, "Ja Avg": 0.442, "MGSM": 0.276, "NIILC": 0.513, "WMT20-en-ja": 0.276, "WMT20-ja-en": 0.219, "XL-Sum": 0.213}, "other": {"GPQA": 0.063}}, "sortkey": "llama 3 youko", "uri": "rinna_llama-3-youko-8b", "url": "https://huggingface.co/rinna/llama-3-youko-8b"}, "sbintuitions/sarashina2-13b": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-06-14", "id": "sbintuitions/sarashina2-13b", "name": "Sarashina2-13B", "params": 13, "radar": {"en_basic": {"id": "en_basic", "series": [0.34, 0.548, 0.562, 0.501, 0.896, 0.496, 0.158, 0.036, 0.442, 0.198], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.85, 0.557, 0.661, 0.898, 0.158, 0.188, 0.284, 0.221, 0.473, 0.161], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 85, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.418}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 61, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.445}}, "results": {"en_basic": {"BBH": 0.442, "En Avg": 0.418, "GSM8K": 0.158, "HellaSwag": 0.562, "HumanEval": 0.198, "MATH": 0.036, "MMLU": 0.496, "OpenBookQA": 0.34, "SQuAD2": 0.501, "TriviaQA": 0.548, "XWINO": 0.896}, "ja_basic": {"JComQA": 0.85, "JEMHopQA": 0.557, "JHumanEval": 0.161, "JMMLU": 0.473, "JSQuAD": 0.898, "Ja Avg": 0.445, "MGSM": 0.188, "NIILC": 0.661, "WMT20-en-ja": 0.284, "WMT20-ja-en": 0.221, "XL-Sum": 0.158}, "other": {"GPQA": 0.02}}, "sortkey": "sarashina2", "uri": "sbintuitions_sarashina2-13b", "url": "https://huggingface.co/sbintuitions/sarashina2-13b"}, "sbintuitions/sarashina2-7b": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-06-14", "id": "sbintuitions/sarashina2-7b", "name": "Sarashina2-7B", "params": 7.3, "radar": {"en_basic": {"id": "en_basic", "series": [0.346, 0.479, 0.532, 0.501, 0.892, 0.425, 0.101, 0.034, 0.373, 0.146], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.742, 0.509, 0.634, 0.868, 0.141, 0.08, 0.273, 0.201, 0.384, 0.121], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 93, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.383}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 76, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.395}}, "results": {"en_basic": {"BBH": 0.373, "En Avg": 0.383, "GSM8K": 0.101, "HellaSwag": 0.532, "HumanEval": 0.146, "MATH": 0.034, "MMLU": 0.425, "OpenBookQA": 0.346, "SQuAD2": 0.501, "TriviaQA": 0.479, "XWINO": 0.892}, "ja_basic": {"JComQA": 0.742, "JEMHopQA": 0.509, "JHumanEval": 0.121, "JMMLU": 0.384, "JSQuAD": 0.868, "Ja Avg": 0.395, "MGSM": 0.08, "NIILC": 0.634, "WMT20-en-ja": 0.273, "WMT20-ja-en": 0.201, "XL-Sum": 0.141}, "other": {"GPQA": 0.078}}, "sortkey": "sarashina2", "uri": "sbintuitions_sarashina2-7b", "url": "https://huggingface.co/sbintuitions/sarashina2-7b"}, "tiiuae/Falcon3-10B-Base": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-12-19", "id": "tiiuae/Falcon3-10B-Base", "name": "Falcon3-10B-Base", "params": 10, "radar": {"en_basic": {"id": "en_basic", "series": [0.368, 0.579, 0.596, 0.603, 0.901, 0.732, 0.802, 0.492, 0.776, 0.543], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.68, 0.443, 0.187, 0.854, 0.187, 0.376, 0.103, 0.139, 0.435, 0.426], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 28, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.639}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 80, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.383}}, "results": {"en_basic": {"BBH": 0.776, "En Avg": 0.639, "GSM8K": 0.802, "HellaSwag": 0.596, "HumanEval": 0.543, "MATH": 0.492, "MMLU": 0.732, "OpenBookQA": 0.368, "SQuAD2": 0.603, "TriviaQA": 0.579, "XWINO": 0.901}, "ja_basic": {"JComQA": 0.68, "JEMHopQA": 0.443, "JHumanEval": 0.426, "JMMLU": 0.435, "JSQuAD": 0.854, "Ja Avg": 0.383, "MGSM": 0.376, "NIILC": 0.187, "WMT20-en-ja": 0.103, "WMT20-ja-en": 0.139, "XL-Sum": 0.187}, "other": {"GPQA": 0.259}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-10B-Base", "url": "https://huggingface.co/tiiuae/Falcon3-10B-Base"}, "tiiuae/Falcon3-7B-Base": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-12-19", "id": "tiiuae/Falcon3-7B-Base", "name": "Falcon3-7B-Base", "params": 7.5, "radar": {"en_basic": {"id": "en_basic", "series": [0.354, 0.552, 0.566, 0.539, 0.881, 0.701, 0.766, 0.438, 0.692, 0.476], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.634, 0.412, 0.18, 0.788, 0.173, 0.244, 0.078, 0.119, 0.385, 0.361], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 41, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.596}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 97, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.337}}, "results": {"en_basic": {"BBH": 0.692, "En Avg": 0.596, "GSM8K": 0.766, "HellaSwag": 0.566, "HumanEval": 0.476, "MATH": 0.438, "MMLU": 0.701, "OpenBookQA": 0.354, "SQuAD2": 0.539, "TriviaQA": 0.552, "XWINO": 0.881}, "ja_basic": {"JComQA": 0.634, "JEMHopQA": 0.412, "JHumanEval": 0.361, "JMMLU": 0.385, "JSQuAD": 0.788, "Ja Avg": 0.337, "MGSM": 0.244, "NIILC": 0.18, "WMT20-en-ja": 0.078, "WMT20-ja-en": 0.119, "XL-Sum": 0.173}, "other": {"GPQA": 0.252}}, "sortkey": "falcon3", "uri": "tiiuae_Falcon3-7B-Base", "url": "https://huggingface.co/tiiuae/Falcon3-7B-Base"}, "tokyotech-llm/Llama-3-Swallow-8B-v0.1": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-07-01", "id": "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "name": "Llama 3 Swallow 8B", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.35, 0.656, 0.59, 0.519, 0.901, 0.615, 0.483, 0.182, 0.598, 0.337], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.896, 0.478, 0.546, 0.9, 0.198, 0.44, 0.276, 0.222, 0.471, 0.282], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 66, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.523}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 55, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.471}}, "results": {"en_basic": {"BBH": 0.598, "En Avg": 0.523, "GSM8K": 0.483, "HellaSwag": 0.59, "HumanEval": 0.337, "MATH": 0.182, "MMLU": 0.615, "OpenBookQA": 0.35, "SQuAD2": 0.519, "TriviaQA": 0.656, "XWINO": 0.901}, "ja_basic": {"JComQA": 0.896, "JEMHopQA": 0.478, "JHumanEval": 0.282, "JMMLU": 0.471, "JSQuAD": 0.9, "Ja Avg": 0.471, "MGSM": 0.44, "NIILC": 0.546, "WMT20-en-ja": 0.276, "WMT20-ja-en": 0.222, "XL-Sum": 0.198}, "other": {"GPQA": 0.188}}, "sortkey": "llama 3 swallow", "uri": "tokyotech-llm_Llama-3-Swallow-8B-v0.1", "url": "https://huggingface.co/tokyotech-llm/Llama-3-Swallow-8B-v0.1"}, "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-10-08", "id": "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "name": "Llama 3.1 Swallow 8B v0.1", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.378, 0.671, 0.605, 0.502, 0.905, 0.624, 0.511, 0.224, 0.615, 0.348], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.912, 0.509, 0.601, 0.899, 0.202, 0.46, 0.291, 0.231, 0.518, 0.276], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 61, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.538}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 47, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.49}}, "results": {"en_basic": {"BBH": 0.615, "En Avg": 0.538, "GSM8K": 0.511, "HellaSwag": 0.605, "HumanEval": 0.348, "MATH": 0.224, "MMLU": 0.624, "OpenBookQA": 0.378, "SQuAD2": 0.502, "TriviaQA": 0.671, "XWINO": 0.905}, "ja_basic": {"JComQA": 0.912, "JEMHopQA": 0.509, "JHumanEval": 0.276, "JMMLU": 0.518, "JSQuAD": 0.899, "Ja Avg": 0.49, "MGSM": 0.46, "NIILC": 0.601, "WMT20-en-ja": 0.291, "WMT20-ja-en": 0.231, "XL-Sum": 0.202}, "other": {"GPQA": 0.234}}, "sortkey": "llama 3.1 swallow v0.1", "uri": "tokyotech-llm_Llama-3.1-Swallow-8B-v0.1", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-v0.1"}, "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-11-11", "id": "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "name": "Llama 3.1 Swallow 8B v0.2", "params": 8.0, "radar": {"en_basic": {"id": "en_basic", "series": [0.382, 0.651, 0.596, 0.513, 0.904, 0.622, 0.521, 0.228, 0.605, 0.366], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.911, 0.51, 0.627, 0.892, 0.198, 0.464, 0.296, 0.233, 0.525, 0.336], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 60, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.539}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 43, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.499}}, "results": {"en_basic": {"BBH": 0.605, "En Avg": 0.539, "GSM8K": 0.521, "HellaSwag": 0.596, "HumanEval": 0.366, "MATH": 0.228, "MMLU": 0.622, "OpenBookQA": 0.382, "SQuAD2": 0.513, "TriviaQA": 0.651, "XWINO": 0.904}, "ja_basic": {"JComQA": 0.911, "JEMHopQA": 0.51, "JHumanEval": 0.336, "JMMLU": 0.525, "JSQuAD": 0.892, "Ja Avg": 0.499, "MGSM": 0.464, "NIILC": 0.627, "WMT20-en-ja": 0.296, "WMT20-ja-en": 0.233, "XL-Sum": 0.198}, "other": {"GPQA": 0.225}}, "sortkey": "llama 3.1 swallow v0.2", "uri": "tokyotech-llm_Llama-3.1-Swallow-8B-v0.2", "url": "https://huggingface.co/tokyotech-llm/Llama-3.1-Swallow-8B-v0.2"}, "tokyotech-llm/Swallow-13b-hf": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2023-12-19", "id": "tokyotech-llm/Swallow-13b-hf", "name": "Swallow 13B", "params": 13, "radar": {"en_basic": {"id": "en_basic", "series": [0.344, 0.58, 0.56, 0.502, 0.902, 0.501, 0.197, 0.024, 0.43, 0.08], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.764, 0.507, 0.643, 0.893, 0.215, 0.208, 0.272, 0.178, 0.439, 0.027], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 87, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.412}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 72, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.415}}, "results": {"en_basic": {"BBH": 0.43, "En Avg": 0.412, "GSM8K": 0.197, "HellaSwag": 0.56, "HumanEval": 0.08, "MATH": 0.024, "MMLU": 0.501, "OpenBookQA": 0.344, "SQuAD2": 0.502, "TriviaQA": 0.58, "XWINO": 0.902}, "ja_basic": {"JComQA": 0.764, "JEMHopQA": 0.507, "JHumanEval": 0.027, "JMMLU": 0.439, "JSQuAD": 0.893, "Ja Avg": 0.415, "MGSM": 0.208, "NIILC": 0.643, "WMT20-en-ja": 0.272, "WMT20-ja-en": 0.178, "XL-Sum": 0.215}, "other": {"GPQA": 0.116}}, "sortkey": "swallow", "uri": "tokyotech-llm_Swallow-13b-hf", "url": "https://huggingface.co/tokyotech-llm/Swallow-13b-hf"}, "tokyotech-llm/Swallow-7b-hf": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2023-12-19", "id": "tokyotech-llm/Swallow-7b-hf", "name": "Swallow 7B", "params": 6.7, "radar": {"en_basic": {"id": "en_basic", "series": [0.312, 0.491, 0.527, 0.501, 0.885, 0.391, 0.103, 0.02, 0.354, 0.041], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.483, 0.511, 0.585, 0.847, 0.182, 0.108, 0.25, 0.149, 0.324, 0.018], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 98, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.363}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 96, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.346}}, "results": {"en_basic": {"BBH": 0.354, "En Avg": 0.363, "GSM8K": 0.103, "HellaSwag": 0.527, "HumanEval": 0.041, "MATH": 0.02, "MMLU": 0.391, "OpenBookQA": 0.312, "SQuAD2": 0.501, "TriviaQA": 0.491, "XWINO": 0.885}, "ja_basic": {"JComQA": 0.483, "JEMHopQA": 0.511, "JHumanEval": 0.018, "JMMLU": 0.324, "JSQuAD": 0.847, "Ja Avg": 0.346, "MGSM": 0.108, "NIILC": 0.585, "WMT20-en-ja": 0.25, "WMT20-ja-en": 0.149, "XL-Sum": 0.182}, "other": {"GPQA": 0.013}}, "sortkey": "swallow", "uri": "tokyotech-llm_Swallow-7b-hf", "url": "https://huggingface.co/tokyotech-llm/Swallow-7b-hf"}, "tokyotech-llm/Swallow-MS-7b-v0.1": {"base_model": "", "category": ["index-base", "category-5b-15b-base"], "date": "2024-03-11", "id": "tokyotech-llm/Swallow-MS-7b-v0.1", "name": "Swallow-MS 7B v0.1", "params": 7.2, "radar": {"en_basic": {"id": "en_basic", "series": [0.352, 0.599, 0.579, 0.501, 0.901, 0.548, 0.268, 0.096, 0.491, 0.27], "tasks": ["OpenBookQA", "TriviaQA", "HellaSwag", "SQuAD2", "XWINO", "MMLU", "GSM8K", "MATH", "BBH", "HumanEval"], "title": "English understanding \u0026 generation"}, "ja_basic": {"id": "ja_basic", "series": [0.873, 0.517, 0.572, 0.879, 0.197, 0.244, 0.251, 0.167, 0.459, 0.232], "tasks": ["JComQA", "JEMHQA", "NIILC", "JSQuAD", "XL-Sum", "MGSM", "En-Ja", "Ja-En", "JMMLU", "JHumanEval"], "title": "Japanese understanding \u0026 generation"}}, "ranking": {"En Avg": {"ids": ["pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "stockmark/stockmark-100b", "llm-jp/llm-jp-3-1.8b-instruct", "llm-jp/llm-jp-3-3.7b", "Qwen/Qwen2.5-0.5B-Instruct", "meta-llama/Llama-3.2-1B", "llm-jp/llm-jp-3-3.7b-instruct", "rinna/gemma-2-baku-2b-it", "tokyotech-llm/Swallow-7b-hf", "Qwen/Qwen2.5-0.5B", "tokyotech-llm/Swallow-7b-instruct-v0.1", "tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "sbintuitions/sarashina2-7b", "llm-jp/llm-jp-3-13b", "rinna/gemma-2-baku-2b", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-1B-Instruct", "SakanaAI/TinySwallow-1.5B-Instruct", "tokyotech-llm/Swallow-13b-hf", "SakanaAI/TinySwallow-1.5B", "sbintuitions/sarashina2-13b", "Qwen/Qwen2.5-1.5B-Instruct", "llm-jp/llm-jp-3-13b-instruct", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "google/gemma-2-2b", "meta-llama/Llama-3.2-3B", "tokyotech-llm/Swallow-MS-7b-v0.1", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "google/gemma-2-2b-jpn-it", "Qwen/Qwen2.5-3B-Instruct", "pfnet/plamo-2-8b", "rinna/llama-3-youko-8b", "google/gemma-2-2b-it", "Qwen/Qwen2.5-1.5B", "sbintuitions/sarashina2-70b", "tiiuae/Falcon3-3B-Base", "elyza/Llama-3-ELYZA-JP-8B", "mistralai/Mistral-7B-v0.3", "rinna/llama-3-youko-8b-instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "tiiuae/Falcon3-3B-Instruct", "cyberagent/calm3-22b-chat", "Qwen/Qwen2.5-3B", "meta-llama/Llama-3.2-3B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "CohereForAI/aya-expanse-8b", "01-ai/Yi-1.5-6B", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Meta-Llama-3-8B", "tokyotech-llm/Swallow-70b-hf", "meta-llama/Meta-Llama-3.1-8B", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mistral-Nemo-Base-2407", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "nvidia/Mistral-NeMo-Minitron-8B-Base", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "Qwen/Qwen2-7B-Instruct", "Qwen/Qwen2.5-32B-Instruct", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "01-ai/Yi-1.5-9B", "tiiuae/Falcon3-7B-Base", "google/gemma-2-9b", "Qwen/Qwen2-7B", "Qwen/Qwen2.5-7B-Instruct", "meta-llama/Meta-Llama-3-8B-Instruct", "mistralai/Mistral-Nemo-Instruct-2407", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-14B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-7B-Instruct", "meta-llama/Meta-Llama-3.1-8B-Instruct", "Qwen/Qwen2.5-7B", "tiiuae/Falcon3-10B-Instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-9b-it", "01-ai/Yi-1.5-34B", "mistralai/Mixtral-8x22B-v0.1", "google/gemma-2-27b", "Qwen/Qwen2-72B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "microsoft/phi-4", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-72B-Instruct", "Qwen/Qwen2-72B", "google/gemma-2-27b-it", "rinna/llama-3-youko-70b-instruct", "Qwen/Qwen2.5-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "turing-motors/Llama-3-heron-brain-70B-v0.3", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "mistralai/Mixtral-8x22B-Instruct-v0.1", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "meta-llama/Meta-Llama-3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "meta-llama/Meta-Llama-3.1-70B-Instruct", "meta-llama/Llama-3.3-70B-Instruct"], "labels": ["PLaMo 2 1B", "llm-jp-3-1.8b", "Stockmark-100b", "llm-jp-3-1.8b-instruct", "llm-jp-3-3.7b", "Qwen2.5-0.5B-Instruct", "Llama 3.2 1B", "llm-jp-3-3.7b-instruct", "Gemma 2 Baku 2B IT", "Swallow 7B", "Qwen2.5-0.5B", "Swallow-7b-instruct-v0.1", "Falcon3-1B-Base", "Falcon3-1B-Instruct", "Sarashina2-7B", "llm-jp-3-13b", "Gemma 2 Baku 2B", "Tanuki-8B-dpo-v1.0", "Llama 3.2 1B Instruct", "TinySwallow-1.5B-Instruct", "Swallow 13B", "TinySwallow-1.5B", "Sarashina2-13B", "Qwen2.5-1.5B-Instruct", "llm-jp-3-13b-instruct", "Swallow-MS-7b-instruct-v0.1", "Gemma 2 2B", "Llama 3.2 3B", "Swallow-MS 7B v0.1", "Tanuki-8x8B-dpo-v1.0", "Gemma 2 JPN", "Qwen2.5-3B-Instruct", "PLaMo 2 8B", "Llama 3 Youko 8B", "Gemma 2 2B IT", "Qwen2.5-1.5B", "Sarashina2-70B", "Falcon3-3B-Base", "Llama-3-ELYZA-JP-8B", "Mistral-7B-v0.3", "Llama 3 Youko 8B Instruct", "Llama 3 Swallow 8B", "Falcon3-3B-Instruct", "CyberAgentLM3-22B-chat", "Qwen2.5-3B", "Llama 3.2 3B Instruct", "Llama 3.1 Swallow 8B v0.1", "Llama 3.1 Swallow 8B v0.2", "Aya Expanse 8B", "Yi-1.5 6B", "Mistral-7B-Instruct-v0.3", "Llama 3 8B", "Swallow 70B", "Llama 3.1 8B", "Llama 3 heron brain 8B v0.3", "Swallow-70b-instruct-v0.1", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Swallow 8B Instruct", "Llama 3.1 Swallow 8B Instruct v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Mistral-NeMo-Minitron 8B", "Llama 3.1 Swallow 8B Instruct v0.2", "Qwen2-7B-Instruct", "Qwen2.5-32B-Instruct", "Swallow-MX 8x7B v0.1", "Yi-1.5 9B", "Falcon3-7B-Base", "Gemma 2 9B", "Qwen2-7B", "Qwen2.5-7B-Instruct", "Llama 3 8B Instruct", "Mistral-NeMo-Instruct-2407 (12B)", "Aya Expanse 32B", "Qwen2.5-14B-Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-7B-Instruct", "Llama 3.1 8B Instruct", "Qwen2.5-7B", "Falcon3-10B-Instruct", "Falcon3-10B-Base", "Gemma 2 9B IT", "Yi-1.5 34B", "Mixtral-8x22B-v0.1", "Gemma 2 27B", "Qwen2-72B-Instruct", "Llama 3.1 70B", "Llama 3 Youko 70B", "Llama 3 Swallow 70B", "Phi-4", "Llama 3.1 Swallow 70B v0.1", "Llama 3 70B", "Qwen2.5-72B-Instruct", "Qwen2-72B", "Gemma 2 27B IT", "Llama 3 Youko 70B Instruct", "Qwen2.5-72B", "Llama 3.1 Swallow 70B Instruct v0.3", "Llama 3.1 Swallow 70B Instruct v0.1", "Llama 3.3 Swallow 70B v0.4", "Llama 3 heron brain 70B v0.3", "Llama 3 Swallow 70B Instruct", "Mixtral-8x22B-Instruct-v0.1", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3.1 70B Instruct", "Llama 3.3 70B Instruct"], "rank": 79, "series": [0.274, 0.293, 0.302, 0.3129, 0.324, 0.3363, 0.339, 0.3473, 0.3608, 0.363, 0.365, 0.3759, 0.376, 0.3811, 0.383, 0.399, 0.4, 0.4065, 0.4079, 0.4114, 0.412, 0.413, 0.418, 0.4241, 0.4318, 0.4362, 0.439, 0.45, 0.461, 0.4641, 0.4705, 0.4717, 0.474, 0.486, 0.4887, 0.49, 0.491, 0.495, 0.4953, 0.507, 0.5073, 0.523, 0.526, 0.5269, 0.534, 0.5374, 0.538, 0.539, 0.5394, 0.54, 0.5407, 0.542, 0.543, 0.545, 0.5511, 0.5561, 0.559, 0.5605, 0.5626, 0.5662, 0.572, 0.5743, 0.582, 0.5881, 0.589, 0.592, 0.596, 0.597, 0.602, 0.6039, 0.6051, 0.6081, 0.6143, 0.6144, 0.6145, 0.6184, 0.6275, 0.63, 0.6333, 0.639, 0.6487, 0.65, 0.652, 0.655, 0.6687, 0.671, 0.671, 0.672, 0.6769, 0.679, 0.689, 0.6913, 0.702, 0.7033, 0.7085, 0.709, 0.7102, 0.7102, 0.711, 0.7151, 0.7158, 0.7196, 0.7253, 0.7293, 0.7356, 0.7381, 0.7619], "task": "En Avg", "taskcat": "en_basic", "value": 0.461}, "Ja Avg": {"ids": ["tiiuae/Falcon3-1B-Base", "tiiuae/Falcon3-1B-Instruct", "meta-llama/Llama-3.2-1B", "tiiuae/Falcon3-3B-Base", "tiiuae/Falcon3-3B-Instruct", "Qwen/Qwen2.5-0.5B", "stockmark/stockmark-100b", "meta-llama/Llama-3.2-1B-Instruct", "Qwen/Qwen2.5-0.5B-Instruct", "pfnet/plamo-2-1b", "llm-jp/llm-jp-3-1.8b", "llm-jp/llm-jp-3-3.7b", "llm-jp/llm-jp-3-1.8b-instruct", "weblab-GENIAC/Tanuki-8B-dpo-v1.0", "meta-llama/Llama-3.2-3B", "tiiuae/Falcon3-7B-Base", "tokyotech-llm/Swallow-7b-hf", "google/gemma-2-2b", "llm-jp/llm-jp-3-3.7b-instruct", "tokyotech-llm/Swallow-7b-instruct-v0.1", "01-ai/Yi-1.5-6B", "Qwen/Qwen2.5-1.5B-Instruct", "mistralai/Mistral-7B-v0.3", "tiiuae/Falcon3-7B-Instruct", "rinna/gemma-2-baku-2b-it", "tiiuae/Falcon3-10B-Instruct", "Qwen/Qwen2.5-1.5B", "rinna/gemma-2-baku-2b", "google/gemma-2-2b-jpn-it", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.2-3B-Instruct", "microsoft/Phi-3-mini-128k-instruct", "tiiuae/Falcon3-10B-Base", "google/gemma-2-2b-it", "llm-jp/llm-jp-3-13b", "tokyotech-llm/Swallow-MS-7b-instruct-v0.1", "sbintuitions/sarashina2-7b", "SakanaAI/TinySwallow-1.5B-Instruct", "SakanaAI/TinySwallow-1.5B", "Qwen/Qwen2.5-3B-Instruct", "tokyotech-llm/Swallow-13b-hf", "meta-llama/Meta-Llama-3-8B", "meta-llama/Meta-Llama-3-8B-Instruct", "01-ai/Yi-1.5-9B", "llm-jp/llm-jp-3-13b-instruct", "meta-llama/Meta-Llama-3.1-8B", "tokyotech-llm/Swallow-MS-7b-v0.1", "Qwen/Qwen2.5-3B", "rinna/llama-3-youko-8b", "nvidia/Mistral-NeMo-Minitron-8B-Base", "CohereForAI/aya-expanse-8b", "sbintuitions/sarashina2-13b", "weblab-GENIAC/Tanuki-8x8B-dpo-v1.0", "mistralai/Mistral-Nemo-Base-2407", "rinna/llama-3-youko-8b-instruct", "01-ai/Yi-1.5-34B", "meta-llama/Meta-Llama-3.1-8B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-v0.1", "elyza/Llama-3-ELYZA-JP-8B", "cyberagent/calm3-22b-chat", "Qwen/Qwen2-7B", "Qwen/Qwen2-7B-Instruct", "tokyotech-llm/Llama-3-Swallow-8B-Instruct-v0.1", "pfnet/plamo-2-8b", "turing-motors/Llama-3-heron-brain-8B-v0.3", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.1", "tokyotech-llm/Swallow-70b-instruct-v0.1", "mistralai/Mixtral-8x22B-v0.1", "Qwen/Qwen2.5-7B-Instruct", "tokyotech-llm/Llama-3.1-Swallow-8B-v0.2", "google/gemma-2-9b", "mistralai/Mistral-Nemo-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.1", "tokyotech-llm/Swallow-MX-8x7b-NVE-v0.1", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.3", "CohereForAI/aya-expanse-32b", "Qwen/Qwen2.5-7B", "tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.2", "gpt-3.5-turbo-0125", "tokyotech-llm/Swallow-70b-hf", "sbintuitions/sarashina2-70b", "mistralai/Mixtral-8x22B-Instruct-v0.1", "google/gemma-2-9b-it", "google/gemma-2-27b", "Qwen/Qwen2.5-14B-Instruct", "meta-llama/Meta-Llama-3.1-70B", "google/gemma-2-27b-it", "meta-llama/Meta-Llama-3-70B", "Qwen/Qwen2.5-32B-Instruct", "rinna/llama-3-youko-70b", "tokyotech-llm/Llama-3-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2.5-72B-Instruct", "meta-llama/Meta-Llama-3-70B-Instruct", "microsoft/phi-4", "gpt-4o-mini-2024-07-18", "rinna/llama-3-youko-70b-instruct", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.1", "Qwen/Qwen2-72B", "tokyotech-llm/Llama-3.1-Swallow-70B-v0.1", "tokyotech-llm/Llama-3-Swallow-70B-v0.1", "meta-llama/Meta-Llama-3.1-70B-Instruct", "cyberagent/Llama-3.1-70B-Japanese-Instruct-2407", "tokyotech-llm/Llama-3.1-Swallow-70B-Instruct-v0.3", "Qwen/Qwen2-72B-Instruct", "meta-llama/Llama-3.3-70B-Instruct", "tokyotech-llm/Llama-3.3-Swallow-70B-Instruct-v0.1-stage2-iter_0002500", "turing-motors/Llama-3-heron-brain-70B-v0.3", "Qwen/Qwen2.5-72B", "gpt-4-turbo-2024-04-09", "tokyotech-llm/Llama-3.3-Swallow-70B-v0.4", "gpt-4o-2024-08-06", "gpt-4o-2024-05-13"], "labels": ["Falcon3-1B-Base", "Falcon3-1B-Instruct", "Llama 3.2 1B", "Falcon3-3B-Base", "Falcon3-3B-Instruct", "Qwen2.5-0.5B", "Stockmark-100b", "Llama 3.2 1B Instruct", "Qwen2.5-0.5B-Instruct", "PLaMo 2 1B", "llm-jp-3-1.8b", "llm-jp-3-3.7b", "llm-jp-3-1.8b-instruct", "Tanuki-8B-dpo-v1.0", "Llama 3.2 3B", "Falcon3-7B-Base", "Swallow 7B", "Gemma 2 2B", "llm-jp-3-3.7b-instruct", "Swallow-7b-instruct-v0.1", "Yi-1.5 6B", "Qwen2.5-1.5B-Instruct", "Mistral-7B-v0.3", "Falcon3-7B-Instruct", "Gemma 2 Baku 2B IT", "Falcon3-10B-Instruct", "Qwen2.5-1.5B", "Gemma 2 Baku 2B", "Gemma 2 JPN", "Mistral-7B-Instruct-v0.3", "Llama 3.2 3B Instruct", "Phi-3-Mini-128K-Instruct", "Falcon3-10B-Base", "Gemma 2 2B IT", "llm-jp-3-13b", "Swallow-MS-7b-instruct-v0.1", "Sarashina2-7B", "TinySwallow-1.5B-Instruct", "TinySwallow-1.5B", "Qwen2.5-3B-Instruct", "Swallow 13B", "Llama 3 8B", "Llama 3 8B Instruct", "Yi-1.5 9B", "llm-jp-3-13b-instruct", "Llama 3.1 8B", "Swallow-MS 7B v0.1", "Qwen2.5-3B", "Llama 3 Youko 8B", "Mistral-NeMo-Minitron 8B", "Aya Expanse 8B", "Sarashina2-13B", "Tanuki-8x8B-dpo-v1.0", "Mistral-Nemo-Base-2407 (12B)", "Llama 3 Youko 8B Instruct", "Yi-1.5 34B", "Llama 3.1 8B Instruct", "Llama 3 Swallow 8B", "Llama-3-ELYZA-JP-8B", "CyberAgentLM3-22B-chat", "Qwen2-7B", "Qwen2-7B-Instruct", "Llama 3 Swallow 8B Instruct", "PLaMo 2 8B", "Llama 3 heron brain 8B v0.3", "Llama 3.1 Swallow 8B v0.1", "Swallow-70b-instruct-v0.1", "Mixtral-8x22B-v0.1", "Qwen2.5-7B-Instruct", "Llama 3.1 Swallow 8B v0.2", "Gemma 2 9B", "Mistral-NeMo-Instruct-2407 (12B)", "Llama 3.1 Swallow 8B Instruct v0.1", "Swallow-MX 8x7B v0.1", "Llama 3.1 Swallow 8B Instruct v0.3", "Aya Expanse 32B", "Qwen2.5-7B", "Llama 3.1 Swallow 8B Instruct v0.2", "GPT-3.5 (gpt-3.5-turbo-0125)", "Swallow 70B", "Sarashina2-70B", "Mixtral-8x22B-Instruct-v0.1", "Gemma 2 9B IT", "Gemma 2 27B", "Qwen2.5-14B-Instruct", "Llama 3.1 70B", "Gemma 2 27B IT", "Llama 3 70B", "Qwen2.5-32B-Instruct", "Llama 3 Youko 70B", "Llama 3 Swallow 70B Instruct", "Qwen2.5-72B-Instruct", "Llama 3 70B Instruct", "Phi-4", "GPT-4o-mini (gpt-4o-mini-2024-07-18)", "Llama 3 Youko 70B Instruct", "Llama 3.1 Swallow 70B Instruct v0.1", "Qwen2-72B", "Llama 3.1 Swallow 70B v0.1", "Llama 3 Swallow 70B", "Llama 3.1 70B Instruct", "Llama-3.1-70B-Japanese-Instruct-2407", "Llama 3.1 Swallow 70B Instruct v0.3", "Qwen2-72B-Instruct", "Llama 3.3 70B Instruct", "Llama 3.3 Swallow 70B Instruct v0.4", "Llama 3 heron brain 70B v0.3", "Qwen2.5-72B", "GPT-4-turbo (gpt-4-turbo-2024-04-09)", "Llama 3.3 Swallow 70B v0.4", "GPT-4o (gpt-4o-2024-08-06)", "GPT-4o (gpt-4o-2024-05-13)"], "rank": 66, "series": [0.129, 0.1689, 0.201, 0.209, 0.2319, 0.234, 0.238, 0.2386, 0.2432, 0.25, 0.251, 0.281, 0.2927, 0.311, 0.337, 0.337, 0.346, 0.348, 0.3501, 0.3527, 0.354, 0.3552, 0.361, 0.3635, 0.3662, 0.3669, 0.372, 0.372, 0.3769, 0.3778, 0.3803, 0.3819, 0.383, 0.3921, 0.393, 0.3936, 0.395, 0.3975, 0.402, 0.4088, 0.415, 0.429, 0.4303, 0.432, 0.4358, 0.437, 0.439, 0.442, 0.442, 0.444, 0.4449, 0.445, 0.4537, 0.46, 0.4676, 0.468, 0.4698, 0.471, 0.4712, 0.4714, 0.472, 0.4779, 0.4805, 0.481, 0.4877, 0.49, 0.4923, 0.496, 0.4983, 0.499, 0.5, 0.5004, 0.5055, 0.506, 0.5101, 0.5116, 0.512, 0.5141, 0.5151, 0.519, 0.53, 0.5323, 0.5345, 0.546, 0.5534, 0.566, 0.5673, 0.569, 0.5706, 0.571, 0.5711, 0.5738, 0.5776, 0.5797, 0.5805, 0.5817, 0.5884, 0.593, 0.593, 0.594, 0.595, 0.5967, 0.5977, 0.5978, 0.6005, 0.6129, 0.6148, 0.623, 0.6264, 0.629, 0.6462, 0.6488], "task": "Ja Avg", "taskcat": "ja_basic", "value": 0.439}}, "results": {"en_basic": {"BBH": 0.491, "En Avg": 0.461, "GSM8K": 0.268, "HellaSwag": 0.579, "HumanEval": 0.27, "MATH": 0.096, "MMLU": 0.548, "OpenBookQA": 0.352, "SQuAD2": 0.501, "TriviaQA": 0.599, "XWINO": 0.901}, "ja_basic": {"JComQA": 0.873, "JEMHopQA": 0.517, "JHumanEval": 0.232, "JMMLU": 0.459, "JSQuAD": 0.879, "Ja Avg": 0.439, "MGSM": 0.244, "NIILC": 0.572, "WMT20-en-ja": 0.251, "WMT20-ja-en": 0.167, "XL-Sum": 0.197}, "other": {"GPQA": 0.08}}, "sortkey": "swallow ms v0.1", "uri": "tokyotech-llm_Swallow-MS-7b-v0.1", "url": "https://huggingface.co/tokyotech-llm/Swallow-MS-7b-v0.1"}};
var g_taskcats = {"en_basic": {"category": "En", "description": "We evaluate LLMs on question answering, reading comprehension, and exam questions to assess language understanding and common knowledge, summarization to measure language generation, and code generation and mathematics to test logical reasoning abilities. The evaluation scores range from 0 (lowest) to 1 (highest).", "for": ["base", "inst"], "tasks": {"BBH": {"description": "23 tasks that are difficult in BIG-Bench dataset (Srivastava et al., 2023)", "link": {"author": "Suzgun et al.", "href": "https://aclanthology.org/2023.findings-acl.824/", "year": "2023"}, "metric": "Accuracy (exact match)", "name": "BBH", "setting": "3-shot, CoT", "short": "BBH", "subtitle": "Collection of hard-to-solve tasks for LLM", "title": "BIG-Bench-Hard (BBH)"}, "En Avg": {"collective": true, "description": "Average score of English understanding and generation", "metric": "Average", "name": "En Avg", "setting": "Excluding MBPP and GPQA", "short": "En avg", "subtitle": "English Understanding and Generation (avg)", "title": "English average"}, "GSM8K": {"description": "Math word problems", "link": {"author": "Cobbe et al.", "href": "https://arxiv.org/abs/2110.14168", "year": "2021"}, "metric": "Accuracy (exact match)", "name": "GSM8K", "setting": "4-shot", "short": "GSM8K", "subtitle": "Mathematics", "title": "GSM8K"}, "HellaSwag": {"description": "Four-choice questions to predict the next event", "link": {"author": "Zellers et al.", "href": "https://aclanthology.org/P19-1472/", "year": "2019"}, "metric": "Accuracy", "name": "HellaSwag", "setting": "4-shot", "short": "HellaSwag", "subtitle": "Commonsense inference", "title": "HellaSwag"}, "HumanEval": {"description": "Ability of code generation measured by unit test", "link": {"author": "Chen et al.", "href": "https://arxiv.org/abs/2107.03374", "year": "2021"}, "metric": "pass@1", "name": "HumanEval", "setting": "0-shot, 10 trials", "short": "HumanEval", "subtitle": "Code generation", "title": "HumanEval"}, "MATH": {"description": "High school math competitions", "link": {"author": "Hendrycks et al.", "href": "https://arxiv.org/abs/2103.03874", "year": "2021"}, "metric": "Accuracy (exact match)", "name": "MATH", "setting": "4-shot", "short": "MATH", "subtitle": "Mathematics", "title": "MATH"}, "MMLU": {"description": "Four-choice exam questions benchmark MMLU (53 subjects)", "link": {"author": "Hendrycks et al.", "href": "https://openreview.net/forum?id=d7KBjmI3GmQ", "year": "2021"}, "metric": "Accuracy", "name": "MMLU", "setting": "5-shot", "short": "MMLU", "subtitle": "Multitask natural language understanding", "title": "MMLU"}, "OpenBookQA": {"description": "Four-choice questions based on scientific knowledge and common sense", "link": {"author": "Mihaylov et al.", "href": "https://aclanthology.org/D18-1260/", "year": "2018"}, "metric": "Accuracy", "name": "OpenBookQA", "setting": "4-shot", "short": "OpenBookQA", "subtitle": "Q\u0026A based on facts and common sense", "title": "OpenBookQA"}, "SQuAD2": {"description": "Open-ended Q\u0026A developed for the evidence document", "link": {"author": "Rajpurkar et al.", "href": "https://aclanthology.org/P18-2124/", "year": "2018"}, "metric": "Accuracy (exact match)", "name": "SQuAD2", "setting": "4-shot", "short": "SQuAD2", "subtitle": "Reading comprehension", "title": "SQuAD2"}, "TriviaQA": {"description": "Open-ended Q\u0026A based on trivias", "link": {"author": "Joshi et al.", "href": "https://aclanthology.org/P17-1147/", "year": "2017"}, "metric": "Accuracy (exact match)", "name": "TriviaQA", "setting": "4-shot", "short": "TriviaQA", "subtitle": "Q\u0026A based on knowledge", "title": "TriviaQA"}, "XWINO": {"description": "Two-choice question to predict the antecedent of a pronoun", "link": {"author": "Tikhonov and Ryabinin", "href": "https://aclanthology.org/2021.findings-acl.310/", "year": "2021"}, "metric": "Accuracy", "name": "XWINO", "setting": "4-shot", "short": "XWINO", "subtitle": "Commonsense inference", "title": "XWINO"}}, "title": "English understanding \u0026 generation"}, "ja_basic": {"category": "Ja", "description": "We evaluate LLMs on question answering and reading comprehension to assess language understanding and common knowledge, summarization and translation to measure language generation, and code generation and mathematics to test logical reasoning abilities. The evaluation scores range from 0 (lowest) to 1 (highest).", "for": ["base", "inst"], "tasks": {"JComQA": {"description": "Five-choice questions created with a knowledge base", "link": {"author": "Kurihara et al.", "href": "https://aclanthology.org/2022.lrec-1.317/", "year": "2022"}, "metric": "Accuracy", "name": "JComQA", "setting": "4-shot", "short": "JComQA", "subtitle": "Q\u0026A regarding commonsense and inference", "title": "JCommonsenseQA (JComQA)"}, "JEMHopQA": {"description": "Open-ended Q\u0026A to assess the amount of knowledge and reasoning ability", "link": {"author": "Ishii et al.", "href": "https://aclanthology.org/2024.lrec-main.831/", "year": "2024"}, "metric": "Character F1", "name": "JEMHopQA", "setting": "4-shot", "short": "JEMHQA", "subtitle": "Multi-hop Q\u0026A", "title": "JEMHopQA"}, "JHumanEval": {"description": "Japanese translation of HumanEval (code genration benchmark)", "link": {"author": "Sato et al.", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/P10-9.pdf", "year": "2024"}, "metric": "pass@1", "name": "JHumanEval", "setting": "0-shot, 10 trials", "short": "JHumanEval", "subtitle": "Code generation", "title": "JHumanEval"}, "JMMLU": {"description": "Japanese translation of four-choice exam questions benchmark MMLU (53 subjects)", "link": {"author": "Yin et al", "href": "https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A7-5.pdf", "year": "2024"}, "metric": "Accuracy", "name": "JMMLU", "setting": "5-shot", "short": "JMMLU", "subtitle": "Multi-task natural language understanding", "title": "JMMLU"}, "JSQuAD": {"description": "Open-ended Q\u0026A for Wikipedia article", "link": {"author": "Kurihara et al.", "href": "https://aclanthology.org/2022.lrec-1.317/", "year": "2022"}, "metric": "Character F1", "name": "JSQuAD", "setting": "4-shot", "short": "JSQuAD", "subtitle": "Reading comprehension", "title": "JSQuAD"}, "Ja Avg": {"collective": true, "description": "Average score of Japanese understanding and generation", "metric": "Average", "name": "Ja Avg", "setting": "Excluding MBPP-Ja", "short": "Ja avg", "subtitle": "Japanese Understanding and Generation (avg)", "title": "Japanese average"}, "MGSM": {"description": "Japanese translation of math word problems (GSM8K)", "link": {"author": "Shi et al.", "href": "https://openreview.net/forum?id=fR3wGCk-IXp", "year": "2023"}, "metric": "Accuracy (exact match)", "name": "MGSM", "setting": "4-shot", "short": "MGSM", "subtitle": "Mathematics", "title": "MGSM"}, "NIILC": {"description": "Open-ended Q\u0026A that can be answered by an encyclopedia", "link": {"author": "Sekine", "href": "https://www.anlp.jp/proceedings/annual_meeting/2003/pdf_dir/C7-6.pdf", "year": "2003"}, "metric": "Character F1", "name": "NIILC", "setting": "4-shot", "short": "NIILC", "subtitle": "Classical Q\u0026A", "title": "NIILC"}, "WMT20-en-ja": {"description": "Translation of news articles (English to Japanese)", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20-en-ja", "setting": "4-shot", "short": "En-Ja", "subtitle": "English-Japanese translation", "title": "WMT20 (en-ja)"}, "WMT20-ja-en": {"description": "Translation of news articles (Japanese to English)", "link": {"author": "Barrault et al.", "href": "https://aclanthology.org/2020.wmt-1.1/", "year": "2020"}, "metric": "BLEU", "name": "WMT20-ja-en", "setting": "4-shot", "short": "Ja-En", "subtitle": "Japanese-English translation", "title": "WMT20 (ja-en)"}, "XL-Sum": {"description": "Task to generate a highlight from a news article of BBC", "link": {"author": "Hasan et al.", "href": "https://aclanthology.org/2021.findings-acl.413/", "year": "2021"}, "metric": "ROUGE-2", "name": "XL-Sum", "setting": "1-shot", "short": "XL-Sum", "subtitle": "Summarization", "title": "XL-Sum"}}, "title": "Japanese understanding \u0026 generation"}, "ja_mtb": {"category": "Ja-MTB", "description": "We used the Japanese version of MT-Bench (Nejumi LLM Leaderboard edition) to evaluate dialogue capabilities. The test questions are based on v4, and the reference answers are derived from v2 with corrections to incorrect responses. The evaluation scores range from 0 (lowest) to 1 (highest).", "for": ["inst"], "tasks": {"JMT Avg": {"collective": true, "name": "JMT Avg", "short": "JMT avg", "subtitle": "Japanese MT-Bench (avg)", "title": "Japanese MT-Bench average"}, "coding": {"description": "Implementing algorithms in Python or C++, and creating websites using HTML.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "coding", "short": "Code", "subtitle": "", "title": "Coding"}, "extraction": {"description": "Extracting named entities (such as author names and numerical values) and sentiment (e.g., positive or negative) from text.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "extraction", "short": "Ext", "subtitle": "", "title": "Extraction"}, "humanities": {"description": "Creating essays and strategies on topics related to law, economics, history, philosophy, and education.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "humanities", "short": "Human", "subtitle": "", "title": "Humanities"}, "math": {"description": "Generating solutions for problems and word problems in algebra, geometry, probability, and number theory.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "math", "short": "Math", "subtitle": "", "title": "Math"}, "reasoning": {"description": "Generating answers to questions by leveraging common knowledge and reasoning skills.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "reasoning", "short": "Reason", "subtitle": "", "title": "Reasoning"}, "roleplay": {"description": "Writing creative texts by assuming the persona of famous individuals or fictional characters and imagining hypothetical scenarios.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "roleplay", "short": "Role", "subtitle": "", "title": "Roleplay"}, "stem": {"description": "Generating answers and explanations on topics related to physics, chemistry, biology, geography, architecture, and machine learning.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "stem", "short": "STEM", "subtitle": "", "title": "STEM"}, "writing": {"description": "Writing blog articles, email drafts, and fictional narratives.", "link": {"author": "Zheng et al.", "href": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/91f18a1287b398d378ef22505bf41832-Abstract-Datasets_and_Benchmarks.html", "year": "2023"}, "metric": "Reference-guided grading by GPT-4o (gpt-4o-2024-08-06)", "name": "writing", "short": "Write", "subtitle": "", "title": "Writing"}}, "title": "Japanese MT-Bench"}, "other": {"category": "Other", "for": ["base", "inst"], "tasks": {"GPQA": {"name": "GPQA", "short": "GPQA", "subtitle": "GPQA", "title": "GPQA"}}, "title": "Other tasks"}};
